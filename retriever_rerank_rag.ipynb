{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab991c4-d9df-47a1-9ccd-490b2287af93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON dir: C:\\Users\\offic\\AGENT\\data\\text_json\n",
      "Index dir: C:\\Users\\offic\\AGENT\\retriever\\faiss_index\n",
      "Loaded 67 documents\n",
      "\n",
      "Chunking to ~480 tokens (+50 overlap)\n",
      "→ 2570 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tokens/chunk: 626 Mean: 444.6225680933852 \n",
      "\n",
      "Embedding and building FAISS index\n",
      "Index built in 642.1s\n",
      "\n",
      "Reloading FAISS index\n",
      "Loading cross-encoder: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
      "Top‑5 reranked passages:\n",
      "1.  The predominant methodology of the baselines: Ind.: inductive inference, TF: transductive feature extraction methods, TI: transductive inference methods. Conv: convolutional blocks, RN: ResNet backbo…\n",
      "\n",
      "2.  ﬁnal output feature di- mension is 64. The ResNet-12 backbone is used in most of the state-of-the-art models (Zhang et al. 2020; Ye et al. 2020; Liu et al. 2020). It consists of four residual blocks,…\n",
      "\n",
      "3. /a 85.0 ± n/a APN ResNet-12 69.87 ±0.32 86.35 ±0.41 FRN ResNet-12 71.16 ±0.22 86.01 ±0.15 HGNN ResNet-12 72.05 ±0.23 86.49 ± 0.15 Table 2: Results on TieredImageNet Methods Backbone 1-shot 5-shot Prot…\n",
      "\n",
      "4. -18, and ­DenseNet42. EfficientNetV2 was selected for its state-of-the-art performance on mod- ern, image classification datasets. ResNet-18 and DenseNet were selected for their state-of-the-art perfo…\n",
      "\n",
      "5. ﬁcult to tune for larger architectures. We speculate that this is the reason a large part of the existing literature focuses on smaller backbone architectures. The few-shot learning literature has onl…\n",
      "\n",
      "Setting up RetrievalQA with FLAN-T5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "C:\\Users\\offic\\AppData\\Local\\Temp\\ipykernel_27476\\1490508394.py:115: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class RerankRetriever(BaseRetriever):\n",
      "C:\\Users\\offic\\AppData\\Local\\Temp\\ipykernel_27476\\1490508394.py:115: DeprecationWarning: Retrievers must implement abstract `_aget_relevant_documents` method instead of `aget_relevant_documents`\n",
      "  class RerankRetriever(BaseRetriever):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running RAG Query ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2481 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      " most of the state-of-the-art models (Zhang et al. 2020; Ye et al. 2020; Liu et al., and ­DenseNet42.\n",
      "\n",
      "Sources:\n",
      "1.  The predominant methodology of the baselines: Ind.: inductive inference, TF: transductive feature extraction methods, TI: transductive inference methods. Conv: convolutional blocks, RN: ResNet backbo…\n",
      "2.  ﬁnal output feature di- mension is 64. The ResNet-12 backbone is used in most of the state-of-the-art models (Zhang et al. 2020; Ye et al. 2020; Liu et al. 2020). It consists of four residual blocks,…\n",
      "3. /a 85.0 ± n/a APN ResNet-12 69.87 ±0.32 86.35 ±0.41 FRN ResNet-12 71.16 ±0.22 86.01 ±0.15 HGNN ResNet-12 72.05 ±0.23 86.49 ± 0.15 Table 2: Results on TieredImageNet Methods Backbone 1-shot 5-shot Prot…\n",
      "4. -18, and ­DenseNet42. EfficientNetV2 was selected for its state-of-the-art performance on mod- ern, image classification datasets. ResNet-18 and DenseNet were selected for their state-of-the-art perfo…\n",
      "5. ﬁcult to tune for larger architectures. We speculate that this is the reason a large part of the existing literature focuses on smaller backbone architectures. The few-shot learning literature has onl…\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "retriever_rerank_rag.py\n",
    "\n",
    "1) Load JSON‑extracted texts\n",
    "2) Token‑chunk to ≤480 tokens\n",
    "3) Embed & build FAISS\n",
    "4) Reload FAISS\n",
    "5) Semantic top‑50 → keyword filter → cross‑encoder rerank → top‑5\n",
    "6) Build RetrievalQA chain\n",
    "7) Run CIFAR‑10 query\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "from transformers import AutoTokenizer, pipeline as hf_pipeline\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document, BaseRetriever\n",
    "\n",
    "# ─── CONFIG ────────────────────────────────────────────────────────────────────\n",
    "TEXT_JSON_DIR       = r\"C:\\Users\\offic\\AGENT\\data\\text_json\"\n",
    "INDEX_DIR           = r\"C:\\Users\\offic\\AGENT\\retriever\\faiss_index\"\n",
    "\n",
    "EMBED_MODEL         = \"sentence-transformers/msmarco-distilbert-base-v4\"\n",
    "EMBED_BATCH_SIZE    = 64\n",
    "\n",
    "TOKEN_CHUNK_SIZE    = 480\n",
    "TOKEN_CHUNK_OVERLAP = 50\n",
    "\n",
    "SEMANTIC_K          = 50\n",
    "FINAL_K             = 5\n",
    "KEYWORD_FILTER      = \"CIFAR-10\"\n",
    "\n",
    "RERANK_MODEL        = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "READER_MODEL        = \"google/flan-t5-large\"\n",
    "\n",
    "# ─── PREPARE ───────────────────────────────────────────────────────────────────\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "print(\"JSON dir:\", TEXT_JSON_DIR)\n",
    "print(\"Index dir:\", INDEX_DIR)\n",
    "\n",
    "# ─── STEP 1: LOAD DOCUMENTS ────────────────────────────────────────────────────\n",
    "docs = []\n",
    "for fn in sorted(os.listdir(TEXT_JSON_DIR)):\n",
    "    if fn.endswith(\".json\"):\n",
    "        with open(os.path.join(TEXT_JSON_DIR, fn), encoding=\"utf-8\") as f:\n",
    "            docs.append(json.load(f).get(\"full_text\", \"\"))\n",
    "print(f\"Loaded {len(docs)} documents\\n\")\n",
    "\n",
    "# ─── STEP 2: TOKEN‑BASED SPLITTING ──────────────────────────────────────────────\n",
    "print(f\"Chunking to ~{TOKEN_CHUNK_SIZE} tokens (+{TOKEN_CHUNK_OVERLAP} overlap)\")\n",
    "splitter = TokenTextSplitter(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=TOKEN_CHUNK_SIZE,\n",
    "    chunk_overlap=TOKEN_CHUNK_OVERLAP,\n",
    ")\n",
    "chunks = [chunk for doc in docs for chunk in splitter.split_text(doc)]\n",
    "print(f\"→ {len(chunks)} chunks\")\n",
    "\n",
    "# sanity check\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBED_MODEL)\n",
    "lengths = [len(tokenizer.encode(c)) for c in chunks]\n",
    "print(\"Max tokens/chunk:\", max(lengths), \"Mean:\", sum(lengths)/len(lengths), \"\\n\")\n",
    "\n",
    "# ─── STEP 3: EMBEDDING & FAISS BUILD ────────────────────────────────────────────\n",
    "print(\"Embedding and building FAISS index\")\n",
    "emb = HuggingFaceEmbeddings(\n",
    "    model_name=EMBED_MODEL,\n",
    "    encode_kwargs={\"batch_size\": EMBED_BATCH_SIZE, \"truncation\": True, \"max_length\": 512},\n",
    ")\n",
    "t0 = time.time()\n",
    "vs = FAISS.from_texts(chunks, emb)\n",
    "vs.save_local(INDEX_DIR)\n",
    "print(f\"Index built in {time.time() - t0:.1f}s\\n\")\n",
    "\n",
    "# ─── STEP 4: RELOAD INDEX ───────────────────────────────────────────────────────\n",
    "print(\"Reloading FAISS index\")\n",
    "vs = FAISS.load_local(INDEX_DIR, emb, allow_dangerous_deserialization=True)\n",
    "\n",
    "# ─── STEP 5: SEMANTIC → KEYWORD → RERANK ────────────────────────────────────────\n",
    "print(f\"Loading cross-encoder: {RERANK_MODEL}\")\n",
    "reranker = CrossEncoder(RERANK_MODEL)\n",
    "\n",
    "def retrieve_and_rerank(query: str):\n",
    "    # 1) semantic top‑K\n",
    "    sem_docs = vs.similarity_search(query, k=SEMANTIC_K)\n",
    "    # 2) keyword filter\n",
    "    filtered = [d for d in sem_docs if KEYWORD_FILTER.lower() in d.page_content.lower()]\n",
    "    candidates = filtered if len(filtered) >= FINAL_K else sem_docs\n",
    "    # 3) rerank via cross‑encoder\n",
    "    pairs = [[query, d.page_content] for d in candidates]\n",
    "    scores = reranker.predict(pairs)\n",
    "    ranked = [candidates[i] for i in sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)]\n",
    "    return ranked[:FINAL_K]\n",
    "\n",
    "# quick test of reranker\n",
    "q = \"Which approaches used ResNet backbone?\"\n",
    "top_docs = retrieve_and_rerank(q)\n",
    "print(f\"Top‑{FINAL_K} reranked passages:\")\n",
    "for i, d in enumerate(top_docs, 1):\n",
    "    print(f\"{i}. {d.page_content[:200].replace(chr(10),' ')}…\\n\")\n",
    "\n",
    "# ─── STEP 6: BUILD & RUN RETRIEVALQA ────────────────────────────────────────────\n",
    "print(\"Setting up RetrievalQA with FLAN-T5\")\n",
    "hf_pipe = hf_pipeline(\"text2text-generation\", model=READER_MODEL, max_new_tokens=256)\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipe)\n",
    "\n",
    "class RerankRetriever(BaseRetriever):\n",
    "    \"\"\"A LangChain Retriever that wraps our reranking function.\"\"\"\n",
    "    def get_relevant_documents(self, query: str) -> list[Document]:\n",
    "        return retrieve_and_rerank(query)\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> list[Document]:\n",
    "        return self.get_relevant_documents(query)\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=RerankRetriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"\\n=== Running RAG Query ===\")\n",
    "res = qa({\"query\": q})\n",
    "print(\"\\nAnswer:\\n\", res[\"result\"])\n",
    "print(\"\\nSources:\")\n",
    "for i, doc in enumerate(res[\"source_documents\"], 1):\n",
    "    snippet = doc.page_content.replace(\"\\n\", \" \")\n",
    "    print(f\"{i}. {snippet[:200]}…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc279843-c334-4a91-a58a-79442d626ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
