{
  "filename": "2107.05427v1.pdf",
  "num_pages": 21,
  "pages": [
    "Choosing Imputation Models\nMoritz Marbach∗\nABSTRACT\nImputing missing values is an important preprocessing step in data analysis, but\nthe literature oﬀers little guidance on how to choose between diﬀerent imputation\nmodels.\nThis letter suggests adopting the imputation model that generates a\ndensity of imputed values most similar to those of the observed values for an\nincomplete variable after balancing all other covariates. We recommend stable\nbalancing weights as a practical approach to balance covariates whose distribution\nis expected to diﬀer if the values are not missing completely at random. After\nbalancing, discrepancy statistics can be used to compare the density of imputed\nand observed values.\nWe illustrate the application of the suggested approach\nusing simulated and real-world survey data from the American National Election\nStudy, comparing popular imputation approaches including random forests, hot-\ndeck, predictive mean matching, and multivariate normal imputation.\nAn R\npackage implementing the suggested approach accompanies this letter.\n∗Texas A&M University, The Bush School of Government & Public Service, moritz.marbach@tamu.edu\n1\narXiv:2107.05427v1  [stat.ME]  12 Jul 2021\n",
    "Missing data are ubiquitous, and missing data imputation remains an important prepro-\ncessing step in any data analysis. A large number of diﬀerent multiple imputation models\nhave been developed over the years. Popular examples for univariate multiple imputation\nmethods include parametric regression imputation (Rubin, 1987), as well as non-parametric\napproaches such as predictive mean matching imputation (Little, 1988), random hot-deck\nimputation (Andridge and Little, 2010; Cranmer and Gill, 2013) and random forest imputa-\ntion (Doove et al., 2014; Stekhoven and B¨uhlmann, 2012). Multivariate multiple imputation\napproaches include multivariate normal imputation (Schafer, 1997; King et al., 2001) as well\nas imputation using a sequence of chained univariate imputation methods (Van Buuren et al.,\n2006; Van Buuren, 2007).1\nFor users imputing a dataset, choosing among available imputation models is often diﬃ-\ncult. As imputation is diﬀerent from optimal point prediction (e.g., Rubin, 1996), standard\nmodel choice approaches such as cross-validation, have limited use. In this letter, we point to\na simple criterion to choose among diﬀerent imputation approaches: choose the imputation\nmodel that produces imputed values that are more consistent with the assumed missing data\nmechanism. Speciﬁcally, for observations that only diﬀer in that some values for one variable\ny are missing, choose the imputation model that produces a density of imputed values that\nis most similar to the density of the observed values. To render this criterion operational,\nwe suggest computing weights such that the densities of covariates X for observations with\nand without missing values on y are identical, and then utilizing discrepancy statistics to\ndetermine the diﬀerences between the density of imputed values and the (adjusted) density\nof observed values.\nThe concept of comparing the unadjusted density of observed and imputed values is an\nestablished recommendation for identifying problems with imputation models (e.g., Abayomi\net al., 2008; Van Buuren, 2018). However, an unadjusted comparison often has limited use\nas it is expected that there will be diﬀerences in the densities if the missing data indicator is\ncorrelated with other covariates in the data, that is, if the data are not missing completely\nat random (MCAR) in the terminology of Little and Rubin (2019). We therefore suggest\nweighting the data before making the comparison.\nOur approach is complementary to a recently proposed, graphical approach in the medical\nresearch literature which has not been used in social science research.2 Speciﬁcally, Bon-\ndarenko and Raghunathan (2016) propose plotting the imputed and observed values against\n1Whereas multivariate normal imputation is implemented in the Amelia R package, chained equation models\nfor imputation are available in the MICE package.\nIn Stata both approaches are available through the\ncommand mi impute mvn and mi impute chained.\n2We reviewed all 33 citations to the paper and found no applied study in the ﬁelds of Political Science,\nEconomics or Sociology.\n2\n",
    "the (estimated) probability that a value is missing and preferring imputations that display\nfewer diﬀerences in the density of observed and imputed values across various levels of the\nmissingness probability.\nGiven the limited popularity of this approach, we developed a general, simple—and, ar-\nguably, more intuitive—weighting method that allows users to choose an imputation model\nthat suits their dataset best. More generally, we hope that the suggested approach facilitates\nthe application of multiple imputation in applied research. In the following, we detail the\nassumptions needed, how to estimate the weights and illustrate the application using simu-\nlated and real-world data. An R package implementing the suggested approach accompanies\nthis letter and is available on Github.3\nADJUSTED COMPARISON OF IMPUTED AND OBSERVED VALUES\nConsider a variable Y for which some values are missing and some values are observed. A\nmissing data indicator, M, encodes Mi = 0 if a value yi is observed or Mi = 1 if it is missing.\nLet X be the set of all other covariates. We assume that the observations are independent\nand identically distributed (i.i.d.) and that the data are missing at random (MAR) (Rubin,\n1976; Mealli and Rubin, 2015), that is, f(Mi|xi, yi) = f(Mi|xi)∀i = 1, ..., N. Most imputation\nmodels, including those mentioned in the introduction, rely on both these assumptions.\nWhen the data are i.i.d. and MAR, the conditional density of the missing values, f(Y |X =\nx, M = 0), is equal to the conditional density of the observed values, f(Y |X = x, M = 1)\n(e.g., Little and Rubin, 2019, p. 18). In other words, holding X constant, the density of\nmissing and observed values is equal under the MAR assumption. This notion suggests an\nassessment of whether the empirical densities of the imputed values and observed values diﬀer\nafter adjusting for diﬀerences in X. Imputation models for which imputed values are more\nsimilar to the observed values after adjustment are more consistent with MAR and may be\npreferred over imputation models that lead to imputed values with larger deviations.\nTo adjust for the covariates X, we propose computing a weight such that the moments\nof the covariate densities for observations with and without missing values in Y match.\nDiﬀerent weighting schemes have been proposed in the literature to compute such weights.\nFor example, Hainmueller’s entropy balancing weighting scheme computes such weights by\nminimizing the Kullback entropy divergence (Hainmueller, 2012) and Zubizarreta’s weighting\nscheme minimizes the variance among the weights (Zubizarreta, 2015). We prefer the latter\nas it, naturally, leads to fewer instances of extreme weights but note that entropy-balancing\ncomputations tend to be faster in practice.\n3https://github.com/sumtxt/missDiag\n3\n",
    "Zubizarreta’s weighting scheme, a convex quadratic programming problem that can be\nsolved with standard optimization solvers, takes the following form:\nminimize\nw\n∥w −w∥2\n2\nsubject to\n|w′xM=0,p −xM=1,p| ≤δp,\np = 1, ..., P,\n1′w = 1,\nw ≥0,\nwhere w is the vector of weights to be computed, w is the average weight, ∥· ∥2 is the\nEuclidean norm (the square root of the sum of squares), xM=0,p is the covariate vector p of\nobservations without a missing value on y, and xM=1,p is the sample mean of covariate p\namong observations for which y is imputed. The tolerance parameter δp is typically set to a\nsmall value if not exactly 0. This weighting scheme balances the ﬁrst moment of the covariate\ndensities (the means). To balance higher-order moments one may include the appropriate\nterms. For example, to balance the second moment of xp (the variances) one includes x2\np.\nTo identify the diﬀerence between the (weighted) density of imputed and observed val-\nues, we suggest adopting four statistics that are widely used to assess balance between the\ntreatment and control groups in causal inference (Imbens and Rubin, 2015; Franklin et al.,\n2014). For all four metrics, smaller values suggest a higher similarity.\nThe standardized mean diﬀerence (SMD) is the diﬀerence between the means of the\ndensities for the imputed and observed values standardized by the square of their average\nvariance. The log variance ratio, log(VR), is the logarithm of the variance ratio. The SMD\nmeasures the diﬀerence in the densities’ locations, and the VR measures the diﬀerence in the\ndensities’ dispersion.\nThe SMD and VR measure the diﬀerences in the ﬁrst and second moments of two densities,\nwhereas the Kolmogorov—Smirnov (KS) statistic is also sensitive to deviations in higher\nmoments. The KS measures the largest discrepancy between the empirical and cumulative\ndistributions. It is best thought of as a measure of the largest dissimilarity between the\nimputed and observed values.\nA complementary statistic is the overlap (OVL) coeﬃcient. The OVL coeﬃcient measures\nlocal similarities instead of local discrepancies between two densities. Speciﬁcally, it is deﬁned\nas the proportion of the overlap between two densities. Typically, the diﬀerence 1-OVL is\nreported such that smaller values suggest a higher similarity.\nTo properly reﬂect uncertainty about the imputed values in any analysis, a series of\nimputed datasets are typically generated; each dataset is analyzed and the estimates are\n4\n",
    "combined using Rubin’s rules (Rubin, 1987).\nThis procedure can also be applied to the\ndiscrepancy statistics introduced above. Users may average the discrepancy statistics across\nthe multiple imputed datasets or, alternatively, compare the densities of the balance statistics\ngraphically as illustrated below.\nIn practice, the covariates X might also include missing values. Adopting a multivariate\nversion of MAR (cf. Little and Rubin, 2019, p. 14), one typically imputes missing values\nin X jointly with missing values in Y . Therefore one can compute a weight such that the\nmoments of the ﬁlled-in covariate densities for observations with and without missing values\nin Y match.4 One concern with this strategy is that the multivariate version of MAR implies\nthat the joined density of missing values is equal to the joined density of observed values.\nYet, applying the suggested approach amounts to comparing the (full) conditional densities\nof Y alone rather than the joined densities. A more comprehensive assessment therefore\ninvolves the comparison of the conditional densities of Y and all covariates X one at a time.\nThat said, it would be desirable for future research to develop an approach that compares\nthe joined densities directly.\nILLUSTRATION WITH SIMULATED DATA\nIn this section, we use simulated data to demonstrate how the above approach can be used\nto assess which imputation model produces better imputed data (i.e., generates a density of\nimputed values more similar to the [reweighted] density of observed values) and that pooled\nregression estimates from models ﬁtted on better imputed data are also less biased.\nWe simulate 1,000 datasets (with N = 1, 000) from a linear model of the form y = x·z +e\nwith ﬁxed parameters. Covariate z is drawn from a Bernoulli distribution with mean 0.5 and\ncontinuous covariate x from a uniform distribution with range -5 to 5. We set the variance\nof the normal error distribution to 1 and let the proportion of missing values in y vary with\nz. The two proportions are drawn independently from a uniform distribution in the range of\n0.1 to 0.5. The larger value determines the proportion of missing values if z = 1 whereas the\nsmaller value determines the proportion of missing values if z = 0. The simulated missing\ndata mechanism is consistent with the i.i.d. and MAR assumptions.\nIterating over all simulated datasets, we impute the missing values ﬁve times using four\npopular imputation approaches implemented in the MICE software package (Van Buuren\nand Groothuis-Oudshoorn, 2011): predictive mean matching, random hot-deck imputation,\nnormal model imputation and random forest imputation. Predictive mean matching amounts\n4An alternative but limited strategy is to treat missingness as another category if X includes categorical\nvariables alone and compute the weight such that the moments of the binary indicators for each category\n(including the missing value category) for observations with and without missing values in Y match.\n5\n",
    "to measuring the distance between all observed values and a missing value using their pre-\ndicted values from a linear, additive regression model. Five observations with the smallest\ndistance are used to construct a donor candidate pool, from which one observation is drawn\nat random to impute the missing value.\nStandardized mean difference\nLog(Variance ratio)\nKolmogorov−Smirnov statistic\n1−Overlap coefficient\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\nFewer <−> more discrepancies\nA: Discrepancy statistics\n(Intercept)\nx\nz\nx:z\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\n−0.4\n−0.2\n0.0\n0.2\n0.4\nImputation approach\nTruth−Estimate\nB: Coefficient estimates\nFigure 1: Summary of 1,000 Monte Carlo simulations. Panel A: Box plots of four discrep-\nancy statistics comparing the weighted density of observed and imputed values. Panel B:\nBox plots of the bias in the (pooled) coeﬃcient estimates of a linear model y = x·z +ϵ. Each\ndataset was imputed ﬁve times using random hot-deck imputation (Hotdeck), random for-\nest imputation (RForest), predictive mean matching (PMM) and normal model imputation\n(Norm). Some box plots are clipped to increase readability.\n6\n",
    "Random hot-deck imputation is similar to predictive mean matching but compares ob-\nservations’ covariate proﬁle using a (multivariate) distance function such as the Mahalanobis\ndistance. A random draw from the candidate pool of ﬁve observations is used to impute the\nmissing value. Normal model imputation uses the predicted values from a linear, additive\nregression model to impute the missing values.\nRandom forest imputation is typically encountered as a single imputation method (e.g.,\nStekhoven and B¨uhlmann, 2012), but an implementation for the multiple imputation context\nis also available (Doove et al., 2014). Random forest is an ensemble machine learning method\nbased on decision trees. Diﬀerent from the normal model imputation, it does not rely on a\nlinear, additive model and thus has the potential to accommodate more ﬂexible dependencies\nbetween variables.\nWe apply the diagnostic as described above and estimate the coeﬃcients of a linear\nregression model that includes an interaction term. Consistent with the multiple imputation\napproach, we estimate these linear regression models on each imputed dataset and average\nthe resulting coeﬃcient estimates.\nIn Figure 1 (Panel A), each box plot describes a distribution of a discrepancy statistic\n(averaged across ﬁve imputed datasets). Given the non-linear data generating process, we\nwould expect imputation approaches without linearity assumptions (hot-deck imputation and\nrandom forest imputation) to perform better. This is indeed what we ﬁnd: The discrepancy\nstatistics from these two imputation approaches are, on average, closer to zero, suggesting\nthat hock-deck imputation and random forest imputation produces better imputed data for\nthe simulated data generating process.\nThe diﬀerences between random hot-deck imputation and random forest imputation are\nless pronounced. While the standardized mean diﬀerences from random hot-deck imputation\nare closer to zero on average, we see fewer diﬀerences for the other three discrepancy statis-\ntics. However, altogether the discrepancy statistics suggest that random hot-deck imputation\nproduces better imputed data for the simulated data generating process.5\nFigure 1 (Panel B) shows the distribution of the bias (truth-estimate) in the (pooled)\ncoeﬃcient estimates for four linear regression terms across the simulations. As expected,\ncoeﬃcient estimates based on the better imputed data are, on average, less biased. When\nthe data are imputed by random hot-deck there is, on average, no bias left in either the main\neﬀects or the interaction eﬀect. When the data are imputed by the random forest, there is no\nbias left for the main eﬀects on average, but some bias remains in the interaction eﬀect. For\n5The longer tailed distribution for the log(VR) distribution might cast doubt on the superior performance of\nrandom hot-deck imputation (relative to random forest imputation). However, random hot-deck imputation\nalso does better in terms of the variance once we explicitly balance the second moment (the variance) of the\ncovariate densities (see Figure A.1).\n7\n",
    "the normal model imputation and predictive mean matching, the bias remains substantial in\nboth the main eﬀect and interaction eﬀect.\nIMPUTING ANES\nTo illustrate the application of the suggested approach beyond simulated data, we use survey\ndata from the 2008 edition of the American National Election Studies (N = 2, 265). The\ndataset prepared by Kropko et al. (2014) includes 11 variables in diﬀerent scales with various\nlevels of missingness.\nTable 1 provides a description of the variables and the number of\nmissing values.\nVariable\nMissing\nDescription\nAge\n0\nAge of the respondent.\nSex\n0\nSex of the respondent.\nRace\n9\nNon-white vs. white.\nEducation\n0\nNo high school, some high school, high school diploma, college.\nIncome\n158\nLow, medium, high.\nReligion\n393\nProtestant, Catholic/Orthodox, Atheist/other.\nMarital status\n0\nSingle, married, no longer married.\nGov. support\n152\n7 response categories ranging from “Govt should let each person\nget ahead on own” to “Govt should see to jobs and standard of\nliving.”\nEnvironment\n23\nWhether the respondent sees the environment as an important\nissue (yes/no).\nVote\n258\nVote choice in the 2008 Presidential election: Obama, McCain,\nNo vote/Other.\nTime\n217\nTime for the respondent to complete the survey.\nTable 1: Summary of eleven variables from the 2008 American National Election Studies.\nWe impute the dataset using the four most popular imputation approaches for mixed-\ntype datasets again: predictive mean matching, random hot-deck imputation, random forest\nimputation and multivariate normal model imputation. We reply on the Amelia package\n(Honaker et al., 2011) for multivariate normal imputation and on the MICE package for\nthe other three approaches (Van Buuren and Groothuis-Oudshoorn, 2011). To simplify the\nanalysis, we consider “government support” as a continuous variable. We also log-transform\nthe variable “response time” before imputation.\nFor each variable with at least 25 imputed values, we construct weights that balance all\nother variables using the weighting scheme described previously. Figure 2 shows the density\n8\n",
    "of the discrepancy statistics across 100 imputed datasets. As the mean of a binary variable is\na suﬃcient statistic, we only provide the standardized mean diﬀerence for all binary variables.\nStandardized mean difference\nIncome\nReligion\nVote\n0.00 0.05 0.10 0.15 0.20 0.25\nHigh income\nLow income\nMedium income\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nHotdeck\nPMM\nRForest\nNorm\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.00\n0.05\n0.10\n0.15\n0.20\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure 2: Box plots of discrepancy statistics comparing the weighted density of observed\nand imputed values across 100 imputed datasets. Some outliers are removed, and some upper\nwhiskers are clipped to increase readability.\nWe observe the largest discrepancies in the standardized mean diﬀerences for two of the\nthree categories of the variable “religion.” The density of the standardized mean diﬀerence\nfor the multivariate normal imputation and random forest are both bounded away from zero\nand are distinct from the density of the two other approaches. We observe similar yet less\n9\n",
    "pronounced diﬀerences for the variable “vote” and “government support.” For two continuous\nvariables we observe a similar pattern for the OVL coeﬃcient and KS statistic; hot-deck and\npredictive mean matching imputation both do much better than the other two approaches.\nAll four approaches are similar in terms of the variance ratio.\nThe hot-deck and predictive mean imputation performances are fairly similar across vari-\nables and discrepancy statistics. Table 2 demonstrates that predictive mean matching does a\nlittle better than hot-deck imputation when averaging across imputed datasets and variables.\nBased on these averages one may recommend using predictive mean matching as it produces\nimputed values that are more consistent with the MAR assumption on average across all vari-\nables. Alternatively, one may use the results to revise the imputation model. MICE relies on\nchained univariate imputation models which means that it is easy to use diﬀerent imputation\napproaches for diﬀerent variables and we could therefore select predictive mean matching for\nsome variables and hot-deck imputation for others, depending on their performance.\nDiscrepancy statistics\nSMD\nlog(VR)\nKS\n1-OVL\nPMM\n0.053\n0.077\n0.029\n0.028\nHotdeck\n0.058\n0.085\n0.031\n0.030\nNorm\n0.100\n0.082\n0.061\n0.061\nRForest\n0.125\n0.079\n0.059\n0.057\nTable 2: Average discrepancy statistics across variables and imputed datasets for predictive\nmean matching imputation (PMM), random hot-deck imputation (Hotdeck), multivariate\nnormal imputation (Norm) and random forest imputation (RForest). The four displayed\ndiscrepancy statistics include standardized mean diﬀerence (SMD), variance ratio (VR),\nKolmogorov—Smirnov statistic (KS) and overlap coeﬃcient (1-OVL).\nThe diﬀerential performance of the four imputation approaches cannot be explained by\nthe diﬀerential performance of the constructed weights. In the appendix (Figure A.2–A.6),\nwe document that the constructed weights balance the ﬁrst moment of the densities exactly\n(as expected). Some moderate imbalances are left for the higher moments of the continuous\nvariables. In principle, these could be removed by adding, for example, the variables squared\nand cubed to the weighting scheme. However, because these higher-moment imbalances are\nlargely not diﬀerential between the four imputation approaches, they cannot explain the\ndiﬀerential performance.\nOne concern with the analysis might be that higher-order interactions are not explicitly\nbalanced.\nFor example, while the weights ensure that the proportions of Obama voters\nand of women among respondents with and without missing values on the variable religion\nare identical, they do not guarantee that the proportions of women voting for Obama are\n10\n",
    "identical. To evaluate the sensitivity of the results to the inclusion of some higher-order\ninteractions, we replicate the analysis balancing the interactions of the demographic variables\n(gender, age, and race) with all other variables. The results, which appear in Figure A.7, are\nlargely identical to those in Figure 2.\nCONCLUSION\nIncomplete data is a common challenge when analyzing real-world data. Another challenge\nis choosing from many available multiple imputation approaches to ﬁll-in the missing values.\nWhile some approaches are more popular than others, the literature oﬀers little advice on\nhow to choose among them for a given dataset.\nIn the absence of such advice, list-wise\ndeletion remains a popular default approach despite its known deﬁcits. And even if multiple\nimputation is used in applied work, it is common practice to rely on the (currently) most\npopular approach in the literature (cf. Lall, 2016) which may or may not be optimal for a\ngiven dataset.\nThis letter provides a conceptually simple and practical approach to choosing between\ncompeting imputation models that impute data under MAR. The approach is ﬂexible and\ndoes not have to be tailored to a particular imputation model; all it needs is the data with\nthe missing values and the ﬁlled-in dataset. It builds on the same assumptions made by most\nmultiple imputation models, in particular the MAR assumption. While more work is needed\nto understand how to choose between imputation models when the data are missing not at\nrandom (MNAR), we hope that this letter, in conjunction with the accompanying, easy-\nto-use software package in R, prompts users to make explicit comparisons between diﬀerent\nimputation models for their dataset and to choose the one that imputes values most consistent\nwith MAR.\nWe also hope that this contribution lowers the barriers faced by applied researchers trying\nto address missing data in their data analysis and therefore reduces the reliance on list-wise\ndeletion which always leads to ineﬃcient estimates but typically also introduces bias. More\ngenerally, our approach highlights how weighting and imputation approaches, often seen as\nalternative strategies to handle missing data, can be combined in a productive manner. While\nwe are not the ﬁrst to combine both—for example, Seaman et al. (2012) combine multiple\nimputations with weighting to achieve double robustness—the combination of weighting and\nimputation appears to be a fruitful avenue for future research.\n11\n",
    "REFERENCES\nAbayomi, K., A. Gelman, and M. Levy (2008). Diagnostics for Multivariate Imputations.\nJournal of the Royal Statistical Society. Series C 57(3), 273–291.\nAndridge, R. R. and R. J. Little (2010). A Review Of Hot Deck Imputation For Survey\nNon-response. International Statistical Review 78(1), 40–64.\nBondarenko, I. and T. Raghunathan (2016).\nGraphical and Numerical Diagnostic Tools\nto Assess Suitability of Multiple Imputations and Imputation Models.\nStatistics in\nMedicine 35(17), 3007–3020.\nCranmer, S. J. and J. Gill (2013). We Have to Be Discrete About This: A Non-Parametric\nImputation Technique for Missing Categorical Data.\nBritish Journal of Political Sci-\nence 43(2), 425–449.\nDoove, L. L., S. Van Buuren, and E. Dusseldorp (2014). Recursive Partitioning for Missing\nData Imputation in the Presence of Interaction Eﬀects. Computational Statistics & Data\nAnalysis 72, 92–104.\nFranklin, J. M., J. A. Rassen, D. Ackermann, D. B. Bartels, and S. Schneeweiss (2014).\nMetrics for Covariate Balance in Cohort Studies Of Causal Eﬀects.\nStatistics in\nMedicine 33(10), 1685–1699.\nHainmueller, J. (2012). Entropy Balancing for Causal Eﬀects: A Multivariate Reweighting\nMethod to Produce Balanced Samples In Observational Studies. Political Analysis 20(1),\n25–46.\nHonaker, J., G. King, and M. Blackwell (2011). Amelia II: A Program for Missing Data.\nJournal of Statistical Software 45(7), 1–47.\nImbens, G. W. and D. B. Rubin (2015). Causal Inference in Statistics, Social, and Biomedical\nSciences: An Introduction. Cambridge: Cambridge University Press.\nKing, G., J. Honaker, A. Joseph, and K. Scheve (2001).\nAnalyzing Incomplete Political\nScience Data: An Alternative Algorithm for Multiple Imputation.\nAmerican Political\nScience Review 95(1), 49–69.\nKropko, J., B. Goodrich, A. Gelman, and J. Hill (2014). Multiple Imputation for Continuous\nand Categorical Data: Comparing Joint Multivariate Normal And Conditional Approaches.\nPolitical Analysis 22(4), 497–519.\n12\n",
    "Lall, R. (2016). How Multiple Imputation Makes a Diﬀerence. Political Analysis 24(4),\n414–433.\nLittle, R. J. (1988). Missing-data Adjustments in Large Surveys. Journal of Business &\nEconomic Statistics 6(3), 287–296.\nLittle, R. J. A. and D. B. Rubin (2019). Statistical Analysis with Missing Data (Third Edition\ned.). New York: Wiley.\nMealli, F. and D. B. Rubin (2015). Clarifying Missing at Random and Related Deﬁnitions,\nand Implications When Coupled With Exchangeability. Biometrika 102(4), 995–1000.\nRubin, D. B. (1976). Inference and Missing Data. Biometrika 63(3), 581–592.\nRubin, D. B. (1987). Multiple Imputation for Nonresponse in Surveys. New York: J. Wiley\n& Sons.\nRubin, D. B. (1996). Multiple Imputation After 18+ Years. Journal of the American Statis-\ntical Association 91(434), 473–489.\nSchafer, J. L. (1997). Analysis of Incomplete Multivariate Data. Boca Raton: Chapman and\nHall.\nSeaman, S. R., I. R. White, A. J. Copas, and L. Li (2012). Combining Multiple Imputation\nand Inverse-Probability Weighting. Biometrics 68(1), 129–137.\nStekhoven, D. J. and P. B¨uhlmann (2012). MissForest—Non-parametric Missing Value Im-\nputation for Mixed-Type Data. Bioinformatics 28(1), 112–118.\nVan Buuren, S. (2007).\nMultiple Imputation of Discrete and Continuous Data by Fully\nConditional Speciﬁcation. Statistical Methods in Medical Research 16(3), 219–242.\nVan Buuren, S. (2018). Flexible Imputation of Missing Data. Chapman & Hall.\nVan Buuren, S., J. P. Brand, C. G. Groothuis-Oudshoorn, and D. B. Rubin (2006). Fully\nConditional Speciﬁcation in Multivariate Imputation. Journal of Statistical Computation\nand Simulation 76(12), 1049–1064.\nVan Buuren, S. and K. Groothuis-Oudshoorn (2011).\nmice: Multivariate Imputation by\nChained Equations in R. Journal of Statistical Software 45(3), 1–67.\nZubizarreta, J. R. (2015). Stable Weights That Balance Covariates for Estimation With\nIncomplete Outcome Data.\nJournal of the American Statistical Association 110(511),\n910–922.\n13\n",
    "Supplementary Information\nAppendix A\nADDITIONAL FIGURES\n14\n",
    "Standardized mean difference\nLog(Variance ratio)\nKolmogorov−Smirnov statistic\n1−Overlap coefficient\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\nFewer <−> more discrepancies\nA: Discrepancy statistics\n(Intercept)\nx\nz\nx:z\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\n−0.4\n−0.2\n0.0\n0.2\n0.4\nImputation approach\nTruth−Estimate\nB: Coefficient estimates\nFigure A.1: Summary of 1,000 Monte Carlo simulations. Panel A: Box plots of four dis-\ncrepancy statistics comparing the weighted density of observed and imputed values. Weights\nare constructed to balance the ﬁrst and second moment of the covariate densities. Panel B:\nBox plots of the bias in the (pooled) coeﬃcient estimates of a linear model y = x·z +ϵ. Each\ndataset was imputed ﬁve times using random hot-deck imputation (Hotdeck), random for-\nest imputation (RForest), predictive mean matching (PMM) and normal model imputation\n(Norm). Some box plots are clipped to increase readability.\n15\n",
    "Standard. mean diff.\nEducation\nMarital st.\nReligion\nVote\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nMarried\nNo longer married\nSingle\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.2: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable income across 100 imputed datasets.\nSome outliers are\nremoved, and some upper whiskers are clipped to increase readability.\n16\n",
    "Standard. mean diff.\nEducation\nIncome\nMarital st.\nReligion\nVote\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nHigh income\nLow income\nMedium income\nMarried\nNo longer married\nSingle\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nResponse\ntime\nAge\nResponse\ntime\nAge\nResponse\ntime\nAge\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.3: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable government support across 100 imputed datasets. Some\noutliers are removed, and some upper whiskers are clipped to increase readability.\n17\n",
    "Standard. mean diff.\nEducation\nIncome\nMarital st.\nVote\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nHigh income\nLow income\nMedium income\nMarried\nNo longer married\nSingle\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.4: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable religion across 100 imputed datasets.\nSome outliers are\nremoved, and some upper whiskers are clipped to increase readability.\n18\n",
    "Standard. mean diff.\nEducation\nIncome\nMarital st.\nReligion\nVote\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nHigh income\nLow income\nMedium income\nMarried\nNo longer married\nSingle\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nGovernment\nsuport\nAge\nGovernment\nsuport\nAge\nGovernment\nsuport\nAge\nGovernment\nsuport\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.5: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable response time across 100 imputed datasets. Some outliers\nare removed, and some upper whiskers are clipped to increase readability.\n19\n",
    "Standard. mean diff.\nEducation\nIncome\nMarital st.\nReligion\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nHigh income\nLow income\nMedium income\nMarried\nNo longer married\nSingle\nAtheist/Other\nCatholic/Orthodox\nProtestant\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.6: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable vote across 100 imputed datasets. Some outliers are removed,\nand some upper whiskers are clipped to increase readability.\n20\n",
    "Standardized mean difference\nIncome\nReligion\nVote\n0.00 0.05 0.10 0.15 0.20 0.25\nHigh income\nLow income\nMedium income\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.00\n0.05\n0.10\n0.15\n0.20\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.7: Additional balancing of interactions. Box plots of discrepancy statistics\ncomparing the weighted density of observed and imputed values across 100 imputed datasets.\nSome outliers are removed, and some upper whiskers are clipped to increase readability.\n21\n"
  ],
  "full_text": "Choosing Imputation Models\nMoritz Marbach∗\nABSTRACT\nImputing missing values is an important preprocessing step in data analysis, but\nthe literature oﬀers little guidance on how to choose between diﬀerent imputation\nmodels.\nThis letter suggests adopting the imputation model that generates a\ndensity of imputed values most similar to those of the observed values for an\nincomplete variable after balancing all other covariates. We recommend stable\nbalancing weights as a practical approach to balance covariates whose distribution\nis expected to diﬀer if the values are not missing completely at random. After\nbalancing, discrepancy statistics can be used to compare the density of imputed\nand observed values.\nWe illustrate the application of the suggested approach\nusing simulated and real-world survey data from the American National Election\nStudy, comparing popular imputation approaches including random forests, hot-\ndeck, predictive mean matching, and multivariate normal imputation.\nAn R\npackage implementing the suggested approach accompanies this letter.\n∗Texas A&M University, The Bush School of Government & Public Service, moritz.marbach@tamu.edu\n1\narXiv:2107.05427v1  [stat.ME]  12 Jul 2021\n\n\nMissing data are ubiquitous, and missing data imputation remains an important prepro-\ncessing step in any data analysis. A large number of diﬀerent multiple imputation models\nhave been developed over the years. Popular examples for univariate multiple imputation\nmethods include parametric regression imputation (Rubin, 1987), as well as non-parametric\napproaches such as predictive mean matching imputation (Little, 1988), random hot-deck\nimputation (Andridge and Little, 2010; Cranmer and Gill, 2013) and random forest imputa-\ntion (Doove et al., 2014; Stekhoven and B¨uhlmann, 2012). Multivariate multiple imputation\napproaches include multivariate normal imputation (Schafer, 1997; King et al., 2001) as well\nas imputation using a sequence of chained univariate imputation methods (Van Buuren et al.,\n2006; Van Buuren, 2007).1\nFor users imputing a dataset, choosing among available imputation models is often diﬃ-\ncult. As imputation is diﬀerent from optimal point prediction (e.g., Rubin, 1996), standard\nmodel choice approaches such as cross-validation, have limited use. In this letter, we point to\na simple criterion to choose among diﬀerent imputation approaches: choose the imputation\nmodel that produces imputed values that are more consistent with the assumed missing data\nmechanism. Speciﬁcally, for observations that only diﬀer in that some values for one variable\ny are missing, choose the imputation model that produces a density of imputed values that\nis most similar to the density of the observed values. To render this criterion operational,\nwe suggest computing weights such that the densities of covariates X for observations with\nand without missing values on y are identical, and then utilizing discrepancy statistics to\ndetermine the diﬀerences between the density of imputed values and the (adjusted) density\nof observed values.\nThe concept of comparing the unadjusted density of observed and imputed values is an\nestablished recommendation for identifying problems with imputation models (e.g., Abayomi\net al., 2008; Van Buuren, 2018). However, an unadjusted comparison often has limited use\nas it is expected that there will be diﬀerences in the densities if the missing data indicator is\ncorrelated with other covariates in the data, that is, if the data are not missing completely\nat random (MCAR) in the terminology of Little and Rubin (2019). We therefore suggest\nweighting the data before making the comparison.\nOur approach is complementary to a recently proposed, graphical approach in the medical\nresearch literature which has not been used in social science research.2 Speciﬁcally, Bon-\ndarenko and Raghunathan (2016) propose plotting the imputed and observed values against\n1Whereas multivariate normal imputation is implemented in the Amelia R package, chained equation models\nfor imputation are available in the MICE package.\nIn Stata both approaches are available through the\ncommand mi impute mvn and mi impute chained.\n2We reviewed all 33 citations to the paper and found no applied study in the ﬁelds of Political Science,\nEconomics or Sociology.\n2\n\n\nthe (estimated) probability that a value is missing and preferring imputations that display\nfewer diﬀerences in the density of observed and imputed values across various levels of the\nmissingness probability.\nGiven the limited popularity of this approach, we developed a general, simple—and, ar-\nguably, more intuitive—weighting method that allows users to choose an imputation model\nthat suits their dataset best. More generally, we hope that the suggested approach facilitates\nthe application of multiple imputation in applied research. In the following, we detail the\nassumptions needed, how to estimate the weights and illustrate the application using simu-\nlated and real-world data. An R package implementing the suggested approach accompanies\nthis letter and is available on Github.3\nADJUSTED COMPARISON OF IMPUTED AND OBSERVED VALUES\nConsider a variable Y for which some values are missing and some values are observed. A\nmissing data indicator, M, encodes Mi = 0 if a value yi is observed or Mi = 1 if it is missing.\nLet X be the set of all other covariates. We assume that the observations are independent\nand identically distributed (i.i.d.) and that the data are missing at random (MAR) (Rubin,\n1976; Mealli and Rubin, 2015), that is, f(Mi|xi, yi) = f(Mi|xi)∀i = 1, ..., N. Most imputation\nmodels, including those mentioned in the introduction, rely on both these assumptions.\nWhen the data are i.i.d. and MAR, the conditional density of the missing values, f(Y |X =\nx, M = 0), is equal to the conditional density of the observed values, f(Y |X = x, M = 1)\n(e.g., Little and Rubin, 2019, p. 18). In other words, holding X constant, the density of\nmissing and observed values is equal under the MAR assumption. This notion suggests an\nassessment of whether the empirical densities of the imputed values and observed values diﬀer\nafter adjusting for diﬀerences in X. Imputation models for which imputed values are more\nsimilar to the observed values after adjustment are more consistent with MAR and may be\npreferred over imputation models that lead to imputed values with larger deviations.\nTo adjust for the covariates X, we propose computing a weight such that the moments\nof the covariate densities for observations with and without missing values in Y match.\nDiﬀerent weighting schemes have been proposed in the literature to compute such weights.\nFor example, Hainmueller’s entropy balancing weighting scheme computes such weights by\nminimizing the Kullback entropy divergence (Hainmueller, 2012) and Zubizarreta’s weighting\nscheme minimizes the variance among the weights (Zubizarreta, 2015). We prefer the latter\nas it, naturally, leads to fewer instances of extreme weights but note that entropy-balancing\ncomputations tend to be faster in practice.\n3https://github.com/sumtxt/missDiag\n3\n\n\nZubizarreta’s weighting scheme, a convex quadratic programming problem that can be\nsolved with standard optimization solvers, takes the following form:\nminimize\nw\n∥w −w∥2\n2\nsubject to\n|w′xM=0,p −xM=1,p| ≤δp,\np = 1, ..., P,\n1′w = 1,\nw ≥0,\nwhere w is the vector of weights to be computed, w is the average weight, ∥· ∥2 is the\nEuclidean norm (the square root of the sum of squares), xM=0,p is the covariate vector p of\nobservations without a missing value on y, and xM=1,p is the sample mean of covariate p\namong observations for which y is imputed. The tolerance parameter δp is typically set to a\nsmall value if not exactly 0. This weighting scheme balances the ﬁrst moment of the covariate\ndensities (the means). To balance higher-order moments one may include the appropriate\nterms. For example, to balance the second moment of xp (the variances) one includes x2\np.\nTo identify the diﬀerence between the (weighted) density of imputed and observed val-\nues, we suggest adopting four statistics that are widely used to assess balance between the\ntreatment and control groups in causal inference (Imbens and Rubin, 2015; Franklin et al.,\n2014). For all four metrics, smaller values suggest a higher similarity.\nThe standardized mean diﬀerence (SMD) is the diﬀerence between the means of the\ndensities for the imputed and observed values standardized by the square of their average\nvariance. The log variance ratio, log(VR), is the logarithm of the variance ratio. The SMD\nmeasures the diﬀerence in the densities’ locations, and the VR measures the diﬀerence in the\ndensities’ dispersion.\nThe SMD and VR measure the diﬀerences in the ﬁrst and second moments of two densities,\nwhereas the Kolmogorov—Smirnov (KS) statistic is also sensitive to deviations in higher\nmoments. The KS measures the largest discrepancy between the empirical and cumulative\ndistributions. It is best thought of as a measure of the largest dissimilarity between the\nimputed and observed values.\nA complementary statistic is the overlap (OVL) coeﬃcient. The OVL coeﬃcient measures\nlocal similarities instead of local discrepancies between two densities. Speciﬁcally, it is deﬁned\nas the proportion of the overlap between two densities. Typically, the diﬀerence 1-OVL is\nreported such that smaller values suggest a higher similarity.\nTo properly reﬂect uncertainty about the imputed values in any analysis, a series of\nimputed datasets are typically generated; each dataset is analyzed and the estimates are\n4\n\n\ncombined using Rubin’s rules (Rubin, 1987).\nThis procedure can also be applied to the\ndiscrepancy statistics introduced above. Users may average the discrepancy statistics across\nthe multiple imputed datasets or, alternatively, compare the densities of the balance statistics\ngraphically as illustrated below.\nIn practice, the covariates X might also include missing values. Adopting a multivariate\nversion of MAR (cf. Little and Rubin, 2019, p. 14), one typically imputes missing values\nin X jointly with missing values in Y . Therefore one can compute a weight such that the\nmoments of the ﬁlled-in covariate densities for observations with and without missing values\nin Y match.4 One concern with this strategy is that the multivariate version of MAR implies\nthat the joined density of missing values is equal to the joined density of observed values.\nYet, applying the suggested approach amounts to comparing the (full) conditional densities\nof Y alone rather than the joined densities. A more comprehensive assessment therefore\ninvolves the comparison of the conditional densities of Y and all covariates X one at a time.\nThat said, it would be desirable for future research to develop an approach that compares\nthe joined densities directly.\nILLUSTRATION WITH SIMULATED DATA\nIn this section, we use simulated data to demonstrate how the above approach can be used\nto assess which imputation model produces better imputed data (i.e., generates a density of\nimputed values more similar to the [reweighted] density of observed values) and that pooled\nregression estimates from models ﬁtted on better imputed data are also less biased.\nWe simulate 1,000 datasets (with N = 1, 000) from a linear model of the form y = x·z +e\nwith ﬁxed parameters. Covariate z is drawn from a Bernoulli distribution with mean 0.5 and\ncontinuous covariate x from a uniform distribution with range -5 to 5. We set the variance\nof the normal error distribution to 1 and let the proportion of missing values in y vary with\nz. The two proportions are drawn independently from a uniform distribution in the range of\n0.1 to 0.5. The larger value determines the proportion of missing values if z = 1 whereas the\nsmaller value determines the proportion of missing values if z = 0. The simulated missing\ndata mechanism is consistent with the i.i.d. and MAR assumptions.\nIterating over all simulated datasets, we impute the missing values ﬁve times using four\npopular imputation approaches implemented in the MICE software package (Van Buuren\nand Groothuis-Oudshoorn, 2011): predictive mean matching, random hot-deck imputation,\nnormal model imputation and random forest imputation. Predictive mean matching amounts\n4An alternative but limited strategy is to treat missingness as another category if X includes categorical\nvariables alone and compute the weight such that the moments of the binary indicators for each category\n(including the missing value category) for observations with and without missing values in Y match.\n5\n\n\nto measuring the distance between all observed values and a missing value using their pre-\ndicted values from a linear, additive regression model. Five observations with the smallest\ndistance are used to construct a donor candidate pool, from which one observation is drawn\nat random to impute the missing value.\nStandardized mean difference\nLog(Variance ratio)\nKolmogorov−Smirnov statistic\n1−Overlap coefficient\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\nFewer <−> more discrepancies\nA: Discrepancy statistics\n(Intercept)\nx\nz\nx:z\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\n−0.4\n−0.2\n0.0\n0.2\n0.4\nImputation approach\nTruth−Estimate\nB: Coefficient estimates\nFigure 1: Summary of 1,000 Monte Carlo simulations. Panel A: Box plots of four discrep-\nancy statistics comparing the weighted density of observed and imputed values. Panel B:\nBox plots of the bias in the (pooled) coeﬃcient estimates of a linear model y = x·z +ϵ. Each\ndataset was imputed ﬁve times using random hot-deck imputation (Hotdeck), random for-\nest imputation (RForest), predictive mean matching (PMM) and normal model imputation\n(Norm). Some box plots are clipped to increase readability.\n6\n\n\nRandom hot-deck imputation is similar to predictive mean matching but compares ob-\nservations’ covariate proﬁle using a (multivariate) distance function such as the Mahalanobis\ndistance. A random draw from the candidate pool of ﬁve observations is used to impute the\nmissing value. Normal model imputation uses the predicted values from a linear, additive\nregression model to impute the missing values.\nRandom forest imputation is typically encountered as a single imputation method (e.g.,\nStekhoven and B¨uhlmann, 2012), but an implementation for the multiple imputation context\nis also available (Doove et al., 2014). Random forest is an ensemble machine learning method\nbased on decision trees. Diﬀerent from the normal model imputation, it does not rely on a\nlinear, additive model and thus has the potential to accommodate more ﬂexible dependencies\nbetween variables.\nWe apply the diagnostic as described above and estimate the coeﬃcients of a linear\nregression model that includes an interaction term. Consistent with the multiple imputation\napproach, we estimate these linear regression models on each imputed dataset and average\nthe resulting coeﬃcient estimates.\nIn Figure 1 (Panel A), each box plot describes a distribution of a discrepancy statistic\n(averaged across ﬁve imputed datasets). Given the non-linear data generating process, we\nwould expect imputation approaches without linearity assumptions (hot-deck imputation and\nrandom forest imputation) to perform better. This is indeed what we ﬁnd: The discrepancy\nstatistics from these two imputation approaches are, on average, closer to zero, suggesting\nthat hock-deck imputation and random forest imputation produces better imputed data for\nthe simulated data generating process.\nThe diﬀerences between random hot-deck imputation and random forest imputation are\nless pronounced. While the standardized mean diﬀerences from random hot-deck imputation\nare closer to zero on average, we see fewer diﬀerences for the other three discrepancy statis-\ntics. However, altogether the discrepancy statistics suggest that random hot-deck imputation\nproduces better imputed data for the simulated data generating process.5\nFigure 1 (Panel B) shows the distribution of the bias (truth-estimate) in the (pooled)\ncoeﬃcient estimates for four linear regression terms across the simulations. As expected,\ncoeﬃcient estimates based on the better imputed data are, on average, less biased. When\nthe data are imputed by random hot-deck there is, on average, no bias left in either the main\neﬀects or the interaction eﬀect. When the data are imputed by the random forest, there is no\nbias left for the main eﬀects on average, but some bias remains in the interaction eﬀect. For\n5The longer tailed distribution for the log(VR) distribution might cast doubt on the superior performance of\nrandom hot-deck imputation (relative to random forest imputation). However, random hot-deck imputation\nalso does better in terms of the variance once we explicitly balance the second moment (the variance) of the\ncovariate densities (see Figure A.1).\n7\n\n\nthe normal model imputation and predictive mean matching, the bias remains substantial in\nboth the main eﬀect and interaction eﬀect.\nIMPUTING ANES\nTo illustrate the application of the suggested approach beyond simulated data, we use survey\ndata from the 2008 edition of the American National Election Studies (N = 2, 265). The\ndataset prepared by Kropko et al. (2014) includes 11 variables in diﬀerent scales with various\nlevels of missingness.\nTable 1 provides a description of the variables and the number of\nmissing values.\nVariable\nMissing\nDescription\nAge\n0\nAge of the respondent.\nSex\n0\nSex of the respondent.\nRace\n9\nNon-white vs. white.\nEducation\n0\nNo high school, some high school, high school diploma, college.\nIncome\n158\nLow, medium, high.\nReligion\n393\nProtestant, Catholic/Orthodox, Atheist/other.\nMarital status\n0\nSingle, married, no longer married.\nGov. support\n152\n7 response categories ranging from “Govt should let each person\nget ahead on own” to “Govt should see to jobs and standard of\nliving.”\nEnvironment\n23\nWhether the respondent sees the environment as an important\nissue (yes/no).\nVote\n258\nVote choice in the 2008 Presidential election: Obama, McCain,\nNo vote/Other.\nTime\n217\nTime for the respondent to complete the survey.\nTable 1: Summary of eleven variables from the 2008 American National Election Studies.\nWe impute the dataset using the four most popular imputation approaches for mixed-\ntype datasets again: predictive mean matching, random hot-deck imputation, random forest\nimputation and multivariate normal model imputation. We reply on the Amelia package\n(Honaker et al., 2011) for multivariate normal imputation and on the MICE package for\nthe other three approaches (Van Buuren and Groothuis-Oudshoorn, 2011). To simplify the\nanalysis, we consider “government support” as a continuous variable. We also log-transform\nthe variable “response time” before imputation.\nFor each variable with at least 25 imputed values, we construct weights that balance all\nother variables using the weighting scheme described previously. Figure 2 shows the density\n8\n\n\nof the discrepancy statistics across 100 imputed datasets. As the mean of a binary variable is\na suﬃcient statistic, we only provide the standardized mean diﬀerence for all binary variables.\nStandardized mean difference\nIncome\nReligion\nVote\n0.00 0.05 0.10 0.15 0.20 0.25\nHigh income\nLow income\nMedium income\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nHotdeck\nPMM\nRForest\nNorm\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.00\n0.05\n0.10\n0.15\n0.20\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure 2: Box plots of discrepancy statistics comparing the weighted density of observed\nand imputed values across 100 imputed datasets. Some outliers are removed, and some upper\nwhiskers are clipped to increase readability.\nWe observe the largest discrepancies in the standardized mean diﬀerences for two of the\nthree categories of the variable “religion.” The density of the standardized mean diﬀerence\nfor the multivariate normal imputation and random forest are both bounded away from zero\nand are distinct from the density of the two other approaches. We observe similar yet less\n9\n\n\npronounced diﬀerences for the variable “vote” and “government support.” For two continuous\nvariables we observe a similar pattern for the OVL coeﬃcient and KS statistic; hot-deck and\npredictive mean matching imputation both do much better than the other two approaches.\nAll four approaches are similar in terms of the variance ratio.\nThe hot-deck and predictive mean imputation performances are fairly similar across vari-\nables and discrepancy statistics. Table 2 demonstrates that predictive mean matching does a\nlittle better than hot-deck imputation when averaging across imputed datasets and variables.\nBased on these averages one may recommend using predictive mean matching as it produces\nimputed values that are more consistent with the MAR assumption on average across all vari-\nables. Alternatively, one may use the results to revise the imputation model. MICE relies on\nchained univariate imputation models which means that it is easy to use diﬀerent imputation\napproaches for diﬀerent variables and we could therefore select predictive mean matching for\nsome variables and hot-deck imputation for others, depending on their performance.\nDiscrepancy statistics\nSMD\nlog(VR)\nKS\n1-OVL\nPMM\n0.053\n0.077\n0.029\n0.028\nHotdeck\n0.058\n0.085\n0.031\n0.030\nNorm\n0.100\n0.082\n0.061\n0.061\nRForest\n0.125\n0.079\n0.059\n0.057\nTable 2: Average discrepancy statistics across variables and imputed datasets for predictive\nmean matching imputation (PMM), random hot-deck imputation (Hotdeck), multivariate\nnormal imputation (Norm) and random forest imputation (RForest). The four displayed\ndiscrepancy statistics include standardized mean diﬀerence (SMD), variance ratio (VR),\nKolmogorov—Smirnov statistic (KS) and overlap coeﬃcient (1-OVL).\nThe diﬀerential performance of the four imputation approaches cannot be explained by\nthe diﬀerential performance of the constructed weights. In the appendix (Figure A.2–A.6),\nwe document that the constructed weights balance the ﬁrst moment of the densities exactly\n(as expected). Some moderate imbalances are left for the higher moments of the continuous\nvariables. In principle, these could be removed by adding, for example, the variables squared\nand cubed to the weighting scheme. However, because these higher-moment imbalances are\nlargely not diﬀerential between the four imputation approaches, they cannot explain the\ndiﬀerential performance.\nOne concern with the analysis might be that higher-order interactions are not explicitly\nbalanced.\nFor example, while the weights ensure that the proportions of Obama voters\nand of women among respondents with and without missing values on the variable religion\nare identical, they do not guarantee that the proportions of women voting for Obama are\n10\n\n\nidentical. To evaluate the sensitivity of the results to the inclusion of some higher-order\ninteractions, we replicate the analysis balancing the interactions of the demographic variables\n(gender, age, and race) with all other variables. The results, which appear in Figure A.7, are\nlargely identical to those in Figure 2.\nCONCLUSION\nIncomplete data is a common challenge when analyzing real-world data. Another challenge\nis choosing from many available multiple imputation approaches to ﬁll-in the missing values.\nWhile some approaches are more popular than others, the literature oﬀers little advice on\nhow to choose among them for a given dataset.\nIn the absence of such advice, list-wise\ndeletion remains a popular default approach despite its known deﬁcits. And even if multiple\nimputation is used in applied work, it is common practice to rely on the (currently) most\npopular approach in the literature (cf. Lall, 2016) which may or may not be optimal for a\ngiven dataset.\nThis letter provides a conceptually simple and practical approach to choosing between\ncompeting imputation models that impute data under MAR. The approach is ﬂexible and\ndoes not have to be tailored to a particular imputation model; all it needs is the data with\nthe missing values and the ﬁlled-in dataset. It builds on the same assumptions made by most\nmultiple imputation models, in particular the MAR assumption. While more work is needed\nto understand how to choose between imputation models when the data are missing not at\nrandom (MNAR), we hope that this letter, in conjunction with the accompanying, easy-\nto-use software package in R, prompts users to make explicit comparisons between diﬀerent\nimputation models for their dataset and to choose the one that imputes values most consistent\nwith MAR.\nWe also hope that this contribution lowers the barriers faced by applied researchers trying\nto address missing data in their data analysis and therefore reduces the reliance on list-wise\ndeletion which always leads to ineﬃcient estimates but typically also introduces bias. More\ngenerally, our approach highlights how weighting and imputation approaches, often seen as\nalternative strategies to handle missing data, can be combined in a productive manner. While\nwe are not the ﬁrst to combine both—for example, Seaman et al. (2012) combine multiple\nimputations with weighting to achieve double robustness—the combination of weighting and\nimputation appears to be a fruitful avenue for future research.\n11\n\n\nREFERENCES\nAbayomi, K., A. Gelman, and M. Levy (2008). Diagnostics for Multivariate Imputations.\nJournal of the Royal Statistical Society. Series C 57(3), 273–291.\nAndridge, R. R. and R. J. Little (2010). A Review Of Hot Deck Imputation For Survey\nNon-response. International Statistical Review 78(1), 40–64.\nBondarenko, I. and T. Raghunathan (2016).\nGraphical and Numerical Diagnostic Tools\nto Assess Suitability of Multiple Imputations and Imputation Models.\nStatistics in\nMedicine 35(17), 3007–3020.\nCranmer, S. J. and J. Gill (2013). We Have to Be Discrete About This: A Non-Parametric\nImputation Technique for Missing Categorical Data.\nBritish Journal of Political Sci-\nence 43(2), 425–449.\nDoove, L. L., S. Van Buuren, and E. Dusseldorp (2014). Recursive Partitioning for Missing\nData Imputation in the Presence of Interaction Eﬀects. Computational Statistics & Data\nAnalysis 72, 92–104.\nFranklin, J. M., J. A. Rassen, D. Ackermann, D. B. Bartels, and S. Schneeweiss (2014).\nMetrics for Covariate Balance in Cohort Studies Of Causal Eﬀects.\nStatistics in\nMedicine 33(10), 1685–1699.\nHainmueller, J. (2012). Entropy Balancing for Causal Eﬀects: A Multivariate Reweighting\nMethod to Produce Balanced Samples In Observational Studies. Political Analysis 20(1),\n25–46.\nHonaker, J., G. King, and M. Blackwell (2011). Amelia II: A Program for Missing Data.\nJournal of Statistical Software 45(7), 1–47.\nImbens, G. W. and D. B. Rubin (2015). Causal Inference in Statistics, Social, and Biomedical\nSciences: An Introduction. Cambridge: Cambridge University Press.\nKing, G., J. Honaker, A. Joseph, and K. Scheve (2001).\nAnalyzing Incomplete Political\nScience Data: An Alternative Algorithm for Multiple Imputation.\nAmerican Political\nScience Review 95(1), 49–69.\nKropko, J., B. Goodrich, A. Gelman, and J. Hill (2014). Multiple Imputation for Continuous\nand Categorical Data: Comparing Joint Multivariate Normal And Conditional Approaches.\nPolitical Analysis 22(4), 497–519.\n12\n\n\nLall, R. (2016). How Multiple Imputation Makes a Diﬀerence. Political Analysis 24(4),\n414–433.\nLittle, R. J. (1988). Missing-data Adjustments in Large Surveys. Journal of Business &\nEconomic Statistics 6(3), 287–296.\nLittle, R. J. A. and D. B. Rubin (2019). Statistical Analysis with Missing Data (Third Edition\ned.). New York: Wiley.\nMealli, F. and D. B. Rubin (2015). Clarifying Missing at Random and Related Deﬁnitions,\nand Implications When Coupled With Exchangeability. Biometrika 102(4), 995–1000.\nRubin, D. B. (1976). Inference and Missing Data. Biometrika 63(3), 581–592.\nRubin, D. B. (1987). Multiple Imputation for Nonresponse in Surveys. New York: J. Wiley\n& Sons.\nRubin, D. B. (1996). Multiple Imputation After 18+ Years. Journal of the American Statis-\ntical Association 91(434), 473–489.\nSchafer, J. L. (1997). Analysis of Incomplete Multivariate Data. Boca Raton: Chapman and\nHall.\nSeaman, S. R., I. R. White, A. J. Copas, and L. Li (2012). Combining Multiple Imputation\nand Inverse-Probability Weighting. Biometrics 68(1), 129–137.\nStekhoven, D. J. and P. B¨uhlmann (2012). MissForest—Non-parametric Missing Value Im-\nputation for Mixed-Type Data. Bioinformatics 28(1), 112–118.\nVan Buuren, S. (2007).\nMultiple Imputation of Discrete and Continuous Data by Fully\nConditional Speciﬁcation. Statistical Methods in Medical Research 16(3), 219–242.\nVan Buuren, S. (2018). Flexible Imputation of Missing Data. Chapman & Hall.\nVan Buuren, S., J. P. Brand, C. G. Groothuis-Oudshoorn, and D. B. Rubin (2006). Fully\nConditional Speciﬁcation in Multivariate Imputation. Journal of Statistical Computation\nand Simulation 76(12), 1049–1064.\nVan Buuren, S. and K. Groothuis-Oudshoorn (2011).\nmice: Multivariate Imputation by\nChained Equations in R. Journal of Statistical Software 45(3), 1–67.\nZubizarreta, J. R. (2015). Stable Weights That Balance Covariates for Estimation With\nIncomplete Outcome Data.\nJournal of the American Statistical Association 110(511),\n910–922.\n13\n\n\nSupplementary Information\nAppendix A\nADDITIONAL FIGURES\n14\n\n\nStandardized mean difference\nLog(Variance ratio)\nKolmogorov−Smirnov statistic\n1−Overlap coefficient\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\nFewer <−> more discrepancies\nA: Discrepancy statistics\n(Intercept)\nx\nz\nx:z\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\nHotdeck\nRForest\nPMM\nNorm\n−0.4\n−0.2\n0.0\n0.2\n0.4\nImputation approach\nTruth−Estimate\nB: Coefficient estimates\nFigure A.1: Summary of 1,000 Monte Carlo simulations. Panel A: Box plots of four dis-\ncrepancy statistics comparing the weighted density of observed and imputed values. Weights\nare constructed to balance the ﬁrst and second moment of the covariate densities. Panel B:\nBox plots of the bias in the (pooled) coeﬃcient estimates of a linear model y = x·z +ϵ. Each\ndataset was imputed ﬁve times using random hot-deck imputation (Hotdeck), random for-\nest imputation (RForest), predictive mean matching (PMM) and normal model imputation\n(Norm). Some box plots are clipped to increase readability.\n15\n\n\nStandard. mean diff.\nEducation\nMarital st.\nReligion\nVote\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nMarried\nNo longer married\nSingle\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.2: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable income across 100 imputed datasets.\nSome outliers are\nremoved, and some upper whiskers are clipped to increase readability.\n16\n\n\nStandard. mean diff.\nEducation\nIncome\nMarital st.\nReligion\nVote\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nHigh income\nLow income\nMedium income\nMarried\nNo longer married\nSingle\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nResponse\ntime\nAge\nResponse\ntime\nAge\nResponse\ntime\nAge\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.3: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable government support across 100 imputed datasets. Some\noutliers are removed, and some upper whiskers are clipped to increase readability.\n17\n\n\nStandard. mean diff.\nEducation\nIncome\nMarital st.\nVote\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nHigh income\nLow income\nMedium income\nMarried\nNo longer married\nSingle\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.4: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable religion across 100 imputed datasets.\nSome outliers are\nremoved, and some upper whiskers are clipped to increase readability.\n18\n\n\nStandard. mean diff.\nEducation\nIncome\nMarital st.\nReligion\nVote\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nHigh income\nLow income\nMedium income\nMarried\nNo longer married\nSingle\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nGovernment\nsuport\nAge\nGovernment\nsuport\nAge\nGovernment\nsuport\nAge\nGovernment\nsuport\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.5: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable response time across 100 imputed datasets. Some outliers\nare removed, and some upper whiskers are clipped to increase readability.\n19\n\n\nStandard. mean diff.\nEducation\nIncome\nMarital st.\nReligion\n0.0\n0.1\n0.2\n0.3\nEnvironment important\nFemale\nWhite\nCollege degree and higher\nHS and maybe some college\nNo high school\nSome high school\nHigh income\nLow income\nMedium income\nMarried\nNo longer married\nSingle\nAtheist/Other\nCatholic/Orthodox\nProtestant\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.0\n0.1\n0.2\n0.3\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nAge\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.6: Density of discrepancy statistics comparing observations with imputed and\nobserved values of the variable vote across 100 imputed datasets. Some outliers are removed,\nand some upper whiskers are clipped to increase readability.\n20\n\n\nStandardized mean difference\nIncome\nReligion\nVote\n0.00 0.05 0.10 0.15 0.20 0.25\nHigh income\nLow income\nMedium income\nAtheist/Other\nCatholic/Orthodox\nProtestant\nMcCain\nNo vote/Other\nObama\nFewer <−> more discrepancies\nA: Binary variables\nLog(Variance ratio)\n1−Overlap coefficient\nKolmogorov−Smirnov statistic\nStandardized mean difference\n0.00\n0.05\n0.10\n0.15\n0.20\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nGovernment\nsuport\nResponse\ntime\nFewer <−> more discrepancies\nB: Continuous variables\nImputation model:\nHotdeck\nPMM\nRForest\nNorm\nFigure A.7: Additional balancing of interactions. Box plots of discrepancy statistics\ncomparing the weighted density of observed and imputed values across 100 imputed datasets.\nSome outliers are removed, and some upper whiskers are clipped to increase readability.\n21\n"
}