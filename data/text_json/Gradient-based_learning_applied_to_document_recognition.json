{
  "filename": "Gradient-based_learning_applied_to_document_recognition.pdf",
  "num_pages": 47,
  "pages": [
    "Gradient-Based Learning Applied\nto Document Recognition\nYANN LECUN, MEMBER, IEEE, L´EON BOTTOU, YOSHUA BENGIO, AND PATRICK HAFFNER\nInvited Paper\nMultilayer neural networks trained with the back-propagation\nalgorithm constitute the best example of a successful gradient-\nbased\nlearning\ntechnique.\nGiven\nan\nappropriate\nnetwork\narchitecture, gradient-based learning algorithms can be used\nto synthesize a complex decision surface that can classify\nhigh-dimensional patterns, such as handwritten characters, with\nminimal preprocessing. This paper reviews various methods\napplied to handwritten character recognition and compares them\non a standard handwritten digit recognition task. Convolutional\nneural networks, which are speciﬁcally designed to deal with\nthe variability of two dimensional (2-D) shapes, are shown to\noutperform all other techniques.\nReal-life document recognition systems are composed of multiple\nmodules including ﬁeld extraction, segmentation, recognition,\nand language modeling. A new learning paradigm, called graph\ntransformer networks (GTN’s), allows such multimodule systems\nto be trained globally using gradient-based methods so as to\nminimize an overall performance measure.\nTwo systems for online handwriting recognition are described.\nExperiments demonstrate the advantage of global training, and\nthe ﬂexibility of graph transformer networks.\nA graph transformer network for reading a bank check is\nalso described. It uses convolutional neural network character\nrecognizers combined with global training techniques to provide\nrecord accuracy on business and personal checks. It is deployed\ncommercially and reads several million checks per day.\nKeywords— Convolutional neural networks, document recog-\nnition, ﬁnite state transducers, gradient-based learning, graph\ntransformer networks, machine learning, neural networks, optical\ncharacter recognition (OCR).\nNOMENCLATURE\nGT\nGraph transformer.\nGTN\nGraph transformer network.\nHMM\nHidden Markov model.\nHOS\nHeuristic oversegmentation.\nK-NN\nK-nearest neighbor.\nManuscript received November 1, 1997; revised April 17, 1998.\nY. LeCun, L. Bottou, and P. Haffner are with the Speech and Image\nProcessing Services Research Laboratory, AT&T Labs-Research, Red\nBank, NJ 07701 USA.\nY. Bengio is with the D´epartement d’Informatique et de Recherche\nOp´erationelle, Universit´e de Montr´eal, Montr´eal, Qu´ebec H3C 3J7 Canada.\nPublisher Item Identiﬁer S 0018-9219(98)07863-3.\nNN\nNeural network.\nOCR\nOptical character recognition.\nPCA\nPrincipal component analysis.\nRBF\nRadial basis function.\nRS-SVM\nReduced-set support vector method.\nSDNN\nSpace displacement neural network.\nSVM\nSupport vector method.\nTDNN\nTime delay neural network.\nV-SVM\nVirtual support vector method.\nI.\nINTRODUCTION\nOver the last several years, machine learning techniques,\nparticularly when applied to NN’s, have played an increas-\ningly important role in the design of pattern recognition\nsystems. In fact, it could be argued that the availability\nof learning techniques has been a crucial factor in the\nrecent success of pattern recognition applications such as\ncontinuous speech recognition and handwriting recognition.\nThe main message of this paper is that better pattern\nrecognition systems can be built by relying more on auto-\nmatic learning and less on hand-designed heuristics. This\nis made possible by recent progress in machine learning\nand computer technology. Using character recognition as a\ncase study, we show that hand-crafted feature extraction can\nbe advantageously replaced by carefully designed learning\nmachines that operate directly on pixel images. Using\ndocument understanding as a case study, we show that the\ntraditional way of building recognition systems by manually\nintegrating individually designed modules can be replaced\nby a uniﬁed and well-principled design paradigm, called\nGTN’s, which allows training all the modules to optimize\na global performance criterion.\nSince the early days of pattern recognition it has been\nknown that the variability and richness of natural data,\nbe it speech, glyphs, or other types of patterns, make it\nalmost impossible to build an accurate recognition system\nentirely by hand. Consequently, most pattern recognition\nsystems are built using a combination of automatic learning\ntechniques and hand-crafted algorithms. The usual method\n0018–9219/98$10.00 1998 IEEE\n2278\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 1.\nTraditional pattern recognition is performed with two\nmodules: a ﬁxed feature extractor and a trainable classiﬁer.\nof recognizing individual patterns consists in dividing the\nsystem into two main modules shown in Fig. 1. The ﬁrst\nmodule, called the feature extractor, transforms the input\npatterns so that they can be represented by low-dimensional\nvectors or short strings of symbols that: 1) can be easily\nmatched or compared and 2) are relatively invariant with\nrespect to transformations and distortions of the input pat-\nterns that do not change their nature. The feature extractor\ncontains most of the prior knowledge and is rather speciﬁc\nto the task. It is also the focus of most of the design effort,\nbecause it is often entirely hand crafted. The classiﬁer,\non the other hand, is often general purpose and trainable.\nOne of the main problems with this approach is that the\nrecognition accuracy is largely determined by the ability of\nthe designer to come up with an appropriate set of features.\nThis turns out to be a daunting task which, unfortunately,\nmust be redone for each new problem. A large amount of\nthe pattern recognition literature is devoted to describing\nand comparing the relative merits of different feature sets\nfor particular tasks.\nHistorically, the need for appropriate feature extractors\nwas due to the fact that the learning techniques used\nby the classiﬁers were limited to low-dimensional spaces\nwith easily separable classes [1]. A combination of three\nfactors has changed this vision over the last decade. First,\nthe availability of low-cost machines with fast arithmetic\nunits allows for reliance on more brute-force “numerical”\nmethods than on algorithmic reﬁnements. Second, the avail-\nability of large databases for problems with a large market\nand wide interest, such as handwriting recognition, has\nenabled designers to rely more on real data and less on\nhand-crafted feature extraction to build recognition systems.\nThe third and very important factor is the availability\nof powerful machine learning techniques that can handle\nhigh-dimensional inputs and can generate intricate decision\nfunctions when fed with these large data sets. It can be\nargued that the recent progress in the accuracy of speech\nand handwriting recognition systems can be attributed in\nlarge part to an increased reliance on learning techniques\nand large training data sets. As evidence of this fact, a large\nproportion of modern commercial OCR systems use some\nform of multilayer NN trained with back propagation.\nIn this study, we consider the tasks of handwritten\ncharacter recognition (Sections I and II) and compare the\nperformance of several learning techniques on a benchmark\ndata set for handwritten digit recognition (Section III).\nWhile more automatic learning is beneﬁcial, no learning\ntechnique can succeed without a minimal amount of prior\nknowledge about the task. In the case of multilayer NN’s,\na good way to incorporate knowledge is to tailor its archi-\ntecture to the task. Convolutional NN’s [2], introduced in\nSection II, are an example of specialized NN architectures\nwhich incorporate knowledge about the invariances of two-\ndimensional (2-D) shapes by using local connection patterns\nand by imposing constraints on the weights. A comparison\nof several methods for isolated handwritten digit recogni-\ntion is presented in Section III. To go from the recognition\nof individual characters to the recognition of words and\nsentences in documents, the idea of combining multiple\nmodules trained to reduce the overall error is introduced\nin Section IV. Recognizing variable-length objects such as\nhandwritten words using multimodule systems is best done\nif the modules manipulate directed graphs. This leads to the\nconcept of trainable GTN, also introduced in Section IV.\nSection V describes the now classical method of HOS for\nrecognizing words or other character strings. Discriminative\nand nondiscriminative gradient-based techniques for train-\ning a recognizer at the word level without requiring manual\nsegmentation and labeling are presented in Section VI.\nSection VII presents the promising space-displacement NN\napproach that eliminates the need for segmentation heuris-\ntics by scanning a recognizer at all possible locations on\nthe input. In Section VIII, it is shown that trainable GTN’s\ncan be formulated as multiple generalized transductions\nbased on a general graph composition algorithm. The\nconnections between GTN’s and HMM’s, commonly used\nin speech recognition, is also treated. Section IX describes\na globally trained GTN system for recognizing handwriting\nentered in a pen computer. This problem is known as\n“online” handwriting recognition since the machine must\nproduce immediate feedback as the user writes. The core\nof the system is a convolutional NN. The results clearly\ndemonstrate the advantages of training a recognizer at\nthe word level, rather than training it on presegmented,\nhand-labeled, isolated characters. Section X describes a\ncomplete GTN-based system for reading handwritten and\nmachine-printed bank checks. The core of the system is\nthe convolutional NN called LeNet-5, which is described\nin Section II. This system is in commercial use in the\nNCR Corporation line of check recognition systems for the\nbanking industry. It is reading millions of checks per month\nin several banks across the United States.\nA. Learning from Data\nThere are several approaches to automatic machine learn-\ning, but one of the most successful approaches, popularized\nin recent years by the NN community, can be called “nu-\nmerical” or gradient-based learning. The learning machine\ncomputes a function\nwhere\nis the\nth\ninput pattern, and\nrepresents the collection of adjustable\nparameters in the system. In a pattern recognition setting,\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2279\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "the output\nmay be interpreted as the recognized class\nlabel of pattern\nor as scores or probabilities associated\nwith each class. A loss function\nmeasures the discrepancy between\nthe “correct” or\ndesired output for pattern\nand the output produced by\nthe system. The average loss function\nis the\naverage of the errors\nover a set of labeled examples\ncalled the training set\nIn the\nsimplest setting, the learning problem consists in ﬁnding\nthe value of\nthat minimizes\nIn practice,\nthe performance of the system on a training set is of little\ninterest. The more relevant measure is the error rate of the\nsystem in the ﬁeld, where it would be used in practice.\nThis performance is estimated by measuring the accuracy\non a set of samples disjoint from the training set, which is\ncalled the test set. Much theoretical and experimental work\n[3]–[5] has shown that the gap between the expected error\nrate on the test set\nand the error rate on the training\nset\ndecreases with the number of training samples\napproximately as\n(1)\nwhere\nis the number of training samples,\nis a measure\nof “effective capacity” or complexity of the machine [6],\n[7],\nis a number between 0.5 and 1.0, and\nis a constant.\nThis gap always decreases when the number of training\nsamples increases. Furthermore, as the capacity\nincreases,\ndecreases. Therefore, when increasing the capacity\nthere is a tradeoff between the decrease of\nand the\nincrease of the gap, with an optimal value of the capacity\nthat achieves the lowest generalization error\nMost\nlearning algorithms attempt to minimize\nas well as\nsome estimate of the gap. A formal version of this is called\nstructural risk minimization [6], [7], and it is based on deﬁn-\ning a sequence of learning machines of increasing capacity,\ncorresponding to a sequence of subsets of the parameter\nspace such that each subset is a superset of the previous\nsubset. In practical terms, structural risk minimization is\nimplemented by minimizing\nwhere the\nfunction\nis called a regularization function and\nis\na constant.\nis chosen such that it takes large values\non parameters\nthat belong to high-capacity subsets of\nthe parameter space. Minimizing\nin effect limits the\ncapacity of the accessible subset of the parameter space,\nthereby controlling the tradeoff between minimizing the\ntraining error and minimizing the expected gap between\nthe training error and test error.\nB. Gradient-Based Learning\nThe general problem of minimizing a function with\nrespect to a set of parameters is at the root of many\nissues in computer science. Gradient-based learning draws\non the fact that it is generally much easier to minimize\na reasonably smooth, continuous function than a discrete\n(combinatorial) function. The loss function can be mini-\nmized by estimating the impact of small variations of the\nparameter values on the loss function. This is measured\nby the gradient of the loss function with respect to the\nparameters. Efﬁcient learning algorithms can be devised\nwhen the gradient vector can be computed analytically (as\nopposed to numerically through perturbations). This is the\nbasis of numerous gradient-based learning algorithms with\ncontinuous-valued parameters. In the procedures described\nin this article, the set of parameters\nis a real-valued\nvector, with respect to which\nis continuous, as well\nas differentiable almost everywhere. The simplest mini-\nmization procedure in such a setting is the gradient descent\nalgorithm where\nis iteratively adjusted as follows:\n(2)\nIn the simplest case,\nis a scalar constant. More sophis-\nticated procedures use variable\nor substitute it for a\ndiagonal matrix, or substitute it for an estimate of the\ninverse Hessian matrix as in Newton or quasi-Newton\nmethods. The conjugate gradient method [8] can also be\nused. However, Appendix B shows that despite many\nclaims to the contrary in the literature, the usefulness of\nthese second-order methods to large learning machines is\nvery limited.\nA popular minimization procedure is the stochastic gra-\ndient algorithm, also called the online update. It consists\nin updating the parameter vector using a noisy, or approxi-\nmated, version of the average gradient. In the most common\ninstance of it,\nis updated on the basis of a single sample\n(3)\nWith this procedure the parameter vector ﬂuctuates around\nan average trajectory, but usually it converges considerably\nfaster than regular gradient descent and second-order meth-\nods on large training sets with redundant samples (such\nas those encountered in speech or character recognition).\nThe reasons for this are explained in Appendix B. The\nproperties of such algorithms applied to learning have been\nstudied theoretically since the 1960’s [9]–[11], but practical\nsuccesses for nontrivial tasks did not occur until the mid\neighties.\nC. Gradient Back Propagation\nGradient-based learning procedures have been used since\nthe late 1950’s, but they were mostly limited to linear\nsystems [1]. The surprising usefulness of such simple\ngradient descent techniques for complex machine learning\ntasks was not widely realized until the following three\nevents occurred. The ﬁrst event was the realization that,\ndespite early warnings to the contrary [12], the presence of\nlocal minima in the loss function does not seem to be a\nmajor problem in practice. This became apparent when it\nwas noticed that local minima did not seem to be a major\nimpediment to the success of early nonlinear gradient-based\nlearning techniques such as Boltzmann machines [13], [14].\nThe second event was the popularization by Rumelhart et\nal. [15] and others of a simple and efﬁcient procedure\nto compute the gradient in a nonlinear system composed\n2280\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "of several layers of processing, i.e., the back-propagation\nalgorithm. The third event was the demonstration that the\nback-propagation procedure applied to multilayer NN’s\nwith sigmoidal units can solve complicated learning tasks.\nThe basic idea of back propagation is that gradients can\nbe computed efﬁciently by propagation from the output to\nthe input. This idea was described in the control theory\nliterature of the early 1960’s [16], but its application to ma-\nchine learning was not generally realized then. Interestingly,\nthe early derivations of back propagation in the context\nof NN learning did not use gradients but “virtual targets”\nfor units in intermediate layers [17], [18], or minimal\ndisturbance arguments [19]. The Lagrange formalism used\nin the control theory literature provides perhaps the best\nrigorous method for deriving back propagation [20] and for\nderiving generalizations of back propagation to recurrent\nnetworks [21] and networks of heterogeneous modules [22].\nA simple derivation for generic multilayer systems is given\nin Section I-E.\nThe fact that local minima do not seem to be a problem\nfor multilayer NN’s is somewhat of a theoretical mystery.\nIt is conjectured that if the network is oversized for the\ntask (as is usually the case in practice), the presence of\n“extra dimensions” in parameter space reduces the risk\nof unattainable regions. Back propagation is by far the\nmost widely used neural-network learning algorithm, and\nprobably the most widely used learning algorithm of any\nform.\nD. Learning in Real Handwriting Recognition Systems\nIsolated handwritten character recognition has been ex-\ntensively studied in the literature (see [23] and [24] for\nreviews), and it was one of the early successful applications\nof NN’s [25]. Comparative experiments on recognition of\nindividual handwritten digits are reported in Section III.\nThey show that NN’s trained with gradient-based learning\nperform better than all other methods tested here on the\nsame data. The best NN’s, called convolutional networks,\nare designed to learn to extract relevant features directly\nfrom pixel images (see Section II).\nOne of the most difﬁcult problems in handwriting recog-\nnition, however, is not only to recognize individual charac-\nters, but also to separate out characters from their neighbors\nwithin the word or sentence, a process known as seg-\nmentation. The technique for doing this that has become\nthe “standard” is called HOS. It consists of generating a\nlarge number of potential cuts between characters using\nheuristic image processing techniques, and subsequently\nselecting the best combination of cuts based on scores\ngiven for each candidate character by the recognizer. In\nsuch a model, the accuracy of the system depends upon the\nquality of the cuts generated by the heuristics, and on the\nability of the recognizer to distinguish correctly segmented\ncharacters from pieces of characters, multiple characters,\nor otherwise incorrectly segmented characters. Training a\nrecognizer to perform this task poses a major challenge\nbecause of the difﬁculty in creating a labeled database\nof incorrectly segmented characters. The simplest solution\nconsists of running the images of character strings through\nthe segmenter and then manually labeling all the character\nhypotheses. Unfortunately, not only is this an extremely\ntedious and costly task, it is also difﬁcult to do the labeling\nconsistently. For example, should the right half of a cut-up\nfour be labeled as a one or as a noncharacter? Should the\nright half of a cut-up eight be labeled as a three?\nThe ﬁrst solution, described in Section V, consists of\ntraining the system at the level of whole strings of char-\nacters rather than at the character level. The notion of\ngradient-based learning can be used for this purpose. The\nsystem is trained to minimize an overall loss function which\nmeasures the probability of an erroneous answer. Section V\nexplores various ways to ensure that the loss function\nis differentiable and therefore lends itself to the use of\ngradient-based learning methods. Section V introduces the\nuse of directed acyclic graphs whose arcs carry numerical\ninformation as a way to represent the alternative hypotheses\nand introduces the idea of GTN.\nThe second solution, described in Section VII, is to\neliminate segmentation altogether. The idea is to sweep\nthe recognizer over every possible location on the input\nimage, and to rely on the “character spotting” property\nof the recognizer, i.e., its ability to correctly recognize\na well-centered character in its input ﬁeld, even in the\npresence of other characters besides it, while rejecting\nimages containing no centered characters [26], [27]. The\nsequence of recognizer outputs obtained by sweeping the\nrecognizer over the input is then fed to a GTN that takes\nlinguistic constraints into account and ﬁnally extracts the\nmost likely interpretation. This GTN is somewhat similar\nto HMM’s, which makes the approach reminiscent of the\nclassical speech recognition [28], [29]. While this technique\nwould be quite expensive in the general case, the use of\nconvolutional NN’s makes it particularly attractive because\nit allows signiﬁcant savings in computational cost.\nE. Globally Trainable Systems\nAs stated earlier, most practical pattern recognition sys-\ntems are composed of multiple modules. For example, a\ndocument recognition system is composed of a ﬁeld loca-\ntor (which extracts regions of interest), a ﬁeld segmenter\n(which cuts the input image into images of candidate\ncharacters), a recognizer (which classiﬁes and scores each\ncandidate character), and a contextual postprocessor, gen-\nerally based on a stochastic grammar (which selects the\nbest grammatically correct answer from the hypotheses\ngenerated by the recognizer). In most cases, the information\ncarried from module to module is best represented as\ngraphs with numerical information attached to the arcs.\nFor example, the output of the recognizer module can be\nrepresented as an acyclic graph where each arc contains the\nlabel and the score of a candidate character, and where each\npath represents an alternative interpretation of the input\nstring. Typically, each module is manually optimized, or\nsometimes trained, outside of its context. For example, the\ncharacter recognizer would be trained on labeled images\nof presegmented characters. Then the complete system is\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2281\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "assembled, and a subset of the parameters of the modules\nis manually adjusted to maximize the overall performance.\nThis last step is extremely tedious, time consuming, and\nalmost certainly suboptimal.\nA better alternative would be to somehow train the entire\nsystem so as to minimize a global error measure such\nas the probability of character misclassiﬁcations at the\ndocument level. Ideally, we would want to ﬁnd a good\nminimum of this global loss function with respect to all the\nparameters in the system. If the loss function\nmeasuring\nthe performance can be made differentiable with respect\nto the system’s tunable parameters\nwe can ﬁnd a local\nminimum of\nusing gradient-based learning. However, at\nﬁrst glance, it appears that the sheer size and complexity\nof the system would make this intractable.\nTo ensure that the global loss function\nis\ndifferentiable, the overall system is built as a feedforward\nnetwork of differentiable modules. The function imple-\nmented by each module must be continuous and differ-\nentiable almost everywhere with respect to the internal\nparameters of the module (e.g., the weights of an NN\ncharacter recognizer in the case of a character recognition\nmodule), and with respect to the module’s inputs. If this is\nthe case, a simple generalization of the well-known back-\npropagation procedure can be used to efﬁciently compute\nthe gradients of the loss function with respect to all the\nparameters in the system [22]. For example, let us consider\na system built as a cascade of modules, each of which\nimplements a function\nwhere\nis a vector representing the output of the module,\nis\nthe vector of tunable parameters in the module (a subset of\nand\nis the module’s input vector (as well as the\nprevious module’s output vector). The input\nto the ﬁrst\nmodule is the input pattern\nIf the partial derivative of\nwith respect to\nis known, then the partial derivatives\nof\nwith respect to\nand\ncan be computed using\nthe backward recurrence\n(4)\nwhere\nis the Jacobian of\nwith\nrespect to\nevaluated at the point\nand\nis the Jacobian of\nwith respect to\nThe Jacobian of a vector function is a matrix containing\nthe partial derivatives of all the outputs with respect to\nall the inputs. The ﬁrst equation computes some terms\nof the gradient of\nwhile the second equation\ngenerates a backward recurrence, as in the well-known\nback-propagation procedure for NN’s. We can average\nthe gradients over the training patterns to obtain the full\ngradient. It is interesting to note that in many instances\nthere is no need to explicitly compute the Jacobian ma-\ntrix. The above formula uses the product of the Jacobian\nwith a vector of partial derivatives, and it is often easier\nto compute this product directly without computing the\nJacobian beforehand. In analogy with ordinary multilayer\nNN’s, all but the last module are called hidden layers\nbecause their outputs are not observable from the outside.\nIn more complex situations than the simple cascade of\nmodules described above, the partial derivative notation\nbecomes somewhat ambiguous and awkward. A completely\nrigorous derivation in more general cases can be done using\nLagrange functions [20]–[22].\nTraditional multilayer NN’s are a special case of the\nabove where the state information\nis represented\nwith ﬁxed-sized vectors, and where the modules are\nalternated layers of matrix multiplications (the weights)\nand component-wise sigmoid functions (the neurons).\nHowever, as stated earlier, the state information in complex\nrecognition system is best represented by graphs with\nnumerical information attached to the arcs. In this case,\neach module, called a GT, takes one or more graphs as input\nand produces a graph as output. Networks of such modules\nare called GTN’s. Sections IV, VI, and VIII develop the\nconcept of GTN’s and show that gradient-based learning\ncan be used to train all the parameters in all the modules\nso as to minimize a global loss function. It may seem\nparadoxical that gradients can be computed when the state\ninformation is represented by essentially discrete objects\nsuch as graphs, but that difﬁculty can be circumvented,\nas shown later.\nII.\nCONVOLUTIONAL NEURAL NETWORKS FOR\nISOLATED CHARACTER RECOGNITION\nThe ability of multilayer networks trained with gradi-\nent descent to learn complex, high-dimensional, nonlinear\nmappings from large collections of examples makes them\nobvious candidates for image recognition tasks. In the\ntraditional model of pattern recognition, a hand-designed\nfeature extractor gathers relevant information from the input\nand eliminates irrelevant variabilities. A trainable classiﬁer\nthen categorizes the resulting feature vectors into classes. In\nthis scheme, standard, fully connected multilayer networks\ncan be used as classiﬁers. A potentially more interesting\nscheme is to rely as much as possible on learning in the\nfeature extractor itself. In the case of character recognition,\na network could be fed with almost raw inputs (e.g.,\nsize-normalized images). While this can be done with an\nordinary fully connected feedforward network with some\nsuccess for tasks such as character recognition, there are\nproblems.\nFirst, typical images are large, often with several hundred\nvariables (pixels). A fully connected ﬁrst layer with, e.g.,\none hundred hidden units in the ﬁrst layer would already\ncontain several tens of thousands of weights. Such a large\nnumber of parameters increases the capacity of the system\nand therefore requires a larger training set. In addition, the\nmemory requirement to store so many weights may rule out\ncertain hardware implementations. But the main deﬁciency\nof unstructured nets for image or speech applications is that\nthey have no built-in invariance with respect to translations\nor local distortions of the inputs. Before being sent to\nthe ﬁxed-size input layer of an NN, character images,\n2282\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 2.\nArchitecture of LeNet-5, a convolutional NN, here used for digits recognition. Each plane\nis a feature map, i.e., a set of units whose weights are constrained to be identical.\nor other 2-D or one-dimensional (1-D) signals, must be\napproximately size normalized and centered in the input\nﬁeld. Unfortunately, no such preprocessing can be perfect:\nhandwriting is often normalized at the word level, which\ncan cause size, slant, and position variations for individual\ncharacters. This, combined with variability in writing style,\nwill cause variations in the position of distinctive features\nin input objects. In principle, a fully connected network of\nsufﬁcient size could learn to produce outputs that are invari-\nant with respect to such variations. However, learning such\na task would probably result in multiple units with similar\nweight patterns positioned at various locations in the input\nso as to detect distinctive features wherever they appear on\nthe input. Learning these weight conﬁgurations requires a\nvery large number of training instances to cover the space of\npossible variations. In convolutional networks, as described\nbelow, shift invariance is automatically obtained by forcing\nthe replication of weight conﬁgurations across space.\nSecondly, a deﬁciency of fully connected architectures is\nthat the topology of the input is entirely ignored. The input\nvariables can be presented in any (ﬁxed) order without af-\nfecting the outcome of the training. On the contrary, images\n(or time-frequency representations of speech) have a strong\n2-D local structure: variables (or pixels) that are spatially or\ntemporally nearby are highly correlated. Local correlations\nare the reasons for the well-known advantages of extracting\nand combining local features before recognizing spatial\nor temporal objects, because conﬁgurations of neighboring\nvariables can be classiﬁed into a small number of categories\n(e.g., edges, corners, etc.). Convolutional networks force\nthe extraction of local features by restricting the receptive\nﬁelds of hidden units to be local.\nA. Convolutional Networks\nConvolutional networks combine three architectural ideas\nto ensure some degree of shift, scale, and distortion in-\nvariance: 1) local receptive ﬁelds; 2) shared weights (or\nweight replication); and 3) spatial or temporal subsampling.\nA typical convolutional network for recognizing characters,\ndubbed LeNet-5, is shown in Fig. 2. The input plane\nreceives images of characters that are approximately size\nnormalized and centered. Each unit in a layer receives\ninputs from a set of units located in a small neighborhood\nin the previous layer. The idea of connecting units to local\nreceptive ﬁelds on the input goes back to the perceptron in\nthe early 1960’s, and it was almost simultaneous with Hubel\nand Wiesel’s discovery of locally sensitive, orientation-\nselective neurons in the cat’s visual system [30]. Local\nconnections have been used many times in neural models\nof visual learning [2], [18], [31]–[34]. With local receptive\nﬁelds neurons can extract elementary visual features such\nas oriented edges, endpoints, corners (or similar features in\nother signals such as speech spectrograms). These features\nare then combined by the subsequent layers in order to\ndetect higher order features. As stated earlier, distortions or\nshifts of the input can cause the position of salient features\nto vary. In addition, elementary feature detectors that are\nuseful on one part of the image are likely to be useful across\nthe entire image. This knowledge can be applied by forcing\na set of units, whose receptive ﬁelds are located at different\nplaces on the image, to have identical weight vectors [15],\n[32], [34]. Units in a layer are organized in planes within\nwhich all the units share the same set of weights. The set of\noutputs of the units in such a plane is called a feature map.\nUnits in a feature map are all constrained to perform the\nsame operation on different parts of the image. A complete\nconvolutional layer is composed of several feature maps\n(with different weight vectors), so that multiple features\ncan be extracted at each location. A concrete example of\nthis is the ﬁrst layer of LeNet-5 shown in Fig. 2. Units\nin the ﬁrst hidden layer of LeNet-5 are organized in six\nplanes, each of which is a feature map. A unit in a feature\nmap has 25 inputs connected to a 5 5 area in the input,\ncalled the receptive ﬁeld of the unit. Each unit has 25\ninputs and therefore 25 trainable coefﬁcients plus a trainable\nbias. The receptive ﬁelds of contiguous units in a feature\nmap are centered on corresponding contiguous units in the\nprevious layer. Therefore, receptive ﬁelds of neighboring\nunits overlap. For example, in the ﬁrst hidden layer of\nLeNet-5, the receptive ﬁelds of horizontally contiguous\nunits overlap by four columns and ﬁve rows. As stated\nearlier, all the units in a feature map share the same set of 25\nweights and the same bias, so they detect the same feature\nat all possible locations on the input. The other feature\nmaps in the layer use different sets of weights and biases,\nthereby extracting different types of local features. In the\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2283\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "case of LeNet-5, at each input location six different types\nof features are extracted by six units in identical locations\nin the six feature maps. A sequential implementation of\na feature map would scan the input image with a single\nunit that has a local receptive ﬁeld and store the states\nof this unit at corresponding locations in the feature map.\nThis operation is equivalent to a convolution, followed by\nan additive bias and squashing function, hence the name\nconvolutional network. The kernel of the convolution is the\nset of connection weights used by the units in the feature\nmap. An interesting property of convolutional layers is that\nif the input image is shifted, the feature map output will be\nshifted by the same amount, but it will be left unchanged\notherwise. This property is at the basis of the robustness of\nconvolutional networks to shifts and distortions of the input.\nOnce a feature has been detected, its exact location\nbecomes less important. Only its approximate position\nrelative to other features is relevant. For example, once\nwe know that the input image contains the endpoint of a\nroughly horizontal segment in the upper left area, a corner\nin the upper right area, and the endpoint of a roughly\nvertical segment in the lower portion of the image, we can\ntell the input image is a seven. Not only is the precise\nposition of each of those features irrelevant for identifying\nthe pattern, it is potentially harmful because the positions\nare likely to vary for different instances of the character. A\nsimple way to reduce the precision with which the position\nof distinctive features are encoded in a feature map is\nto reduce the spatial resolution of the feature map. This\ncan be achieved with a so-called subsampling layer, which\nperforms a local averaging and a subsampling, thereby\nreducing the resolution of the feature map and reducing\nthe sensitivity of the output to shifts and distortions. The\nsecond hidden layer of LeNet-5 is a subsampling layer. This\nlayer comprises six feature maps, one for each feature map\nin the previous layer. The receptive ﬁeld of each unit is\na 2 2 area in the previous layer’s corresponding feature\nmap. Each unit computes the average of its four inputs,\nmultiplies it by a trainable coefﬁcient, adds a trainable\nbias, and passes the result through a sigmoid function.\nContiguous units have nonoverlapping contiguous receptive\nﬁelds. Consequently, a subsampling layer feature map has\nhalf the number of rows and columns as the feature maps in\nthe previous layer. The trainable coefﬁcient and bias control\nthe effect of the sigmoid nonlinearity. If the coefﬁcient is\nsmall, then the unit operates in a quasi-linear mode, and the\nsubsampling layer merely blurs the input. If the coefﬁcient\nis large, subsampling units can be seen as performing a\n“noisy OR” or a “noisy AND” function depending on\nthe value of the bias. Successive layers of convolutions\nand subsampling are typically alternated resulting in a\n“bipyramid”: at each layer, the number of feature maps\nis increased as the spatial resolution is decreased. Each\nunit in the third hidden layer in Fig. 2 may have input\nconnections from several feature maps in the previous\nlayer. The convolution/subsampling combination, inspired\nby Hubel and Wiesel’s notions of “simple” and “complex”\ncells, was implemented in Fukushima’s Neocognitron [32],\nthough no globally supervised learning procedure such\nas back propagation was available then. A large degree\nof invariance to geometric transformations of the input\ncan be achieved with this progressive reduction of spatial\nresolution compensated by a progressive increase of the\nrichness of the representation (the number of feature maps).\nSince all the weights are learned with back propagation,\nconvolutional networks can be seen as synthesizing their\nown feature extractor. The weight sharing technique has\nthe interesting side effect of reducing the number of free\nparameters, thereby reducing the “capacity” of the machine\nand reducing the gap between test error and training error\n[34]. The network in Fig. 2 contains 345 308 connections,\nbut only 60 000 trainable free parameters because of the\nweight sharing.\nFixed-size convolutional networks have been applied to\nmany applications, among other handwriting recognition\n[35], [36], machine-printed character recognition [37], on-\nline handwriting recognition [38], and face recognition\n[39]. Fixed-size convolutional networks that share weights\nalong a single temporal dimension are known as time-delay\nNN’s (TDNN’s). TDNN’s have been used in phoneme\nrecognition (without subsampling) [40], [41], spoken word\nrecognition (with subsampling) [42], [43], online recogni-\ntion of isolated handwritten characters [44], and signature\nveriﬁcation [45].\nB. LeNet-5\nThis section describes in more detail the architecture of\nLeNet-5, the Convolutional NN used in the experiments.\nLeNet-5 comprises seven layers, not counting the input, all\nof which contain trainable parameters (weights). The input\nis a 32 32 pixel image. This is signiﬁcantly larger than\nthe largest character in the database (at most 20 20 pixels\ncentered in a 28 28 ﬁeld). The reason is that it is desirable\nthat potential distinctive features such as stroke endpoints\nor corner can appear in the center of the receptive ﬁeld\nof the highest level feature detectors. In LeNet-5, the set\nof centers of the receptive ﬁelds of the last convolutional\nlayer (C3, see below) form a 20 20 area in the center of the\n32 32 input. The values of the input pixels are normalized\nso that the background level (white) corresponds to a value\nof\nand the foreground (black) corresponds to 1.175.\nThis makes the mean input roughly zero and the variance\nroughly one, which accelerates learning [46].\nIn the following, convolutional layers are labeled Cx,\nsubsampling layers are labeled Sx, and fully connected\nlayers are labeled Fx, where x is the layer index.\nLayer C1 is a convolutional layer with six feature maps.\nEach unit in each feature map is connected to a 5 5 neigh-\nborhood in the input. The size of the feature maps is 28 28\nwhich prevents connection from the input from falling off\nthe boundary. C1 contains 156 trainable parameters and\n122 304 connections.\nLayer S2 is a subsampling layer with six feature maps of\nsize 14 14. Each unit in each feature map is connected to a\n2 2 neighborhood in the corresponding feature map in C1.\nThe four inputs to a unit in S2 are added, then multiplied by\n2284\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Table 1\nEach Column Indicates Which Feature Map in S2 Are\nCombined by the Units in a Particular Feature Map of C3\na trainable coefﬁcient, and then added to a trainable bias.\nThe result is passed through a sigmoidal function. The 2 2\nreceptive ﬁelds are nonoverlapping, therefore feature maps\nin S2 have half the number of rows and column as feature\nmaps in C1. Layer S2 has 12 trainable parameters and 5880\nconnections.\nLayer C3 is a convolutional layer with 16 feature maps.\nEach unit in each feature map is connected to several\n5 5 neighborhoods at identical locations in a subset of\nS2’s feature maps. Table 1 shows the set of S2 feature\nmaps combined by each C3 feature map. Why not connect\nevery S2 feature map to every C3 feature map? The\nreason is twofold. First, a noncomplete connection scheme\nkeeps the number of connections within reasonable bounds.\nMore importantly, it forces a break of symmetry in the\nnetwork. Different feature maps are forced to extract dif-\nferent (hopefully complementary) features because they get\ndifferent sets of inputs. The rationale behind the connection\nscheme in Table 1 is the following. The ﬁrst six C3 feature\nmaps take inputs from every contiguous subsets of three\nfeature maps in S2. The next six take input from every\ncontiguous subset of four. The next three take input from\nsome discontinuous subsets of four. Finally, the last one\ntakes input from all S2 feature maps. Layer C3 has 1516\ntrainable parameters and 156 000 connections.\nLayer S4 is a subsampling layer with 16 feature maps of\nsize 5 5. Each unit in each feature map is connected to a\n2 2 neighborhood in the corresponding feature map in C3,\nin a similar way as C1 and S2. Layer S4 has 32 trainable\nparameters and 2000 connections.\nLayer C5 is a convolutional layer with 120 feature maps.\nEach unit is connected to a 5 5 neighborhood on all 16\nof S4’s feature maps. Here, because the size of S4 is also\n5 5, the size of C5’s feature maps is 1 1; this amounts\nto a full connection between S4 and C5. C5 is labeled as\na convolutional layer, instead of a fully connected layer,\nbecause if LeNet-5 input were made bigger with everything\nelse kept constant, the feature map dimension would be\nlarger than 1 1. This process of dynamically increasing the\nsize of a convolutional network is described in Section VII.\nLayer C5 has 48 120 trainable connections.\nLayer F6 contains 84 units (the reason for this number\ncomes from the design of the output layer, explained\nbelow) and is fully connected to C5. It has 10 164 trainable\nparameters.\nAs in classical NN’s, units in layers up to F6 compute a\ndot product between their input vector and their weight\nvector, to which a bias is added. This weighted sum,\ndenoted\nfor unit\nis then passed through a sigmoid\nsquashing function to produce the state of unit\ndenoted\nby\n(5)\nThe squashing function is a scaled hyperbolic tangent\n(6)\nwhere\nis the amplitude of the function and\ndetermines\nits slope at the origin. The function\nis odd, with horizontal\nasymptotes at\nand\nThe constant\nis chosen to be\n1.7159. The rationale for this choice of a squashing function\nis given in Appendix A.\nFinally, the output layer is composed of Euclidean RBF\nunits, one for each class, with 84 inputs each. The outputs\nof each RBF unit\nis computed as follows:\n(7)\nIn other words, each output RBF unit computes the Eu-\nclidean distance between its input vector and its parameter\nvector. The further away the input is from the parameter\nvector, the larger the RBF output. The output of a particular\nRBF can be interpreted as a penalty term measuring the\nﬁt between the input pattern and a model of the class\nassociated with the RBF. In probabilistic terms, the RBF\noutput can be interpreted as the unnormalized negative\nlog-likelihood of a Gaussian distribution in the space of\nconﬁgurations of layer F6. Given an input pattern, the loss\nfunction should be designed so as to get the conﬁguration\nof F6 as close as possible to the parameter vector of the\nRBF that corresponds to the pattern’s desired class. The\nparameter vectors of these units were chosen by hand and\nkept ﬁxed (at least initially). The components of those\nparameters vectors were set to\n1 or\n1. While they could\nhave been chosen at random with equal probabilities for\n1 and\n1, or even chosen to form an error correcting\ncode as suggested by [47], they were instead designed to\nrepresent a stylized image of the corresponding character\nclass drawn on a 7 12 bitmap (hence the number 84). Such\na representation is not particularly useful for recognizing\nisolated digits, but it is quite useful for recognizing strings\nof characters taken from the fully printable ASCII set. The\nrationale is that characters that are similar, and therefore\nconfusable, such as uppercase “O,” lowercase “o,” and zero,\nlowercase “l” digit one, and square brackets and uppercase\n“I,” will have similar output codes. This is particularly\nuseful if the system is combined with a linguistic post-\nprocessor that can correct such confusions. Because the\ncodes for confusable classes are similar, the output of the\ncorresponding RBF’s for an ambiguous character will be\nsimilar, and the postprocessor will be able to pick the\nappropriate interpretation. Fig. 3 gives the output codes for\nthe full ASCII set.\nAnother reason for using such distributed codes, rather\nthan the more common “1 of N” code (also called place\ncode or grandmother cell code) for the outputs is that\nnondistributed codes tend to behave badly when the number\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2285\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 3.\nInitial parameters of the output RBF’s for recognizing the full ASCII set.\nof classes is larger than a few dozen. The reason is\nthat output units in a nondistributed code must be off\nmost of the time. This is quite difﬁcult to achieve with\nsigmoid units. Yet another reason is that the classiﬁers are\noften used not only to recognize characters, but also to\nreject noncharacters. RBF’s with distributed codes are more\nappropriate for that purpose because unlike sigmoids, they\nare activated within a well-circumscribed region of their\ninput space, outside of which nontypical patterns are more\nlikely to fall.\nThe parameter vectors of the RBF’s play the role of\ntarget vectors for layer F6. It is worth pointing out that\nthe components of those vectors are\n1 or\n1, which is\nwell within the range of the sigmoid of F6, and therefore\nprevents those sigmoids from getting saturated. In fact,\n1 and\n1 are the points of maximum curvature of the\nsigmoids. This forces the F6 units to operate in their\nmaximally nonlinear range. Saturation of the sigmoids must\nbe avoided because it is known to lead to slow convergence\nand ill-conditioning of the loss function.\nC. Loss Function\nThe simplest output loss function that can be used with\nthe above network is the maximum likelihood estimation\ncriterion, which in our case is equivalent to the minimum\nmean squared error (MSE). The criterion for a set of\ntraining samples is simply\n(8)\nwhere\nis the output of the\nth RBF unit, i.e., the\none that corresponds to the correct class of input pattern\nWhile this cost function is appropriate for most cases,\nit lacks three important properties. First, if we allow the\nparameters of the RBF to adapt,\nhas a trivial, but\ntotally unacceptable, solution. In this solution, all the RBF\nparameter vectors are equal and the state of F6 is constant\nand equal to that parameter vector. In this case the network\nhappily ignores the input, and all the RBF outputs are equal\nto zero. This collapsing phenomenon does not occur if the\nRBF weights are not allowed to adapt. The second problem\nis that there is no competition between the classes. Such a\ncompetition can be obtained by using a more discriminative\ntraining criterion, dubbed the maximum a posteriori (MAP)\ncriterion, similar to maximum mutual information criterion\nsometimes used to train HMM’s [48]–[50]. It corresponds\nto maximizing the posterior probability of the correct class\n(or minimizing the logarithm of the probability of the\ncorrect class), given that the input image can come from\none of the classes or from a background “rubbish” class\nlabel. In terms of penalties, it means that in addition to\npushing down the penalty of the correct class like the MSE\ncriterion, this criterion also pulls up the penalties of the\nincorrect classes\n(9)\nThe negative of the second term plays a “competitive”\nrole. It is necessarily smaller than (or equal to) the ﬁrst\nterm, therefore this loss function is positive. The constant\nis positive and prevents the penalties of classes that\nare already very large from being pushed further up. The\nposterior probability of this rubbish class label would be the\nratio of\nand\nThis discriminative\ncriterion prevents the previously mentioned “collapsing\neffect” when the RBF parameters are learned because it\nkeeps the RBF centers apart from each other. In Section VI,\nwe present a generalization of this criterion for systems\nthat learn to classify multiple objects in the input (e.g.,\ncharacters in words or in documents).\nComputing the gradient of the loss function with respect\nto all the weights in all the layers of the convolutional\nnetwork is done with back propagation. The standard al-\ngorithm must be slightly modiﬁed to take account of the\n2286\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "weight sharing. An easy way to implement it is to ﬁrst\ncompute the partial derivatives of the loss function with\nrespect to each connection, as if the network were a\nconventional multilayer network without weight sharing.\nThen the partial derivatives of all the connections that share\na same parameter are added to form the derivative with\nrespect to that parameter.\nSuch a large architecture can be trained very efﬁciently,\nbut doing so requires the use of a few techniques that are\ndescribed in the appendixes. Appendix A describes details\nsuch as the particular sigmoid used and the weight ini-\ntialization. Appendixes B and C describe the minimization\nprocedure used, which is a stochastic version of a diagonal\napproximation to the Levenberg–Marquardt procedure.\nIII.\nRESULTS AND COMPARISON WITH OTHER METHODS\nWhile recognizing individual digits is only one of many\nproblems involved in designing a practical recognition\nsystem, it is an excellent benchmark for comparing shape\nrecognition methods. Though many existing methods com-\nbine a hand-crafted feature extractor and a trainable clas-\nsiﬁer, this study concentrates on adaptive methods that\noperate directly on size-normalized images.\nA. Database: The Modiﬁed NIST Set\nThe database used to train and test the systems described\nin this paper was constructed from the NIST’s Special\nDatabase 3 and Special Database 1 containing binary im-\nages of handwritten digits. NIST originally designated SD-3\nas their training set and SD-1 as their test set. However,\nSD-3 is much cleaner and easier to recognize than SD-1.\nThe reason for this can be found on the fact that SD-\n3 was collected among Census Bureau employees, while\nSD-1 was collected among high-school students. Drawing\nsensible conclusions from learning experiments requires\nthat the result be independent of the choice of training set\nand test among the complete set of samples. Therefore it\nwas necessary to build a new database by mixing NIST’s\ndatasets.\nSD-1 contains 58 527 digit images written by 500 dif-\nferent writers. In contrast to SD-3, where blocks of data\nfrom each writer appeared in sequence, the data in SD-1 is\nscrambled. Writer identities for SD-1 are available and we\nused this information to unscramble the writers. We then\nsplit SD-1 in two: characters written by the ﬁrst 250 writers\nwent into our new training set. The remaining 250 writers\nwere placed in our test set. Thus we had two sets with nearly\n30 000 examples each. The new training set was completed\nwith enough examples from SD-3, starting at pattern #0, to\nmake a full set of 60 000 training patterns. Similarly, the\nnew test set was completed with SD-3 examples starting at\npattern #35 000 to make a full set with 60 000 test patterns.\nIn the experiments described here, we only used a subset of\n10 000 test images (5,000 from SD-1 and 5,000 from SD-3),\nbut we used the full 60 000 training samples. The resulting\ndatabase was called the modiﬁed NIST, or MNIST, dataset.\nFig. 4.\nSize-normalized examples from the MNIST database.\nThe original black and white (bilevel) images were size\nnormalized to ﬁt in a 20 20 pixel box while preserving\ntheir aspect ratio. The resulting images contain grey levels\nas result of the antialiasing (image interpolation) technique\nused by the normalization algorithm. Three versions of the\ndatabase were used. In the ﬁrst version, the images were\ncentered in a 28 28 image by computing the center of mass\nof the pixels and translating the image so as to position this\npoint at the center of the 28 28 ﬁeld. In some instances,\nthis 28 28 ﬁeld was extended to 32 32 with background\npixels. This version of the database will be referred to as\nthe regular database. In the second version of the database,\nthe character images were deslanted and cropped down to\n20 20 pixels images. The deslanting computes the second\nmoments of inertia of the pixels (counting a foreground\npixel as one and a background pixel as zero) and shears the\nimage by horizontally shifting the lines so that the principal\naxis is vertical. This version of the database will be referred\nto as the deslanted database. In the third version of the\ndatabase, used in some early experiments, the images were\nreduced to 16 16 pixels.1 Fig. 4 shows examples randomly\npicked from the test set.\nB. Results\nSeveral versions of LeNet-5 were trained on the regu-\nlar MNIST database. Twenty iterations through the entire\ntraining data were performed for each session. The values\nof the global learning rate\n[see (21) in Appendix C for\na deﬁnition] was decreased using the following schedule:\n0.0005 for the ﬁrst two passes; 0.0002 for the next three;\n0.0001 for the next three; 0.000 05 for the next 4; and\n0.000 01 thereafter. Before each iteration, the diagonal\n1The regular database (60 000 training examples, 10 000 test examples\nsize-normalized to 20\u000220 and centered by center of mass in 28\u000228 ﬁelds)\nis available WWW: http://www.research.att.com/˜yann/ocr/mnist.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2287\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 5.\nTraining and test error of LeNet-5 as a function of the\nnumber of passes through the 60 000 pattern training set (without\ndistortions). The average training error is measured on-the-ﬂy as\ntraining proceeds. This explains why the training error appears to\nbe larger than the test error initially. Convergence is attained after\n10–12 passes through the training set.\nHessian approximation was reevaluated on 500 samples,\nas described in Appendix C, and was kept ﬁxed during\nthe entire iteration. The parameter\nwas set to 0.02.\nThe resulting effective learning rates during the ﬁrst pass\nvaried between approximately 7 10\nand 0.016 over\nthe set of parameters. The test error rate stabilizes after\naround ten passes through the training set at 0.95%. The\nerror rate on the training set reaches 0.35% after 19\npasses. Many authors have reported observing the common\nphenomenon of overtraining when training NN’s or other\nadaptive algorithms on various tasks. When overtraining\noccurs, the training error keeps decreasing over time but\nthe test error goes through a minimum and starts increasing\nafter a certain number of iterations. While this phenomenon\nis very common, it was not observed in our case as the\nlearning curves in Fig. 5 show. A possible reason is that\nthe learning rate was kept relatively large. The effect of\nthis is that the weights never settle down in the local\nminimum but keep oscillating randomly. Because of those\nﬂuctuations, the average cost will be lower in a broader\nminimum. Therefore, stochastic gradient will have a similar\neffect as a regularization term that favors broader minima.\nBroader minima correspond to solutions with large entropy\nof the parameter distribution, which is beneﬁcial to the\ngeneralization error.\nThe inﬂuence of the training set size was measured\nby training the network with 15 000, 30 000, and 60 000\nexamples. The resulting training error and test error are\nshown in Fig. 6. It is clear that, even with specialized\narchitectures such as LeNet-5, more training data would\nimprove the accuracy.\nTo verify this hypothesis, we artiﬁcially generated more\ntraining examples by randomly distorting the original train-\ning images. The increased training set was composed of\nthe 60 000 original patterns plus 540 000 instances of dis-\ntorted patterns with randomly picked distortion parameters.\nThe distortions were combinations of the following planar\nafﬁne transformations: horizontal and vertical translations;\nscaling; squeezing (simultaneous horizontal compression\nand vertical elongation, or the reverse); and horizontal\nshearing. Fig. 7 shows examples of distorted patterns used\nfor training. When distorted data were used for training,\nthe test error rate dropped to 0.8% (from 0.95% without\ndeformation). The same training parameters were used\nas without deformations. The total length of the training\nsession was left unchanged (20 passes of 60 000 patterns\neach). It is interesting to note that the network effectively\nsees each individual sample only twice over the course of\nthese 20 passes.\nFig. 8 shows all 82 misclassiﬁed test examples. some\nof those examples are genuinely ambiguous, but several\nare perfectly identiﬁable by humans, although they are\nwritten in an under-represented style. This shows that\nfurther improvements are to be expected with more training\ndata.\nC. Comparison with Other Classiﬁers\nFor the sake of comparison, a variety of other trainable\nclassiﬁers was trained and tested on the same database. An\nearly subset of these results was presented in [51]. The error\nrates on the test set for the various methods are shown in\nFig. 9.\n1) Linear\nClassiﬁer\nand\nPairwise\nLinear\nClassiﬁer:\nPossibly the simplest classiﬁer that one might consider\nis a linear classiﬁer. Each input pixel value contributes to a\nweighted sum for each output unit. The output unit with the\nhighest sum (including the contribution of a bias constant)\nindicates the class of the input character. On the regular\ndata, the error rate is 12%. The network has 7850 free\nparameters. On the deslanted images, the test error rate is\n8.4%. The network has 4010 free parameters. The deﬁcien-\ncies of the linear classiﬁer are well documented [1], and it is\nincluded here simply to form a basis of comparison for more\nsophisticated classiﬁers. Various combinations of sigmoid\nunits, linear units, gradient descent learning, and learning\nby directly solving linear systems gave similar results.\nA simple improvement of the basic linear classiﬁer was\ntested [52]. The idea is to train each unit of a single-\nlayer network to separate each class from each other\nclass. In our case this layer comprises 45 units labeled\nUnit\nis trained to pro-\nduce\n1 on patterns of class\n1 on patterns of class\n,\nand it is not trained on other patterns. The ﬁnal score for\nclass\nis the sum of the outputs all the units labeled\nminus the sum of the output of all the units labeled\nfor\nall\nand\nThe error rate on the regular test set was 7.6%.\n2) Baseline Nearest Neighbor Classiﬁer: Another simple\nclassiﬁer is a K-NN classiﬁer with a Euclidean distance\nmeasure between input images. This classiﬁer has the\nadvantage that no training time, and no thought on the\npart of the designer, are required. However the memory\nrequirement and recognition time are large: the complete\n60 000 20\n20 pixel training images (about 24 megabytes\nat one byte per pixel) must be available at run time. Much\n2288\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 6.\nTraining and test errors of LeNet-5 achieved using training sets of various sizes. This graph\nsuggests that a larger training set could improve the performance of LeNet-5. The hollow square\nshows the test error when more training patterns are artiﬁcially generated using random distortions.\nThe test patterns are not distorted.\nFig. 7.\nExamples of distortions of ten training patterns.\nmore compact representations could be devised with modest\nincrease in error rate. On the regular test set the error\nrate was 5.0%. On the deslanted data, the error rate was\n2.4%, with\nNaturally, a realistic Euclidean distance\nnearest-neighbor system would operate on feature vectors\nFig. 8.\nThe 82 test patterns misclassiﬁed by LeNet-5. Below\neach image is displayed the correct answers (left) and the net-\nwork answer (right). These errors are mostly caused either by\ngenuinely ambiguous patterns, or by digits written in a style that\nare under-represented in the training set.\nrather than directly on the pixels, but since all of the other\nsystems presented in this study operate directly on the\npixels, this result is useful for a baseline comparison.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2289\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 9.\nError rate on the test set (%) for various classiﬁcation methods. [deslant] indicates that the\nclassiﬁer was trained and tested on the deslanted version of the database. [dist] indicates that the\ntraining set was augmented with artiﬁcially distorted examples. [16\u000216] indicates that the system\nused the 16\u000216 pixel images. The uncertainty in the quoted error rates is about 0.1%.\n3) PCA and Polynomial Classiﬁer: Following [53] and\n[54], a preprocessing stage was constructed which computes\nthe projection of the input pattern on the 40 principal\ncomponents of the set of training vectors. To compute the\nprincipal components, the mean of each input component\nwas ﬁrst computed and subtracted from the training\nvectors. The covariance matrix of the resulting vectors\nwas then computed and diagonalized using singular value\ndecomposition. The 40-dimensional feature vector was used\nas the input of a second degree polynomial classiﬁer. This\nclassiﬁer can be seen as a linear classiﬁer with 821 inputs,\npreceded by a module that computes all products of pairs of\ninput variables. The error on the regular test set was 3.3%.\n4) RBF Network: Following [55], an RBF network was\nconstructed. The ﬁrst layer was composed of 1000 Gaussian\nRBF units with 28 28 inputs, and the second layer was a\nsimple 1000 inputs/ten outputs linear classiﬁer. The RBF\nunits were divided into ten groups of 100. Each group of\nunits was trained on all the training examples of one of\nthe ten classes using the adaptive K-means algorithm. The\nsecond-layer weights were computed using a regularized\npseudoinverse method. The error rate on the regular test\nset was 3.6%.\n5) One-Hidden-Layer Fully Connected Multilayer NN:\nAnother classiﬁer that we tested was a fully connected\nmultilayer NN with two layers of weights (one hidden layer)\ntrained with the version of back-propagation described in\nAppendix C. Error on the regular test set was 4.7% for a\nnetwork with 300 hidden units and 4.5% for a network with\n1000 hidden units. Using artiﬁcial distortions to generate\nmore training data brought only marginal improvement:\n3.6% for 300 hidden units and 3.8% for 1000 hidden units.\nWhen deslanted images were used, the test error jumped\ndown to 1.6% for a network with 300 hidden units.\nIt remains somewhat of a mystery that networks with\nsuch a large number of free parameters manage to achieve\nreasonably low testing errors. We conjecture that the dy-\nnamics of gradient descent learning in multilayer nets\nhas a “self-regularization” effect. Because the origin of\nweight space is a saddle point that is attractive in al-\nmost every direction, the weights invariably shrink during\nthe ﬁrst few epochs (recent theoretical analysis seem to\nconﬁrm this [56]). Small weights cause the sigmoids to\noperate in the quasi-linear region, making the network\nessentially equivalent to a low-capacity, single-layer net-\nwork. As the learning proceeds the weights grow, which\n2290\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "progressively increases the effective capacity of the net-\nwork. This seems to be an almost perfect, if fortuitous,\nimplementation of Vapnik’s “structural risk minimization”\nprinciple [6]. A better theoretical understanding of these\nphenomena, and more empirical evidence, are deﬁnitely\nneeded.\n6) Two-Hidden-Layer Fully Connected Multilayer NN: To\nsee the effect of the architecture, several two-hidden-layer\nmultilayer NN’s were trained. Theoretical results have\nshown that any function can be approximated by a one-\nhidden-layer NN [57]. However, several authors have ob-\nserved that two-hidden-layer architectures sometimes yield\nbetter performance in practical situations. This phenomenon\nwas also observed here. The test error rate of a 28 28-\n300-100-10 network was 3.05%, a much better result than\nthe one-hidden-layer network, obtained using marginally\nmore weights and connections. Increasing the network size\nto 28 28-1000-150-10 yielded only marginally improved\nerror rates: 2.95%. Training with distorted patterns im-\nproved the performance somewhat: 2.50% error for the\n28 28-300-100-10 network, and 2.45% for the 28 28-\n1000-150-10 network.\n7) A Small Convolutional Network—LeNet-1: Convolu-\ntional networks are an attempt to solve the dilemma\nbetween small networks that cannot learn the training\nset and large networks that seem overparameterized.\nLeNet-1 was an early embodiment of the convolutional\nnetwork architecture which is included here for comparison\npurposes. The images were down-sampled to 16 16\npixels and centered in the 28 28 input layer. Although\nabout 100 000 multiply/add steps are required to evaluate\nLeNet-1, its convolutional nature keeps the number of free\nparameters to only about 2600. The LeNet-1 architecture\nwas developed using our own version of the USPS (U.S.\nPostal Service zip codes) database and its size was tuned to\nmatch the available data [35]. LeNet-1 achieved 1.7% test\nerror. The fact that a network with such a small number of\nparameters can attain such a good error rate is an indication\nthat the architecture is appropriate for the task.\n8) LeNet-4: Experiments with LeNet-1 made it clear that\na larger convolutional network was needed to make optimal\nuse of the large size of the training set. LeNet-4 and later\nLeNet-5 were designed to address this problem. LeNet-\n4 is very similar to LeNet-5, except for the details of\nthe architecture. It contains four ﬁrst-level feature maps,\nfollowed by eight subsampling maps connected in pairs\nto each ﬁrst-layer feature maps, then 16 feature maps,\nfollowed by 16 subsampling maps, followed by a fully\nconnected layer with 120 units, followed by the output layer\n(ten units). LeNet-4 contains about 260 000 connections and\nhas about 17 000 free parameters. Test error was 1.1%. In a\nseries of experiments, we replaced the last layer of LeNet-\n4 with a Euclidean nearest-neighbor classiﬁer, and with\nthe “local learning” method of Bottou and Vapnik [58], in\nwhich a local linear classiﬁer is retrained each time a new\ntest pattern is shown. Neither of those methods improved\nthe raw error rate, although they did improve the rejection\nperformance.\n9) Boosted LeNet-4: Following\ntheoretical\nwork\nby\nSchapire [59], Drucker et al. [60] developed the “boosting”\nmethod for combining multiple classiﬁers. Three LeNet-4’s\nare combined: the ﬁrst one is trained the usual way; the\nsecond one is trained on patterns that are ﬁltered by the\nﬁrst net so that the second machine sees a mix of patterns,\n50% of which the ﬁrst net got right and 50% of which\nit got wrong; the third net is trained on new patterns on\nwhich the ﬁrst and the second nets disagree. During testing,\nthe outputs of the three nets are simply added. Because the\nerror rate of LeNet-4 is very low, it was necessary to\nuse the artiﬁcially distorted images (as with LeNet-5) in\norder to get enough samples to train the second and third\nnets. The test error rate was 0.7%, the best of any of our\nclassiﬁers. At ﬁrst glance, boosting appears to be three\ntimes more expensive as a single net. In fact, when the ﬁrst\nnet produces a high conﬁdence answer, the other nets are\nnot called. The average computational cost is about 1.75\ntimes that of a single net.\n10) Tangent Distance Classiﬁer: The\ntangent\ndistance\nclassiﬁer is a nearest-neighbor method where the distance\nfunction is made insensitive to small distortions and\ntranslations of the input image [61]. If we consider an\nimage as a point in a high-dimensional pixel space (where\nthe dimensionality equals the number of pixels), then an\nevolving distortion of a character traces out a curve in pixel\nspace. Taken together, all these distortions deﬁne a low-\ndimensional manifold in pixel space. For small distortions\nin the vicinity of the original image, this manifold can be\napproximated by a plane, known as the tangent plane. An\nexcellent measure of “closeness” for character images is\nthe distance between their tangent planes, where the set of\ndistortions used to generate the planes includes translations,\nscaling, skewing, squeezing, rotation, and line thickness\nvariations. A test error rate of 1.1% was achieved using\n16 16 pixel images. Preﬁltering techniques using simple\nEuclidean distance at multiple resolutions allowed to reduce\nthe number of necessary tangent distance calculations.\n11) SVM: Polynomial classiﬁers are well studied meth-\nods for generating complex decision surfaces. Unfortu-\nnately, they are impractical for high-dimensional problems\nbecause the number of product terms is prohibitive. The\nsupport vector technique is an extremely economical way of\nrepresenting complex surfaces in high-dimensional spaces,\nincluding polynomials and many other types of surfaces [6].\nA particularly interesting subset of decision surfaces\nis the ones that correspond to hyperplanes that are at a\nmaximum distance from the convex hulls of the two classes\nin the high-dimensional space of the product terms. Boser\net al. [62] realized that any polynomial of degree\nin this\n“maximum margin” set can be computed by ﬁrst computing\nthe dot product of the input image with a subset of the train-\ning samples (called the “support vectors”), elevating the\nresult to the\nth power, and linearly combining the numbers\nthereby obtained. Finding the support vectors and the coef-\nﬁcients amounts to solving a high-dimensional quadratic\nminimization problem with linear inequality constraints.\nFor the sake of comparison, we include here the results\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2291\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 10.\nRejection Performance: percentage of test patterns that must be rejected to achieve 0.5%\nerror for some of the systems.\nFig. 11.\nNumber of multiply–accumulate operations for the recognition of a single character\nstarting with a size-normalized image.\nobtained by Burges and Sch¨olkopf and reported in [63].\nWith a regular SVM, their error rate on the regular test set\nwas 1.4%. Cortes and Vapnik had reported an error rate of\n1.1% with SVM on the same data using a slightly different\ntechnique. The computational cost of this technique is very\nhigh: about 14 million multiply-adds per recognition. Using\nSch¨olkopf’s V-SVM technique, 1.0% error was attained.\nMore recently, Sch¨olkopf (personal communication) has\nreached 0.8% using a modiﬁed version of the V-SVM.\nUnfortunately, V-SVM is extremely expensive: about twice\nas much as regular SVM. To alleviate this problem, Burges\nhas proposed the RS-SVM technique, which attained 1.1%\non the regular test set [63], with a computational cost of\nonly 650 000 multiply–adds per recognition, i.e., only about\n60% more expensive than LeNet-5.\nD. Discussion\nA summary of the performance of the classiﬁers is\nshown in Figs. 9–12. Fig. 9 shows the raw error rate of the\nclassiﬁers on the 10 000 example test set. Boosted LeNet-4\nperformed best, achieving a score of 0.7%, closely followed\nby LeNet-5 at 0.8%.\nFig. 10 shows the number of patterns in the test set\nthat must be rejected to attain a 0.5% error for some of\n2292\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 12.\nMemory requirements, measured in number of variables, for each of the methods. Most\nof the methods only require one byte per variable for adequate performance.\nthe methods. Patterns are rejected when the value of the\ncorresponding output is smaller than a predeﬁned thresh-\nold. In many applications, rejection performance is more\nsigniﬁcant than raw error rate. The score used to decide\nupon the rejection of a pattern was the difference between\nthe scores of the top two classes. Again, Boosted LeNet-4\nhas the best performance. The enhanced versions of LeNet-\n4 did better than the original LeNet-4, even though the raw\naccuracies were identical.\nFig. 11 shows the number of multiply–accumulate op-\nerations necessary for the recognition of a single size-\nnormalized image for each method. Expectedly, NN’s are\nmuch less demanding than memory-based methods. Con-\nvolutional NN’s are particularly well suited to hardware\nimplementations because of their regular structure and\ntheir low memory requirements for the weights. Single\nchip mixed analog–digital implementations of LeNet-5’s\npredecessors have been shown to operate at speeds in\nexcess of 1000 characters per second [64]. However, the\nrapid progress of mainstream computer technology renders\nthose exotic technologies quickly obsolete. Cost-effective\nimplementations of memory-based techniques are more\nelusive due to their enormous memory requirements and\ncomputational requirements.\nTraining time was also measured. K-NN’s and tangent\ndistance classiﬁer have essentially zero training time. While\nthe single-layer net, the pairwise net, and PCA quadratic\nnet could be trained in less than an hour, the multilayer net\ntraining times were expectedly much longer, but only re-\nquired 10–20 passes through the training set. This amounts\nto two–three days of CPU to train LeNet-5 on a Silicon\nGraphics Origin 2000 server using a single 200 MHz\nR10000 processor. It is important to note that while the\ntraining time is somewhat relevant to the designer, it is\nof little interest to the ﬁnal user of the system. Given the\nchoice between an existing technique and a new technique\nthat brings marginal accuracy improvements at the price of\nconsiderable training time, any ﬁnal user would choose the\nlatter.\nFig. 12 shows the memory requirements, and therefore\nthe number of free parameters, of the various classiﬁers\nmeasured in terms of the number of variables that need\nto be stored. Most methods require only about 1 byte\nper variable for adequate performance. However, nearest-\nneighbor methods may get by with 4 bits per pixel for\nstoring the template images. Not surprisingly, NN’s require\nmuch less memory than memory-based methods.\nThe overall performance depends on many factors includ-\ning accuracy, running time, and memory requirements. As\ncomputer technology improves, larger capacity recognizers\nbecome feasible. Larger recognizers in turn require larger\ntraining sets. LeNet-1 was appropriate to the available\ntechnology in 1989, just as LeNet-5 is appropriate now.\nIn 1989 a recognizer as complex as LeNet-5 would have\nrequired several weeks’ training and more data than were\navailable and was therefore not even considered. For quite a\nlong time, LeNet-1 was considered the state of the art. The\nlocal learning classiﬁer, the optimal margin classiﬁer, and\nthe tangent distance classiﬁer were developed to improve\nupon LeNet-1—and they succeeded at that. However, they\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2293\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "in turn motivated a search for improved NN architectures.\nThis search was guided in part by estimates of the capacity\nof various learning machines, derived from measurements\nof the training and test error as a function of the number\nof training examples. We discovered that more capacity\nwas needed. Through a series of experiments in architec-\nture, combined with an analysis of the characteristics of\nrecognition errors, LeNet-4 and LeNet-5 were crafted.\nWe ﬁnd that boosting gives a substantial improvement in\naccuracy, with a relatively modest penalty in memory and\ncomputing expense. Also, distortion models can be used\nto increase the effective size of a data set without actually\nrequiring to collect more data.\nThe SVM has excellent accuracy, which is most remark-\nable because, unlike the other high performance classiﬁers,\nit does not include a priori knowledge about the problem.\nIn fact, this classiﬁer would do just as well if the image\npixels were permuted with a ﬁxed mapping and lost their\npictorial structure. However, reaching levels of performance\ncomparable to the convolutional NN’s can only be done\nat considerable expense in memory and computational re-\nquirements. The RS-SVM requirements are within a factor\nof two of the convolutional networks, and the error rate is\nvery close. Improvements of those results are expected as\nthe technique is relatively new.\nWhen plenty of data are available, many methods can\nattain respectable accuracy. The neural-net methods run\nmuch faster and require much less space than memory-\nbased techniques. The NN’s advantage will become more\nstriking as training databases continue to increase in size.\nE. Invariance and Noise Resistance\nConvolutional networks are particularly well suited for\nrecognizing or rejecting shapes with widely varying size,\nposition, and orientation, such as the ones typically pro-\nduced by heuristic segmenters in real-world string recog-\nnition systems.\nIn an experiment like the one described above, the\nimportance of noise resistance and distortion invariance is\nnot obvious. The situation in most real applications is quite\ndifferent. Characters generally must be segmented out of\ntheir context prior to recognition. Segmentation algorithms\nare rarely perfect and often leave extraneous marks in char-\nacter images (noise, underlines, neighboring characters), or\nsometimes cut characters too much and produce incomplete\ncharacters. Those images cannot be reliably size-normalized\nand centered. Normalizing incomplete characters can be\nvery dangerous. For example, an enlarged stray mark can\nlook like a genuine “1.” Therefore, many systems have\nresorted to normalizing the images at the level of ﬁelds or\nwords. In our case, the upper and lower proﬁles of entire\nﬁelds (i.e., amounts in a check) are detected and used to\nnormalize the image to a ﬁxed height. While this guarantees\nthat stray marks will not be blown up into character-\nlooking images, this also creates wide variations of the\nsize and vertical position of characters after segmentation.\nTherefore it is preferable to use a recognizer that is robust\nto such variations. Fig. 13 shows several examples of\ndistorted characters that are correctly recognized by LeNet-\n5. It is estimated that accurate recognition occurs for\nscale variations up to about a factor of two, vertical shift\nvariations of plus or minus about half the height of the\ncharacter, and rotations up to plus or minus 30 degrees.\nWhile fully invariant recognition of complex shapes is still\nan elusive goal, it seems that convolutional networks offer\na partial answer to the problem of invariance or robustness\nwith respect to geometrical distortions.\nFig. 13 includes examples of the robustness of LeNet-5\nunder extremely noisy conditions. Processing those images\nwould pose insurmountable problems of segmentation and\nfeature extraction to many methods, but LeNet-5 seems\nable to robustly extract salient features from these cluttered\nimages. The training set used for the network shown here\nwas the MNIST training set with salt and pepper noise\nadded. Each pixel was randomly inverted with probability\n0.1.2\nIV.\nMULTIMODULE SYSTEMS AND GRAPH\nTRANSFORMER NETWORKS\nThe classical back-propagation algorithm, as described\nand used in the previous sections, is a simple form of\ngradient-based learning. However, it is clear that the gra-\ndient back-propagation algorithm given by (4) describes a\nmore general situation than simple multilayer feedforward\nnetworks composed of alternated linear transformations and\nsigmoidal functions. In principle, derivatives can be back-\npropagated through any arrangement of functional modules,\nas long as we can compute the product of the Jacobians of\nthose modules by any vector. Why would we want to train\nsystems composed of multiple heterogeneous modules? The\nanswer is that large and complex trainable systems need to\nbe built out of simple, specialized modules. The simplest\nexample is LeNet-5, which mixes convolutional layers,\nsubsampling layers, fully connected layers, and RBF layers.\nAnother less trivial example, described in Sections IV-A\nand IV-B, is a system for recognizing words, that can\nbe trained to simultaneously segment and recognize words\nwithout ever being given the correct segmentation.\nFig. 14 shows an example of a trainable multimodular\nsystem. A multimodule system is deﬁned by the function\nimplemented by each of the modules and by the graph of\ninterconnection of the modules to each other. The graph\nimplicitly deﬁnes a partial order according to which the\nmodules must be updated in the forward pass. For example\nin Fig. 14, module 0 is ﬁrst updated, then modules 1 and\n2 are updated (possibly in parallel), followed by module\n3. Modules may or may not have trainable parameters.\nLoss functions, which measure the performance of the\nsystem, are implemented as module 4. In the simplest case,\nthe loss function module receives an external input that\ncarries the desired output. In this framework, there is no\nqualitative difference between trainable parameters (W1,\n2More\nexamples\nof\nLeNet-5\nin\naction\nare\navailable\nWWW:\nhttp://www.research.att.com/˜yann/ocr.\n2294\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 13.\nExamples of unusual, distorted, and noisy characters correctly recognized by LeNet-5.\nThe grey level of the output label represents the penalty (lighter for higher penalties).\nFig. 14.\nA trainable system composed of heterogeneous modules.\nW2 in the ﬁgure), external inputs and outputs (Z,D,E), and\nintermediate state variables (X1, X2, X3, X4, X5).\nA. An Object-Oriented Approach\nObject-oriented programming offers a particularly con-\nvenient way of implementing multimodule systems. Each\nmodule is an instance of a class. Module classes have\na “forward propagation” method (or member function)\ncalled fprop whose arguments are the inputs and outputs\nof the module. For example, computing the output of\nmodule 3 in Fig. 14 can be done by calling the method\nfprop on module 3 with the arguments X3, X4, X5.\nComplex modules can be constructed from simpler modules\nby simply deﬁning a new class whose slots will contain\nthe member modules and the intermediate state variables\nbetween those modules. The fprop method for the class\nsimply calls the fprop methods of the member modules,\nwith the appropriate intermediate state variables or external\ninput and outputs as arguments. Although the algorithms\nare easily generalizable to any network of such modules,\nincluding those whose inﬂuence graph has cycles, we will\nlimit the discussion to the case of directed acyclic graphs\n(feed-forward networks).\nComputing derivatives in a multimodule system is just as\nsimple. A “backward propagation” method, called bprop,\nfor each module class can be deﬁned for that purpose. The\nbprop method of a module takes the same arguments as\nthe fprop method. All the derivatives in the system can be\ncomputed by calling the bprop method on all the modules\nin reverse order compared to the forward propagation\nphase. The state variables are assumed to contain slots\nfor storing the gradients computed during the backward\npass, in addition to storage for the states computed in the\nforward pass. The backward pass effectively computes the\npartial derivatives of the loss\nwith respect to all the state\nvariables and all the parameters in the system. There is\nan interesting duality property between the forward and\nbackward functions of certain modules. For example, a\nsum of several variables in the forward direction is trans-\nformed into a simple fan-out (replication) in the backward\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2295\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "direction. Conversely, a fan-out in the forward direction\nis transformed into a sum in the backward direction. The\nsoftware environment used to obtain the results described\nin this paper, called SN3.1, uses the above concepts. It\nis based on a home-grown object-oriented dialect of Lisp\nwith a compiler to C.\nThe fact that derivatives can be computed by propagation\nin the reverse graph is easy to understand intuitively. The\nbest way to justify it theoretically is through the use of\nLagrange functions [21], [22]. The same formalism can be\nused to extend the procedures to networks with recurrent\nconnections.\nB. Special Modules\nNN’s and many other standard pattern recognition tech-\nniques can be formulated in terms of multimodular systems\ntrained with gradient-based learning. Commonly used mod-\nules include matrix multiplications and sigmoidal modules,\nthe combination of which can be used to build conven-\ntional NN’s. Other modules include convolutional layers,\nsubsampling layers, RBF layers, and “softmax” layers [65].\nLoss functions are also represented as modules whose\nsingle output produces the value of the loss. Commonly\nused modules have simple bprop methods. In general, the\nbprop method of a function\nis a multiplication by the\nJacobian of\nHere are a few commonly used examples.\nThe bprop method of a fanout (a “Y” connection) is a\nsum, and vice versa. The bprop method of a multipli-\ncation by a coefﬁcient is a multiplication by the same\ncoefﬁcient. The bprop method of a multiplication by a\nmatrix is a multiplication by the transpose of that matrix.\nThe bprop method of an addition with a constant is the\nidentity.\nInterestingly, certain nondifferentiable modules can be\ninserted in a multimodule system without adverse effect.\nAn interesting example of that is the multiplexer module.\nIt has two (or more) regular inputs, one switching input, and\none output. The module selects one of its inputs, depending\nupon the (discrete) value of the switching input, and copies\nit on its output. While this module is not differentiable\nwith respect to the switching input, it is differentiable with\nrespect to the regular inputs. Therefore the overall function\nof a system that includes such modules will be differentiable\nwith respect to its parameters as long as the switching input\ndoes not depend upon the parameters. For example, the\nswitching input can be an external input.\nAnother interesting case is the min module. This module\nhas two (or more) inputs and one output. The output of\nthe module is the minimum of the inputs. The function\nof this module is differentiable everywhere, except on\nthe switching surface which is a set of measure zero.\nInterestingly, this function is continuous and reasonably\nregular, and that is sufﬁcient to ensure the convergence\nof a gradient-based learning algorithm.\nThe object-oriented implementation of the multimodule\nidea can easily be extended to include a bbprop method\nthat propagates Gauss–Newton approximations of the sec-\nond derivatives. This leads to a direct generalization for\nmodular systems of the second-derivative back propagation\n(22) given in Appendix C.\nThe multiplexer module is a special case of a much more\ngeneral situation, described at length in Section IX, where\nthe architecture of the system changes dynamically with the\ninput data. Multiplexer modules can be used to dynamically\nrewire (or reconﬁgure) the architecture of the system for\neach new input pattern.\nC. GTN’s\nMultimodule systems are very ﬂexible tools for build-\ning a large trainable system. However, the descriptions\nin the previous sections implicitly assumed that the set\nof parameters, and the state information communicated\nbetween the modules, are all ﬁxed-size vectors. The limited\nﬂexibility of ﬁxed-size vectors for data representation is\na serious deﬁciency for many applications, notably for\ntasks that deal with variable length inputs (e.g., continuous\nspeech recognition and handwritten word recognition) or for\ntasks that require encoding relationships between objects or\nfeatures whose number and nature can vary (invariant per-\nception, scene analysis, recognition of composite objects).\nAn important special case is the recognition of strings of\ncharacters or words.\nMore generally, ﬁxed-size vectors lack ﬂexibility for\ntasks in which the state must encode probability distribu-\ntions over sequences of vectors or symbols, as is the case in\nlinguistic processing. Such distributions over sequences are\nbest represented by stochastic grammars, or, in the more\ngeneral case, directed graphs in which each arc contains\na vector (stochastic grammars are special cases in which\nthe vector contains probabilities and symbolic information).\nEach path in the graph represents a different sequence of\nvectors. Distributions over sequences can be represented\nby interpreting elements of the data associated with each\narc as parameters of a probability distribution or simply\nas a penalty. Distributions over sequences are particularly\nhandy for modeling linguistic knowledge in speech or\nhandwriting recognition systems: each sequence, i.e., each\npath in the graph, represents an alternative interpretation\nof the input. Successive processing modules progressively\nreﬁne the interpretation. For example, a speech recognition\nsystem might start with a single sequence of acoustic\nvectors, transform it into a lattice of phonemes (distribution\nover phoneme sequences), then into a lattice of words\n(distribution over word sequences), and then into a single\nsequence of words representing the best interpretation.\nIn our work on building large-scale handwriting recog-\nnition systems, we have found that these systems could be\ndeveloped and designed much more easily and quickly by\nviewing the system as a networks of modules that take one\nor several graphs as input and produce graphs as output.\nSuch modules are called GT’s, and the complete systems\nare called GTN’s. Modules in a GTN communicate their\nstates and gradients in the form of directed graphs whose\narcs carry numerical information (scalars or vectors) [66].\nFrom the statistical point of view, the ﬁxed-size state vec-\ntors of conventional networks can be seen as representing\n2296\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "(a)\n(b)\nFig. 15.\nTraditional NN’s and multimodule systems communi-\ncate ﬁxed-size vectors between layers. Multilayer GTN’s are\ncomposed of trainable modules that operate on and produce graphs\nwhose arcs carry numerical information.\nthe means of distributions in state space. In variable-size\nnetworks such as the space-displacement NN’s described\nin Section VII, the states are variable-length sequences\nof ﬁxed size vectors. They can be seen as representing\nthe mean of a probability distribution over variable-length\nsequences of ﬁxed-size vectors. In GTN’s the states are\nrepresented as graphs, which can be seen as represent-\ning mixtures of probability distributions over structured\ncollections (possibly sequences) of vectors (Fig. 15).\nOne of the main points of the next several sections is\nto show that gradient-based learning procedures are not\nlimited to networks of simple modules that communicate\nthrough ﬁxed-size vectors but can be generalized to\nGTN’s. Gradient back propagation through a GT takes\ngradients with respect to the numerical information in\nthe output graph and computes gradients with respect to\nthe numerical information attached to the input graphs,\nand with respect to the module’s internal parameters.\nGradient-based\nlearning\ncan\nbe\napplied\nas\nlong\nas\ndifferentiable functions are used to produce the numerical\ndata in the output graph from the numerical data in the\ninput graph and the functions parameters.\nThe second point of the next several sections is to show\nthat the functions implemented by many of the modules\nused in typical document processing systems (and other\nimage recognition systems), though commonly thought to\nbe combinatorial in nature, are indeed differentiable with\nrespect to their internal parameters as well as with respect\nto their inputs, and are therefore usable as part of a globally\ntrainable system.\nIn most of the following, we will purposely avoid making\nreferences to probability theory. All the quantities manipu-\nlated are viewed as penalties, or costs, which if necessary\ncan be transformed into probabilities by taking exponentials\nand normalizing.\nV.\nMULTIPLE OBJECT RECOGNITION: HOS\nOne of the most difﬁcult problems of handwriting recog-\nnition is to recognize not just isolated characters, but\nFig. 16.\nBuilding a segmentation graph with HOS.\nstrings of characters such as zip codes, check amounts,\nor words. Since most recognizers can only deal with one\ncharacter at a time, we must ﬁrst segment the string\ninto individual character images. However, it is almost\nimpossible to devise image analysis techniques that will\ninfallibly segment naturally written sequences of characters\ninto well formed characters.\nThe recent history of automatic speech recognition [28],\n[67] is here to remind us that training a recognizer by\noptimizing a global criterion (at the word or sentence level)\nis much preferable to merely training it on hand-segmented\nphonemes or other units. Several recent works have shown\nthat the same is true for handwriting recognition [38]:\noptimizing a word-level criterion is preferable to solely\ntraining a recognizer on presegmented characters because\nthe recognizer can learn not only to recognize individual\ncharacters, but also to reject missegmented characters,\nthereby minimizing the overall word error.\nThis section and Section VI describe in detail a simple\nexample of GTN to address the problem of reading strings\nof characters, such as words or check amounts. The method\navoids the expensive and unreliable task of hand-truthing\nthe result of the segmentation often required in more\ntraditional systems trained on individually labeled character\nimages.\nA. Segmentation Graph\nA now classical method for segmentation and recognition\nis called HOS [68], [69]. Its main advantages over other\napproaches to segmentation are that it avoids making hard\ndecisions about the segmentation by taking a large number\nof different segmentations into consideration. The idea is to\nuse heuristic image processing techniques to ﬁnd candidate\ncuts of the word or string, and then to use the recognizer to\nscore the alternative segmentations thereby generated. The\nprocess is depicted in Fig. 16. First, a number of candidate\ncuts are generated. Good candidate locations for cuts can be\nfound by locating minima in the vertical projection proﬁle,\nor minima of the distance between the upper and lower\ncontours of the word. Better segmentation heuristics are\ndescribed in Section XI. The cut generation heuristic is\ndesigned so as to generate more cuts than necessary in the\nhope that the “correct” set of cuts will be included. Once the\ncuts have been generated, alternative segmentations are best\nrepresented by a graph, called the segmentation graph. The\nsegmentation graph is a directed acyclic graph with a start\nnode and an end node. Each internal node is associated with\na candidate cut produced by the segmentation algorithm.\nEach arc between a source node and a destination node\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2297\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 17.\nRecognizing a character string with a GTN. For read-\nability, only the arcs with low penalties are shown.\nis associated with an image that contains all the ink\nbetween the cut associated with the source node and the\ncut associated with the destination node. An arc is created\nbetween two nodes if the segmentor decided that the ink\nbetween the corresponding cuts could form a candidate\ncharacter. Typically, each individual piece of ink would\nbe associated with an arc. Pairs of successive pieces of\nink would also be included, unless they are separated by a\nwide gap, which is a clear indication that they belong to\ndifferent characters. Each complete path through the graph\ncontains each piece of ink once and only once. Each path\ncorresponds to a different way of associating pieces of ink\ntogether so as to form characters.\nB. Recognition Transformer and Viterbi Transformer\nA simple GTN to recognize character strings is shown in\nFig. 17. It is composed of two GT’s called the recognition\ntransformer\nand the Viterbi transformer\nThe goal\nof the recognition transformer is to generate a graph, called\nthe interpretation graph or recognition graph\nthat\ncontains all the possible interpretations for all the possible\nsegmentations of the input. Each path in\nrepresents\none possible interpretation of one particular segmentation\nFig. 18.\nThe recognition transformer reﬁnes each arc of the\nsegmentation arc into a set of arcs in the interpretation graph, one\nper character class, with attached penalties and labels.\nof the input. The role of the Viterbi transformer is to extract\nthe best interpretation from the interpretation graph.\nThe recognition transformer\ntakes the segmentation\ngraph\nas input, and applies the recognizer for single\ncharacters to the images associated with each of the arcs in\nthe segmentation graph. The interpretation graph\nhas\nalmost the same structure as the segmentation graph, except\nthat each arc is replaced by a set of arcs from and to the\nsame node. In this set of arcs, there is one arc for each pos-\nsible class for the image associated with the corresponding\narc in\nAs shown in Fig. 18, to each arc is attached\na class label, and the penalty that the image belongs to\nthis class as produced by the recognizer. If the segmentor\nhas computed penalties for the candidate segments, these\npenalties are combined with the penalties computed by the\ncharacter recognizer to obtain the penalties on the arcs of\nthe interpretation graph. Although combining penalties of\ndifferent nature seems highly heuristic, the GTN training\nprocedure will tune the penalties and take advantage of this\ncombination anyway. Each path in the interpretation graph\ncorresponds to a possible interpretation of the input word.\nThe penalty of a particular interpretation for a particular\nsegmentation is given by the sum of the arc penalties\nalong the corresponding path in the interpretation graph.\nComputing the penalty of an interpretation independently\nof the segmentation requires to combine the penalties of\nall the paths with that interpretation. An appropriate rule\nfor combining the penalties of parallel paths is given in\nSection VI-C.\n2298\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "The Viterbi transformer produces a graph\nwith a\nsingle path. This path is the path of least cumulated penalty\nin the Interpretation graph. The result of the recognition\ncan be produced by reading off the labels of the arcs along\nthe graph\nextracted by the Viterbi transformer. The\nViterbi transformer owes its name to the famous Viterbi\nalgorithm [70], an application of the principle of dynamic\nprogramming to ﬁnd the shortest path in a graph efﬁciently.\nLet\nbe the penalty associated to arc\nwith source\nnode\nand destination node\n(note that there can be\nmultiple arcs between two nodes). In the interpretation\ngraph, arcs also have a label\nThe Viterbi algorithm\nproceeds as follows. Each node\nis associated with a\ncumulated Viterbi penalty\nThose cumulated penalties\nare computed in any order that satisﬁes the partial order\ndeﬁned by the interpretation graph (which is directed and\nacyclic). The start node is initialized with the cumulated\npenalty\nThe other nodes cumulated penalties\nare computed recursively from the\nvalues of their\nparent nodes, through the upstream arcs\nwith\ndestination\n(10)\nFurthermore, the value of\nfor each node\nwhich min-\nimizes the right-hand side is noted\nthe minimizing\nentering arc. When the end node is reached we obtain in\nthe total penalty of the path with the smallest total\npenalty. We call this penalty the Viterbi penalty, and this\nsequence of arcs and nodes the Viterbi path. To obtain the\nViterbi path with nodes\nand arcs\nwe\ntrace back these nodes and arcs as follows, starting with\nthe end node, and recursively using the minimizing\nentering arc:\nand\nuntil the start node\nis reached. The label sequence can then be read off the arcs\nof the Viterbi path.\nVI.\nGLOBAL TRAINING FOR GRAPH\nTRANSFORMER NETWORKS\nSection V described the process of recognizing a string\nusing HOS, assuming that the recognizer is trained so\nas to give low penalties for the correct class label of\ncorrectly segmented characters, high penalties for erroneous\ncategories of correctly segmented characters, and high\npenalties for all categories for poorly formed characters.\nThis section explains how to train the system at the string\nlevel to do the above without requiring manual labeling of\ncharacter segments. This training will be performed with\na GTN whose architecture is slightly different from the\nrecognition architecture described in Section V.\nIn many applications, there is enough a priori knowledge\nabout what is expected from each of the modules in order\nto train them separately. For example, with HOS one\ncould individually label single-character images and train\na character recognizer on them, but it might be difﬁcult\nto obtain an appropriate set of noncharacter images to\ntrain the model to reject wrongly segmented candidates.\nAlthough separate training is simple, it requires additional\nsupervision information that is often lacking or incomplete\n(the correct segmentation and the labels of incorrect candi-\ndate segments). Furthermore, it can be shown that separate\ntraining is suboptimal [67].\nThe following section describes four different gradient-\nbased methods for training GTN-based handwriting recog-\nnizers at the string level: Viterbi training, discriminative\nViterbi training, forward training, and discriminative for-\nward training. The last one is a generalization to graph-\nbased systems of the maximum a posteriori criterion in-\ntroduced in Section II-C. Discriminative forward training\nis somewhat similar to the so-called maximum mutual\ninformation criterion used to train HMM in speech recog-\nnition. However, our rationale differs from the classical\none. We make no recourse to a probabilistic interpretation\nbut show that, within the gradient-based learning approach,\ndiscriminative training is a simple instance of the pervasive\nprinciple of error correcting learning.\nTraining methods for graph-based sequence recognition\nsystems such as HMM’s have been extensively studied\nin the context of speech recognition [28]. Those meth-\nods require that the system be based on probabilistic\ngenerative models of the data, which provide normalized\nlikelihoods over the space of possible input sequences.\nPopular HMM learning methods, such as the Baum–Welsh\nalgorithm, rely on this normalization. The normalization\ncannot be preserved when nongenerative models such as\nNN’s are integrated into the system. Other techniques, such\nas discriminative training methods, must be used in this\ncase. Several authors have proposed such methods to train\nNN/HMM speech recognizers at the word or sentence level\n[29], [67], [71]–[78].\nOther globally trainable sequence recognition systems\navoid the difﬁculties of statistical modeling by not resorting\nto graph-based techniques. The best example is recurrent\nNN’s (RNN’s). Unfortunately, despite early enthusiasm,\nthe training of RNN’s with gradient-based techniques has\nproven very difﬁcult in practice [79].\nThe GTN techniques presented below simplify and gen-\neralize the global training methods developed for speech\nrecognition.\nA. Viterbi Training\nDuring recognition, we select the path in the interpre-\ntation graph that has the lowest penalty with the Viterbi\nalgorithm. Ideally, we would like this path of lowest penalty\nto be associated with the correct label sequence as often as\npossible. An obvious loss function to minimize is therefore\nthe average over the training set of the penalty of the\npath associated with the correct label sequence that has the\nlowest penalty. The goal of training will be to ﬁnd the set of\nrecognizer parameters (the weights, if the recognizer is an\nNN) that minimize the average penalty of this “correct”\nlowest penalty path. The gradient of this loss function\ncan be computed by back propagation through the GTN\narchitecture shown in Fig. 19. This training architecture is\nalmost identical to the recognition architecture described\nin the previous section, except that an extra GT called a\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2299\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 19.\nViterbi training GTN architecture for a character string\nrecognizer based on HOS.\npath selector is inserted between the interpretation graph\nand the Viterbi transformer. This transformer takes the\ninterpretation graph and the desired label sequence as input.\nIt extracts from the interpretation graph those paths that\ncontain the correct (desired) label sequence. Its output\ngraph\nis called the constrained interpretation graph (also\nknown as forced alignment in the HMM literature) and\ncontains all the paths that correspond to the correct label\nsequence. The constrained interpretation graph is then sent\nto the Viterbi transformer which produces a graph\nwith a single path. This path is the “correct” path with\nthe lowest penalty. Finally, a path scorer transformer takes\nand simply computes its cumulated penalty\nby\nadding up the penalties along the path. The output of this\nGTN is the loss function for the current pattern\n(11)\nThe only label information that is required by the above\nsystem is the sequence of desired character labels. No\nknowledge of the correct segmentation is required on\nthe part of the supervisor, since it chooses among the\nsegmentations in the interpretation graph the one that yields\nthe lowest penalty.\nThe process of back propagating gradients through the\nViterbi training GTN is now described. As explained in\nSection IV, the gradients must be propagated backward\nthrough all modules of the GTN in order to compute\ngradients in preceding modules and thereafter tune their\nparameters. Back propagating gradients through the path\nscorer is quite straightforward. The partial derivatives of\nthe loss function with respect to the individual penalties on\nthe constrained Viterbi path\nare equal to one, since\nthe loss function is simply the sum of those penalties. Back\npropagating through the Viterbi Transformer is equally\nsimple. The partial derivatives of\nwith respect to the\npenalties on the arcs of the constrained graph\nare one for\nthose arcs that appear in the constrained Viterbi path\nand zero for those that do not. Why is it legitimate to back\npropagate through an essentially discrete function such as\nthe Viterbi transformer? The answer is that the Viterbi trans-\nformer is nothing more than a collection of min functions\nand adders put together. It was shown in Section IV that\ngradients can be back propagated through min functions\nwithout adverse effects. Back propagation through the path\nselector transformer is similar to back propagation through\nthe Viterbi transformer. Arcs in\nthat appear in\nhave the same gradient as the corresponding arc in\ni.e., one or zero, depending on whether the arc appear\nin\nThe other arcs, i.e., those that do not have an\nalter ego in\nbecause they do not contain the right label\nhave a gradient of zero. During the forward propagation\nthrough the recognition transformer, one instance of the\nrecognizer for single character was created for each arc in\nthe segmentation graph. The state of recognizer instances\nwas stored. Since each arc penalty in\nis produced by\nan individual output of a recognizer instance, we now have\na gradient (one or zero) for each output of each instance\nof the recognizer. Recognizer outputs that have a nonzero\ngradient are part of the correct answer and will therefore\nhave their value pushed down. The gradients present on\nthe recognizer outputs can be back propagated through\neach recognizer instance. For each recognizer instance, we\nobtain a vector of partial derivatives of the loss function\nwith respect to the recognizer instance parameters. All the\nrecognizer instances share the same parameter vector, since\nthey are merely clones of each other, therefore the full\ngradient of the loss function with respect to the recognizer’s\nparameter vector is simply the sum of the gradient vectors\nproduced by each recognizer instance. Viterbi training,\nthough formulated differently, is often use in HMM-based\nspeech recognition systems [28]. Similar algorithms have\nbeen applied to speech recognition systems that integrate\nNN’s with time alignment [71], [72], [76] or hybrid neural-\nnetwork/HMM systems [29], [74], [75].\nWhile it seems simple and satisfying, this training archi-\ntecture has a ﬂaw that can potentially be fatal. The problem\nwas already mentioned in Section II-C. If the recognizer\nis a simple NN with sigmoid output units, the minimum\nof the loss function is attained, not when the recognizer\nalways gives the right answer, but when it ignores the\ninput and sets its output to a constant vector with small\nvalues for all the components. This is known as the collapse\nproblem. The collapse only occurs if the recognizer outputs\ncan simultaneously take their minimum value. If, on the\nother hand, the recognizer’s output layer contains RBF\nunits with ﬁxed parameters, then there is no such trivial\nsolution. This is due to the fact that a set of RBF with\nﬁxed distinct parameter vectors cannot simultaneously take\ntheir minimum value. In this case, the complete collapse\ndescribed above does not occur. However, this does not\ntotally prevent the occurrence of a milder collapse because\nthe loss function still has a “ﬂat spot” for a trivial solution\nwith constant recognizer output. This ﬂat spot is a saddle\npoint, but it is attractive in almost all directions and is very\ndifﬁcult to get out of using gradient-based minimization\nprocedures. If the parameters of the RBF’s are allowed\n2300\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "to adapt, then the collapse problems reappear because the\nRBF centers can all converge to a single vector, and the\nunderlying NN can learn to produce that vector and ignore\nthe input. A different kind of collapse occurs if the width\nof the RBF’s are also allowed to adapt. The collapse only\noccurs if a trainable module such as an NN feeds the\nRBF’s. The collapse does not occur in HMM-based speech\nrecognition systems because they are generative systems\nthat produce normalized likelihoods for the input data (more\non this later). Another way to avoid the collapse is to train\nthe whole system with respect to a discriminative training\ncriterion, such as maximizing the conditional probability of\nthe correct interpretations (correct sequence of class labels)\ngiven the input image.\nAnother problem with Viterbi training is that the penalty\nof the answer cannot be used reliably as a measure of\nconﬁdence because it does not take low-penalty (or high-\nscoring) competing answers into account.\nB. Discriminative Viterbi Training\nA modiﬁcation of the training criterion can circumvent\nthe collapse problem described above and at the same time\nproduce more reliable conﬁdence values. The idea is to\nnot only minimize the cumulated penalty of the lowest\npenalty path with the correct interpretation, but also to\nsomehow increase the penalty of competing and possibly\nincorrect paths that have a dangerously low penalty. This\ntype of criterion is called discriminative because it plays the\ngood answers against the bad ones. Discriminative training\nprocedures can be seen as attempting to build appropriate\nseparating surfaces between classes rather than to model in-\ndividual classes independently of each other. For example,\nmodeling the conditional distribution of the classes given\nthe input image is more discriminative (focusing more on\nthe classiﬁcation surface) than having a separate generative\nmodel of the input data associated to each class (which, with\nclass priors, yields the whole joint distribution of classes\nand inputs). This is because the conditional approach does\nnot need to assume a particular form for the distribution of\nthe input data.\nOne example of discriminative criterion is the difference\nbetween the penalty of the Viterbi path in the constrained\ngraph, and the penalty of the Viterbi path in the (uncon-\nstrained) interpretation graph, i.e., the difference between\nthe penalty of the best correct path and the penalty of\nthe best path (correct or incorrect). The corresponding\nGTN training architecture is shown in Fig. 20. The left\nside of the diagram is identical to the GTN used for\nnondiscriminative Viterbi training. This loss function re-\nduces the risk of collapse because it forces the recognizer\nto increases the penalty of wrongly recognized objects.\nDiscriminative training can also be seen as another example\nof error correction procedure, which tends to minimize the\ndifference between the desired output computed in the left\nhalf of the GTN in Fig. 20 and the actual output computed\nin the right half of Fig. 20.\nLet the discriminative Viterbi loss function be denoted\nand let us call\nthe penalty of the Viterbi path\nin the constrained graph and\nthe penalty of the Viterbi\npath in the unconstrained interpretation graph\n(12)\nis always positive since the constrained graph is a\nsubset of the paths in the interpretation graph, and the\nViterbi algorithm selects the path with the lowest total\npenalty. In the ideal case, the two paths\nand\ncoincide, and\nis zero.\nBack-propagating gradients through the discriminative\nViterbi GTN adds some “negative” training to the previ-\nously described nondiscriminative training. Fig. 20 shows\nhow the gradients are back propagated. The left half is\nidentical to the nondiscriminative Viterbi training GTN,\ntherefore the back propagation is identical. The gradients\nback propagated through the right half of the GTN are\nmultiplied by\n1, since\ncontributes to the loss with\na negative sign. Otherwise the process is similar to the left\nhalf. The gradients on arcs of\nget positive contributions\nfrom the left half and negative contributions from the\nright half. The two contributions must be added since the\npenalties on\narcs are sent to the two halves through\na “Y” connection in the forward pass. Arcs in\nthat\nappear neither in\nnor in\nhave a gradient of zero.\nThey do not contribute to the cost. Arcs that appear in both\nand\nalso have zero gradient. The\n1 contribution\nfrom the right half cancels the\n1 contribution from the left\nhalf. In other words, when an arc is rightfully part of the\nanswer there is no gradient. If an arc appears in\nbut\nnot in\nthe gradient is\n1. The arc should have had a\nlower penalty to make it to\nIf an arc is in\nbut\nnot in\nthe gradient is\nThe arc had a low penalty,\nbut it should have had a higher penalty since it is not part\nof the desired answer.\nVariations of this technique have been used for the speech\nrecognition. Driancourt and Bottou [76] used a version of\nit where the loss function is saturated to a ﬁxed value.\nThis can be seen as a generalization of the Learning Vector\nQuantization 2 (LVQ-2) loss function [80]. Other variations\nof this method use not only the Viterbi path but the K-\nbest paths. The discriminative Viterbi algorithm does not\nhave the ﬂaws of the nondiscriminative version, but there\nare problems nonetheless. The main problem is that the\ncriterion does not build a margin between the classes. The\ngradient is zero as soon as the penalty of the constrained\nViterbi path is equal to that of the Viterbi path. It would be\ndesirable to push up the penalties of the wrong paths when\nthey are dangerously close to the good one. The following\nsection presents a solution to this problem.\nC. Forward Scoring and Forward Training\nWhile the penalty of the Viterbi path is perfectly appro-\npriate for the purpose of recognition it gives only a partial\npicture of the situation. Imagine the lowest penalty paths\ncorresponding to several different segmentations produced\nthe same answer (the same label sequence). Then it could be\nargued that the overall penalty for the interpretation should\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2301\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 20.\nDiscriminative Viterbi training GTN architecture for a character string recognizer based\non HOS. Quantities in square brackets are penalties computed during the forward propagation.\nQuantities in parentheses are partial derivatives computed during the backward propagation.\nbe smaller than the penalty obtained when only one path\nproduced that interpretation, because multiple paths with\nidentical label sequences are more evidence that the label\nsequence is correct. Several rules can be used compute\nthe penalty associated to a graph that contains several\nparallel paths. We use a combination rule borrowed from\na probabilistic interpretation of the penalties as negative\nlog posteriors. In a probabilistic framework, the posterior\nprobability for the interpretation should be the sum of the\nposteriors for all the paths that produce that interpretation.\nTranslated in terms of penalties, the penalty of an inter-\npretation should be the negative logarithm of the sum of\nthe negative exponentials of the penalties of the individual\npaths. The overall penalty will be smaller than all the\npenalties of the individual paths.\nGiven an interpretation, there is a well-known method,\ncalled the forward algorithm for computing the above\nquantity efﬁciently [28]. The penalty computed with this\nprocedure for a particular interpretation is called the for-\nward penalty. Consider again the concept of constrained\n2302\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "graph, the subgraph of the interpretation graph which\ncontains only the paths that are consistent with a particular\nlabel sequence. There is one constrained graph for each\npossible label sequence (some may be empty graphs, which\nhave inﬁnite penalties). Given an interpretation, running\nthe forward algorithm on the corresponding constrained\ngraph gives the forward penalty for that interpretation.\nThe forward algorithm proceeds in a way very similar to\nthe Viterbi algorithm, except that the operation used at\neach node to combine the incoming cumulated penalties,\ninstead of being the min function, is the so-called logadd\noperation, which can be seen as a “soft” version of the min\nfunction\n(13)\nwhere\nis the set of upstream arcs of node\nis the penalty on arc\nand\n(14)\nNote that because of numerical inaccuracies, it is better\nto factorize the largest\n(corresponding to the smallest\npenalty) out of the logarithm.\nAn interesting analogy can be drawn if we consider\nthat a graph on which we apply the forward algorithm is\nequivalent to an NN on which we run a forward propaga-\ntion, except that multiplications are replaced by additions,\nthe additions are replaced by log-adds, and there are no\nsigmoids.\nOne way to understand the forward algorithm is to think\nabout multiplicative scores (e.g., probabilities) instead of\nadditive penalties on the arcs: score\nIn that case the Viterbi algorithm selects the path with\nthe largest cumulative score (with scores multiplied along\nthe path), whereas the forward score is the sum of the\ncumulative scores associated to each of the possible paths\nfrom the start to the end node. The forward penalty is\nalways lower than the cumulated penalty on any of the\npaths, but if one path “dominates” (with a much lower\npenalty), its penalty is almost equal to the forward penalty.\nThe forward algorithm gets its name from the forward\npass of the well-known Baum–Welsh algorithm for training\nHMM’s [28]. Section VIII-E gives more details on the\nrelation between this work and HMM’s.\nThe advantage of the forward penalty with respect to the\nViterbi penalty is that it takes into account all the different\nways to produce an answer, not just the one with the lowest\npenalty. This is important if there is some ambiguity in the\nsegmentation, since the combined forward penalty of two\npaths\nand\nassociated with the same label sequence\nmay be less than the penalty of a path\nassociated with\nanother label sequence, even though the penalty of\nmight be less than any one of\nor\nThe forward-training GTN is only a slight modiﬁcation of\nthe previously introduced Viterbi-training GTN. It sufﬁces\nto turn the Viterbi transformers in Fig. 19 into forward\nscorers that take an interpretation graph as input an produce\nthe forward penalty of that graph on output. Then the\npenalties of all the paths that contain the correct answer\nare lowered, instead of just that of the best one.\nBack propagating through the forward penalty computa-\ntion (the forward transformer) is quite different from back\npropagating through a Viterbi transformer. All the penalties\nof the input graph have an inﬂuence on the forward penalty,\nbut penalties that belong to low-penalty paths have a\nstronger inﬂuence. Computing derivatives with respect to\nthe forward penalties\ncomputed at each\nnode of a\ngraph is done by back-propagation through the graph\n(15)\nwhere\nwith source\nis the set of\ndownstream arcs from node\nFrom the above derivatives,\nthe derivatives with respect to the arc penalties are obtained\n(16)\nThis can be seen as a “soft” version of the back propagation\nthrough a Viterbi scorer and transformer. All the arcs in\nhave an inﬂuence on the loss function. The arcs that\nbelong to low penalty paths have a larger inﬂuence. Back\npropagation through the path selector is the same as before.\nThe derivative with respect to\narcs that have an alter\nego in\nare simply copied from the corresponding arc in\nThe derivatives with respect to the other arcs are zero.\nSeveral authors have applied the idea of back-propagating\ngradients through a forward scorer to train speech recogni-\ntion systems, including Bridle and his\n-net model [73] and\nHaffner and his\n-TDNN model [81], but these authors\nrecommended discriminative training as described in the\nnext section.\nD. Discriminative Forward Training\nThe information contained in the forward penalty can be\nused in another discriminative training criterion which we\nwill call the discriminative forward criterion. This criterion\ncorresponds to maximization of the posterior probability of\nchoosing the paths associated with the correct interpreta-\ntion. This posterior probability is deﬁned as the exponential\nof minus the constrained forward penalty, normalized by the\nexponential of minus the unconstrained forward penalty.\nNote that the forward penalty of the constrained graph\nis always larger or equal to the forward penalty of the\nunconstrained interpretation graph. Ideally, we would like\nthe forward penalty of the constrained graph to be equal\nto the forward penalty of the complete interpretation graph.\nEquality between those two quantities is achieved when\nthe combined penalties of the paths with the correct label\nsequence is negligibly small compared to the penalties of all\nthe other paths, or that the posterior probability associated\nto the paths with the correct interpretation is almost one,\nwhich is precisely what we want. The corresponding GTN\ntraining architecture is shown in Fig. 21.\nLet the difference be denoted\nand let us call\nthe forward penalty of the constrained graph and\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2303\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 21.\nDiscriminative forward training GTN architecture for a\ncharacter string recognizer based on HOS.\nthe forward penalty of the complete interpretation\ngraph\n(17)\nis always positive since the constrained graph is\na subset of the paths in the interpretation graph, and the\nforward penalty of a graph is always larger than the forward\npenalty of a subgraph of this graph. In the ideal case, the\npenalties of incorrect paths are inﬁnitely large, therefore\nthe two penalties coincide and\nis zero. Readers\nfamiliar with the Boltzmann machine connectionist model\nmight recognize the constrained and unconstrained graphs\nas analogous to the “clamped” (constrained by the observed\nvalues of the output variable) and “free” (unconstrained)\nphases of the Boltzmann machine algorithm [13].\nBack propagating derivatives through the discriminative\nforward GTN distributes gradients more evenly than in the\nViterbi case. Derivatives are back propagated through the\nleft half of the GTN in Fig. 21 down to the interpretation\ngraph. Derivatives are negated and back propagated through\nthe right-half, and the result for each arc is added to the\ncontribution from the left half. Each arc in\nnow has\na derivative. Arcs that are part of a correct path have\na positive derivative. This derivative is very large if an\nincorrect path has a lower penalty than all the correct\npaths. Similarly, the derivatives with respect to arcs that are\npart of a low-penalty incorrect path have a large negative\nderivative. On the other hand, if the penalty of a path\nassociated with the correct interpretation is much smaller\nthan all other paths, the loss function is very close to zero\nand almost no gradient is back propagated. The training\ntherefore concentrates on examples of images which yield\na classiﬁcation error, and furthermore, it concentrates on the\npieces of the image which cause that error. Discriminative\nforward training is an elegant and efﬁcient way of solving\nthe infamous credit assignment problem for learning ma-\nchines that manipulate “dynamic” data structures such as\ngraphs. More generally, the same idea can be used in all\nsituations where a learning machine must choose between\ndiscrete alternative interpretations.\nAs previously, the derivatives on the interpretation graph\npenalties can then be back propagated into the character\nrecognizer instances. Back propagation through the charac-\nter recognizer gives derivatives on its parameters. All the\ngradient contributions for the different candidate segments\nare added up to obtain the total gradient associated to\none pair (input image, correct label sequence), that is, one\nexample in the training set. A step of stochastic gradient\ndescent can then be applied to update the parameters.\nE. Remarks on Discriminative Training\nIn the above discussion, the global training criterion\nwas given a probabilistic interpretation, but the individual\npenalties on the arcs of the graphs were not. There are\ngood reasons for that. For example, if some penalties are\nassociated to the different class labels, they would: 1) have\nto sum to one (class posteriors) or 2) integrate to one over\nthe input domain (likelihoods).\nLet us ﬁrst discuss the ﬁrst case (class posteriors nor-\nmalization). This local normalization of penalties may\neliminate information that is important for locally rejecting\nall the classes [82], e.g., when a piece of image does\nnot correspond to a valid character class because some of\nthe segmentation candidates may be wrong. Although an\nexplicit “garbage class” can be introduced in a probabilistic\nframework to address that question, some problems remain\nbecause it is difﬁcult to characterize such a class probabilis-\ntically and to train a system in this way (it would require\na density model of unseen or unlabeled samples).\nThe probabilistic interpretation of individual variables\nplays an important role in the Baum–Welsh algorithm\nin combination with the expectation-maximization (EM)\nprocedure. Unfortunately, those methods cannot be applied\nto discriminative training criteria, and one is reduced to\nusing gradient-based methods. Enforcing the normalization\nof the probabilistic quantities while performing gradient-\nbased learning is complex, inefﬁcient, time consuming, and\ncreates ill-conditioning of the loss-function.\nFollowing [82], we therefore prefer to postpone normal-\nization as far as possible (in fact, until the ﬁnal decision\nstage of the system). Without normalization, the quantities\nmanipulated in the system do not have a direct probabilistic\ninterpretation.\nLet us now discuss the second case (using a generative\nmodel of the input). Generative models build the boundary\nindirectly by ﬁrst building an independent density model\nfor each class and then performing classiﬁcation decisions\non the basis of these models. This is not a discriminative\napproach in that it does not focus on the ultimate goal of\nlearning, which in this case is to learn the classiﬁcation\ndecision surface. Theoretical arguments [6], [7] suggest that\nestimating input densities when the real goal is to obtain\na discriminant function for classiﬁcation is a suboptimal\nstrategy. In theory, the problem of estimating densities\nin high-dimensional spaces is much more ill posed than\nﬁnding decision boundaries.\n2304\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 22.\nExplicit segmentation can be avoided by sweeping a\nrecognizer at every possible location in the input ﬁeld.\nEven though the internal variables of the system do not\nhave a direct probabilistic interpretation, the overall system\ncan still be viewed as producing posterior probabilities\nfor the classes. In fact, assuming that a particular label\nsequence is given as the “desired sequence” to the GTN in\nFig. 21, the exponential of minus\ncan be interpreted\nas an estimate of the posterior probability of that label\nsequence given the input. The sum of those posteriors for\nall the possible label sequences is one. Another approach\nwould consists of directly minimizing an approximation\nof the number of misclassiﬁcations [83], [76]. We prefer\nto use the discriminative forward loss function because it\ncauses less numerical problems during the optimization. We\nwill see in Section X-C that this is a good way to obtain\nscores on which to base a rejection strategy. The important\npoint being made here is that one is free to choose any\nparameterization deemed appropriate for a classiﬁcation\nmodel. The fact that a particular parameterization uses\ninternal variables with no clear probabilistic interpretation\ndoes not make the model any less legitimate than models\nthat manipulate normalized quantities.\nAn important advantage of global and discriminative\ntraining is that learning focuses on the most important\nerrors, and the system learns to integrate the ambiguities\nfrom the segmentation algorithm with the ambiguities of\nthe character recognizer. In Section IX we present ex-\nperimental results with an online handwriting recognition\nsystem that conﬁrm the advantages of using global training\nversus separate training. Experiments in speech recognition\nwith hybrids of NN’s and HMM’s also showed marked\nimprovements brought by global training [29], [67], [77],\n[84].\nVII.\nMULTIPLE OBJECT RECOGNITION: SPACE\nDISPLACEMENT NEURAL NETWORK\nThere is a simple alternative to explicitly segmenting\nimages of character strings using heuristics. The idea is\nto sweep a recognizer at all possible locations across a\nnormalized image of the entire word or string as shown\nin Fig. 22. With this technique, no segmentation heuristics\nare required since the system essentially examines all the\npossible segmentations of the input. However, there are\nproblems with this approach. First, the method is in general\nFig. 23.\nAn SDNN is a convolutional network that has been\nreplicated over a wide input ﬁeld.\nquite expensive. The recognizer must be applied at every\npossible location on the input, or at least at a large enough\nsubset of locations so that misalignments of characters\nin the ﬁeld of view of the recognizers are small enough\nto have no effect on the error rate. Second, when the\nrecognizer is centered on a character to be recognized,\nthe neighbors of the center character will be present in the\nﬁeld of view of the recognizer, possibly touching the center\ncharacter. Therefore the recognizer must be able to correctly\nrecognize the character in the center of its input ﬁeld, even\nif neighboring characters are very close to or touching the\ncentral character. Third, a word or character string cannot\nbe perfectly size-normalized. Individual characters within a\nstring may have widely varying sizes and baseline positions.\nTherefore the recognizer must be very robust to shifts and\nsize variations.\nThese three problems are elegantly circumvented if a\nconvolutional network is replicated over the input ﬁeld.\nFirst of all, as shown in Section III, convolutional NN’s are\nvery robust to shifts and scale variations of the input image,\nas well as to noise and extraneous marks in the input. These\nproperties take care of the latter two problems mentioned\nin the previous paragraph. Second, convolutional networks\nprovide a drastic saving in computational requirement when\nreplicated over large input ﬁelds. A replicated convolutional\nnetwork, also called an SDNN [27], is shown in Fig. 23.\nWhile scanning a recognizer can be prohibitively expen-\nsive in general, convolutional networks can be scanned or\nreplicated very efﬁciently over large, variable-size input\nﬁelds. Consider one instance of a convolutional net and its\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2305\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "alter ego at a nearby location. Because of the convolutional\nnature of the network, units in the two instances that look\nat identical locations on the input have identical outputs,\ntherefore their states do not need to be computed twice.\nOnly a thin “slice” of new states that are not shared by\nthe two network instances needs to be recomputed. When\nall the slices are put together, the result is simply a larger\nconvolutional network whose structure is identical to the\noriginal network, except that the feature maps are larger\nin the horizontal dimension. In other words, replicating a\nconvolutional network can be done simply by increasing the\nsize of the ﬁelds over which the convolutions are performed\nand by replicating the output layer accordingly. The output\nlayer effectively becomes a convolutional layer. An output\nwhose receptive ﬁeld is centered on an elementary object\nwill produce the class of this object, while an in-between\noutput may indicate no character or contain rubbish. The\noutputs can be interpreted as evidences for the presence of\nobjects at all possible positions in the input ﬁeld.\nThe SDNN architecture seems particularly attractive for\nrecognizing cursive handwriting where no reliable segmen-\ntation heuristic exists. Although the idea of SDNN is quite\nold and very attractive in its simplicity, it has not generated\nwide interest until recently because, as stated above, it puts\nenormous demands on the recognizer [26], [27]. In speech\nrecognition, where the recognizer is at least one order of\nmagnitude smaller, replicated convolutional networks are\neasier to implement, for instance in Haffner’s multistate\nTDNN model [78], [85].\nA. Interpreting the Output of an SDNN with a GTN\nThe output of an SDNN is a sequence of vectors which\nencode the likelihoods, penalties, or scores of ﬁnding char-\nacter of a particular class label at the corresponding location\nin the input. A postprocessor is required to pull out the\nbest possible label sequence from this vector sequence. An\nexample of SDNN output is shown in Fig. 25. Very often,\nindividual characters are spotted by several neighboring\ninstances of the recognizer, a consequence of the robustness\nof the recognizer to horizontal translations. Also quite\noften, characters are erroneously detected by recognizer\ninstances that see only a piece of a character. For example\na recognizer instance that only sees the right third of a\n“4” might output the label 1. How can we eliminate those\nextraneous characters from the output sequence and pull\nout the best interpretation? This can be done using a new\ntype of GT with two input graphs as shown in Fig. 24.\nThe sequence of vectors produced by the SDNN is ﬁrst\ncoded into a linear graph with multiple arcs between pairs\nof successive nodes. Each arc between a particular pair of\nnodes contains the label of one of the possible categories,\ntogether with the penalty produced by the SDNN for that\nclass label at that location. This graph is called the SDNN\noutput graph. The second input graph to the transformer\nis a grammar transducer, more speciﬁcally a ﬁnite-state\ntransducer [86], that encodes the relationship between input\nstrings of class labels and corresponding output strings\nof recognized characters. The transducer is a weighted\nFig. 24.\nA GT pulls out the best interpretation from the output\nof the SDNN.\nFig. 25.\nAn example of multiple character recognition with\nSDNN. With SDNN, no explicit segmentation is performed.\nﬁnite state machine (a graph) where each arc contains a\npair of labels and possibly a penalty. Like a ﬁnite-state\nmachine, a transducer is in a state and follows an arc\nto a new state when an observed input symbol matches\nthe ﬁrst symbol in the symbol pair attached to the arc.\nAt this point the transducer emits the second symbol in\nthe pair together with a penalty that combines the penalty\nof the input symbol and the penalty of the arc. A trans-\nducer therefore transforms a weighted symbol sequence\ninto another weighted symbol sequence. The GT shown\nin Fig. 24 performs a composition between the recognition\ngraph and the grammar transducer. This operation takes\nevery possible sequence corresponding to every possible\npath in the recognition graph and matches them with the\npaths in the grammar transducer. The composition produces\nthe interpretation graph, which contains a path for each\ncorresponding output label sequence. This composition\noperation may seem combinatorially intractable, but it turns\nout there exists an efﬁcient algorithm for it described in\nmore details in Section VIII.\nB. Experiments with SDNN\nIn a series of experiments, LeNet-5 was trained with the\ngoal of being replicated so as to recognize multiple charac-\nters without segmentations. The data were generated from\n2306\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 26.\nAN SDNN applied to a noisy image of digit string.\nThe digits shown in the SDNN output represent the winning class\nlabels, with a lighter grey level for high-penalty answers.\nthe previously described MNIST set as follows. Training\nimages were composed of a central character, ﬂanked by\ntwo side characters picked at random in the training set. The\nseparation between the bounding boxes of the characters\nwere chosen at random between\n1 and 4 pixels. In other\ninstances, no central character was present, in which case\nthe desired output of the network was the blank space class.\nIn addition, training images were degraded with 10% salt\nand pepper noise (random pixel inversions).\nFigs. 25 and 26 show a few examples of successful\nrecognitions of multiple characters by the LeNet-5 SDNN.\nStandard techniques based on HOS would fail miserably on\nmany of those examples. As can be seen on these examples,\nthe network exhibits striking invariance and noise resistance\nproperties. While some authors have argued that invariance\nrequires more sophisticated models than feedforward NN’s\n[87], LeNet-5 exhibits these properties to a large extent.\nSimilarly, it has been suggested that accurate recognition\nof multiple overlapping objects require explicit mechanisms\nthat would solve the so-called feature binding problem [87].\nAs can be seen on Figs. 25 and 26, the network is able\nto tell the characters apart even when they are closely\nintertwined, a task that would be impossible to achieve\nwith the more classical HOS technique. The SDNN is also\nable to correctly group disconnected pieces of ink that form\ncharacters. Good examples of that are shown in the upper\nhalf of Fig. 26. In the top left example, the 4 and the 0 are\nmore connected to each other than they are connected with\nthemselves, yet the system correctly identiﬁes the 4 and the\n0 as separate objects. The top right example is interesting\nfor several reasons. First the system correctly identiﬁes the\nthree individual ones. Second, the left half and right half\nof disconnected 4 are correctly grouped, even though no\ngeometrical information could decide to associate the left\nhalf to the vertical bar on its left or on its right. The right\nhalf of the 4 does cause the appearance of an erroneous\none on the SDNN output, but this one is removed by the\ncharacter model transducer which prevents characters from\nappearing on contiguous outputs.\nAnother important advantage of SDNN is the ease with\nwhich they can be implemented on parallel hardware.\nSpecialized analog/digital chips have been designed and\nused in character recognition, and in image preprocessing\napplications [88]. However the rapid progress of conven-\ntional processor technology with reduced-precision vector\narithmetic instructions (such as Intel’s MMX) make the\nsuccess of specialized hardware hypothetical at best.3\nC. Global Training of SDNN\nIn the above experiments, the string images were artiﬁ-\ncially generated from individual character. The advantage\nis that we know in advance the location and the label of\nthe important character. With real training data, the correct\nsequence of labels for a string is generally available, but\nthe precise locations of each corresponding character in the\ninput image are unknown.\nIn the experiments described in the previous section, the\nbest interpretation was extracted from the SDNN output\nusing a very simple GT. Global training of an SDNN can\nbe performed by back propagating gradients through such\nGT’s arranged in architectures similar to the ones described\nin Section VI.\nThis is somewhat equivalent to modeling the output\nof an SDNN with an HMM. Globally trained, variable-\nsize TDNN/HMM hybrids have been used for speech\nrecognition and online handwriting recognition [67], [77],\n[89], [90]. SDNN’s have been used in combination with\nHMM’s or other elastic matching methods for handwritten\nword recognition [91], [92].\nFig. 27 shows the GT architecture for training an\nSDNN/HMM hybrid with\nthe discriminative forward\ncriterion. The top part is comparable to the top part of\nFig. 21. On the right side the composition of the recognition\ngraph with the grammar gives the interpretation graph\nwith all the possible legal interpretations. On the left side\nthe composition is performed with a grammar that only\ncontains paths with the desired sequence of labels. This has\na somewhat similar function to the path selector used in the\nprevious section. Like in Section VI-D, the loss function is\nthe difference between the forward score obtained from the\nleft half and the forward score obtained from the right half.\nTo back propagate through the composition transformer,\nwe need to keep a record of which arc in the recognition\ngraph originated which arcs in the interpretation graph.\nThe derivative with respect to an arc in the recognition\ngraph is equal to the sum of the derivatives with respect\nto all the arcs in the interpretation graph that originated\nfrom it. Derivative can also be computed for the penalties\non the grammar graph, allowing to learn them as well. As\nin the previous example, a discriminative criterion must\n3Short video clips of the LeNet-5 SDNN are available WWW:\nhttp://www.research.att.com/˜yann/ocr.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2307\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 27.\nA globally trainable SDNN/HMM hybrid system ex-\npressed as a GTN.\nbe used, because using a nondiscriminative criterion could\nresult in a collapse effect if the network’s output RBF are\nadaptive. The above training procedure can be equivalently\nformulated in term of HMM. Early experiments in zip\ncode recognition [91], and more recent experiments in\nonline handwriting recognition [38] have demonstrated the\nidea of globally trained SDNN/HMM hybrids. SDNN is\nan extremely promising and attractive technique for OCR,\nbut so far it has not yielded better results than HOS. We\nhope that these results will improve as more experience is\ngained with these models.\nD. Object Detection and Spotting with SDNN\nAn interesting application of SDNN’s is object detection\nand spotting. The invariance properties of convolutional\nnetworks, combined with the efﬁciency with which they\ncan be replicated over large ﬁelds, suggests that they can be\nused for “brute force” object spotting and detection in large\nimages. The main idea is to train a single convolutional\nnetwork to distinguish images of the object of interest from\nimages present in the background. In utilization mode, the\nnetwork is replicated so as to cover the entire image to\nbe analyzed, thereby forming a 2-D SDNN. The output of\nthe SDNN is a 2-D plane in which activated units indicate\nthe presence of the object of interest in the corresponding\nreceptive ﬁeld. Since the sizes of the objects to be detected\nwithin the image are unknown, the image can be presented\nto the network at multiple resolutions, and the results at\nmultiple resolutions combined. The idea has been applied\nto face location [93], address block location on envelopes\n[94], and hand tracking in video [95].\nTo illustrate the method, we will consider the case\nof face detection in images as described in [93]. First,\nimages containing faces at various scales are collected.\nThose images are ﬁltered through a zero-mean Laplacian\nﬁlter so as to remove variations in global illumination and\nlow spatial frequency illumination gradients. Then, training\nsamples of faces and nonfaces are manually extracted from\nthose images. The face subimages are then size normalized\nso that the height of the entire face is approximately 20\npixels while keeping fairly large variations (within a factor\nof two). The scale of background subimages are picked\nat random. A single convolutional network is trained on\nthose samples to classify face subimages from nonface\nsubimages.\nWhen a scene image is to be analyzed, it is ﬁrst ﬁltered\nthrough the Laplacian ﬁlter and subsampled at powers-of-\ntwo resolutions. The network is replicated over each of\nmultiple resolution images. A simple voting technique is\nused to combine the results from multiple resolutions.\nA 2-D version of the global training method described\nin the previous section can be used to alleviate the need\nto manually locate faces when building the training sample\n[93]. Each possible location is seen as an alternative inter-\npretation, i.e., one of several parallel arcs in a simple graph\nthat only contains a start node and an end node.\nOther authors have used NN’s or other classiﬁers such\nas SVM’s for face detection with great success [96], [97].\nTheir systems are very similar to the one described above,\nincluding the idea of presenting the image to the network\nat multiple scales. But since those systems do not use\nconvolutional networks, they cannot take advantage of the\nspeedup described here, and they have to rely on other\ntechniques, such as preﬁltering and real-time tracking,\nto keep the computational requirement within reasonable\nlimits. In addition, because those classiﬁers are much less\ninvariant to scale variations than convolutional networks, it\nis necessary to multiply the number of scales at which the\nimages are presented to the classiﬁer.\nVIII.\nGRAPH TRANSFORMER NETWORKS\nAND TRANSDUCERS\nIn Section IV, GTN’s were introduced as a general-\nization of multilayer, multimodule networks where the\nstate information is represented as graphs instead of ﬁxed-\nsize vectors. This section reinterprets the GTN’s in the\nframework of generalized transduction and proposes a\npowerful graph composition algorithm.\nA. Previous Work\nNumerous authors in speech recognition have used\ngradient-based learning methods that integrate graph-\nbased statistical models (notably HMM’s) with acoustic\nrecognition modules, mainly Gaussian mixture models,\nbut also NN’s [67], [78], [98], [99]. Similar ideas have\nbeen applied to handwriting recognition (see [38] for\na review). However, there has been no proposal for a\nsystematic approach to multilayer graph-based trainable\nsystems. The idea of transforming graphs into other graphs\nhas received considerable attention in computer science\n2308\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "through the concept of weighted ﬁnite-state transducers\n[86]. Transducers have been applied to speech recognition\n[100] and language translation [101], and proposals have\nbeen made for handwriting recognition [102]. This line\nof work has been mainly focused on efﬁcient search\nalgorithms [103] and on the algebraic aspects of combining\ntransducers and graphs (called acceptors in this context),\nbut very little effort has been devoted to building globally\ntrainable systems out of transducers. What is proposed\nin the following sections is a systematic approach to\nautomatic\ntraining\nin\ngraph-manipulating\nsystems.\nA\ndifferent approach to graph-based trainable systems, called\ninput–output HMM, was proposed in [104] and [105].\nB. Standard Transduction\nIn the established framework of ﬁnite-state transducers\n[86], discrete symbols are attached to arcs in the graphs.\nAcceptor graphs have a single symbol attached to each\narc whereas transducer graphs have two symbols (an input\nsymbol and an output symbol). A special null symbol is\nabsorbed by any other symbol (when concatenating symbols\nto build a symbol sequence). Weighted transducers and\nacceptors also have a scalar quantity attached to each\narc. In this framework, the composition operation takes\nas input an acceptor graph and a transducer graph and\nbuilds an output acceptor graph. Each path in this output\ngraph (with symbol sequence\n) corresponds to one path\n(with symbol sequence\n) in the input acceptor graph\nand one path and a corresponding pair of input–output\nsequences\nin the transducer graph. The weights\non the arcs of the output graph are obtained by adding\nthe weights from the matching arcs in the input acceptor\nand transducer graphs. In the rest of the paper, we will\ncall this graph composition operation using transducers the\n(standard) transduction operation.\nA simple example of transduction is shown in Fig. 28.\nIn this simple example, the input and output symbols\non the transducer arcs are always identical. This type of\ntransducer graph is called a grammar graph. To better\nunderstand the transduction operation, imagine two tokens\nsitting each on the start nodes of the input acceptor graph\nand the transducer graph. The tokens can freely follow\nany arc labeled with a null input symbol. A token can\nfollow an arc labeled with a nonnull input symbol if the\nother token also follows an arc labeled with the same\ninput symbol. We have an acceptable trajectory when\nboth tokens reach the end nodes of their graphs (i.e.,\nthe tokens have reached the terminal conﬁguration). This\ntrajectory represents a sequence of input symbols that\ncomplies with both the acceptor and the transducer. We can\nthen collect the corresponding sequence of output symbols\nalong the trajectory of the transducer token. The above\nprocedure produces a tree, but a simple technique described\nin Section VIII-C can be used to avoid generating multiple\ncopies of certain subgraphs by detecting when a particular\noutput state has already been seen.\nThe transduction operation can be performed very ef-\nﬁciently [106], but presents complex bookkeeping prob-\nFig. 28.\nExample of composition of the recognition graph with\nthe grammar graph in order to build an interpretation that is\nconsistent with both of them. During the forward propagation\n(dark arrows), the methods check and fprop are used. Gradients\n(dashed arrows) are back propagated with the adaptation of the\nmethod group.\nlems concerning the handling of all combinations of null\nand nonnull symbols. If the weights are interpreted as\nprobabilities (normalized appropriately) then an acceptor\ngraph represents a probability distribution over the language\ndeﬁned by the set of label sequences associated to all\npossible paths (from the start to the end node) in the graph.\nAn example of application of the transduction operation\nis the incorporation of linguistic constraints (a lexicon or\na grammar) when recognizing words or other character\nstrings. The recognition transformer produces the recog-\nnition graph (an acceptor graph) by applying the NN\nrecognizer to each candidate segment. This acceptor graph\nis composed with a transducer graph for the grammar. The\ngrammar transducer contains a path for each legal sequence\nof symbol, possibly augmented with penalties to indicate\nthe relative likelihoods of the possible sequences. The arcs\ncontain identical input and output symbols. Another exam-\nple of transduction was mentioned in Section V: the path\nselector used in the HOS training GTN is implementable by\na composition. The transducer graph is linear graph which\ncontains the correct label sequence. The composition of\nthe interpretation graph with this linear graph yields the\nconstrained graph.\nC. Generalized Transduction\nIf the data structures associated to each arc took only\na ﬁnite number of values, composing the input graph and\nan appropriate transducer would be a sound solution. For\nour applications however, the data structures attached to\nthe arcs of the graphs may be vectors, images or other\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2309\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "high-dimensional objects that are not readily enumerated.\nWe present a new composition operation that solves this\nproblem.\nInstead of only handling graphs with discrete symbols\nand penalties on the arcs, we are interested in considering\ngraphs whose arcs may carry complex data structures,\nincluding continuous-valued data structures such as vectors\nand images. Composing such graphs requires additional\ninformation.\n1) When examining a pair of arcs (one from each input\ngraph), we need a criterion to decide whether to create\ncorresponding arc(s) and node(s) in the output graph,\nbased on the information attached to the input arcs.\nWe can decide to build an arc, several arcs, or an\nentire subgraph with several nodes and arcs.\n2) When that criterion is met, we must build the corre-\nsponding arc(s) and node(s) in the output graph and\ncompute the information attached to the newly created\narc(s) as a function that the information attached to\nthe input arcs.\nThese functions are encapsulated in an object called\na composition transformer. An instance of composition\ntransformer implements the following three methods:\n1) check(arc1,\narc2) compares the data struc-\ntures pointed to by arcs arc1 (from the ﬁrst graph)\nand arc2 (from the second graph) and returns\na boolean indicating whether corresponding arc(s)\nshould be created in the output graph;\n2) fprop(ngraph, upnode,downnode, arc1,\narc2) is called when check(arc1,arc2) re-\nturns true; this method creates new arcs and nodes\nbetween nodes upnode and downnode in the out-\nput graph ngraph, and computes the information\nattached to these newly created arcs as a function of\nthe attached information of the input arcs arc1 and\narc2;\n3) bprop(ngraph, upnode, downnode, arc1,\narc2) is called during training in order to prop-\nagate gradient information from the output subgraph\nbetween upnode and downnode into the data struc-\ntures on the arc1 and arc2, as well as with respect\nto the parameters that were used in the fprop call\nwith the same arguments; this method assumes that\nthe function used by fprop to compute the values\nattached to its output arcs is differentiable.\nThe check method can be seen as constructing a dy-\nnamic architecture of functional dependencies, while the\nfprop method performs a forward propagation through\nthat architecture to compute the numerical information at-\ntached to the arcs. The bprop method performs a backward\npropagation through the same architecture to compute the\npartial derivatives of the loss function with respect to\nthe information attached to the arcs. This is illustrated in\nFig. 28.\nFig. 29 shows a simpliﬁed generalized graph composition\nalgorithm. This simpliﬁed algorithm does not handle null\ntransitions, and it does not check whether the tokens\nFig. 29.\nPseudocode for a simpliﬁed generalized composition\nalgorithm. For simplifying the presentation, we do not handle\nnull transitions nor implement dead end avoidance. The two main\ncomponents of the composition appear clearly here: 1) the recursive\nfunction simtoken() enumerating the token trajectories and 2)\nthe associative array map used for remembering which nodes of\nthe composed graph have been visited.\ntrajectory is acceptable (i.e., both tokens simultaneously\nreach the end nodes of their graphs). The management\nof null transitions is a straightforward modiﬁcation of the\ntoken simulation function. Before enumerating the possible\nnonnull joint token transitions, we loop on the possible\nnull transitions of each token, recursively call the token\nsimulation function, and ﬁnally call the method fprop.\nThe safest way for identifying acceptable trajectories con-\nsists of running a preliminary pass for identifying the\ntoken conﬁgurations from which we can reach the terminal\nconﬁguration (i.e., both tokens on the end nodes). This\n2310\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "is easily achieved by enumerating the trajectories in the\nopposite direction. We start on the end nodes and follow\nthe arcs upstream. During the main pass, we only build\nthe nodes that allow the tokens to reach the terminal\nconﬁguration.\nGraph composition using transducers (i.e., standard trans-\nduction) is easily and efﬁciently implemented as a gener-\nalized transduction. The method check simply tests the\nequality of the input symbols on the two arcs, and the\nmethod fprop creates a single arc whose symbol is the\noutput symbol on the transducer’s arc.\nThe composition between pairs of graphs is particularly\nuseful for incorporating linguistic constraints in a handwrit-\ning recognizer. Examples of its use are given in the online\nhandwriting recognition system described in Section IX\n(and in the check reading system described in Section X).\nIn the rest of the paper, the term composition transformer\nwill denote a GT based on the generalized transductions\nof multiple graphs. The concept of generalized transduc-\ntion is a very general one. In fact, many of the GT’s\ndescribed earlier in this paper, such as the segmenter and\nthe recognizer, can be formulated in terms of generalized\ntransduction. In this case, the generalized transduction does\nnot take two input graphs but a single input graph. The\nmethod fprop of the transformer may create several arcs\nor even a complete subgraph for each arc of the initial\ngraph. In fact the pair check,fprop itself can be seen\nas procedurally deﬁning a transducer.\nIn addition, it can be shown that the generalized trans-\nduction of a single graph is theoretically equivalent to\nthe standard composition of this graph with a particular\ntransducer graph. However, implementing the operation this\nway may be very inefﬁcient since the transducer can be\nvery complicated.\nIn practice, the graph produced by a generalized transduc-\ntion is represented procedurally in order to avoid building\nthe whole output graph (which may be huge when for\nexample the interpretation graph is composed with the\ngrammar graph). We only instantiate the nodes which are\nvisited by the search algorithm during recognition (e.g.,\nViterbi). This strategy propagates the beneﬁts of pruning\nalgorithms (e.g., beam search) in all the GTN’s.\nD. Notes on the Graph Structures\nSection VI discussed the idea of global training by back-\npropagating gradient through simple GT’s. The bprop\nmethod is the basis of the back-propagation algorithm for\ngeneric GT’s. A generalized composition transformer can\nbe seen as dynamically establishing functional relation-\nships between the numerical quantities on the input and\noutput arcs. Once the check function has decided that a\nrelationship should be established, the fprop function im-\nplements the numerical relationship. The check function\nestablishes the structure of the ephemeral network inside\nthe composition transformer.\nSince fprop is assumed to be differentiable, gradients\ncan be back propagated through that structure. Most param-\neters affect the scores stored on the arcs of the successive\ngraphs of the system. A few threshold parameters may\ndetermine whether an arc appears or not in the graph.\nSince nonexisting arcs are equivalent to arcs with very large\npenalties, we only consider the case of parameters affecting\nthe penalties.\nIn the kind of systems we have discussed until now\n(and the application described in Section X), much of the\nknowledge about the structure of the graph that is produced\nby a GT is determined by the nature of the GT, but it may\nalso depend on the value of the parameters and on the input.\nIt may also be interesting to consider GT modules which\nattempt to learn the structure of the output graph. This might\nbe considered a combinatorial problem and not amenable\nto gradient-based learning, but a solution to this problem is\nto generate a large graph that contains the graph candidates\nas subgraphs, and then select the appropriate subgraph.\nE. GTN and HMM’s\nGTN’s can be seen as a generalization and an extension\nof HMM’s. On the one hand, the probabilistic interpretation\ncan be either kept (with penalties being log-probabilities),\npushed to the ﬁnal decision stage (with the difference of\nthe constrained forward penalty and the unconstrained for-\nward penalty being interpreted as negative log-probabilities\nof label sequences), or dropped altogether (the network\njust represents a decision surface for label sequences in\ninput space). On the other hand, GTN’s extend HMM’s\nby allowing to combine in a well-principled framework\nmultiple levels of processing, or multiple models (e.g.,\nPereira et al. have been using the transducer framework for\nstacking HMM’s representing different levels of processing\nin automatic speech recognition [86]).\nUnfolding an HMM in time yields a graph that is very\nsimilar to our interpretation graph (at the ﬁnal stage of\nprocessing of the GTN, before Viterbi recognition). It has\nnodes\nassociated to each time step\nand state\nin the\nmodel. The penalty\nfor an arc from\nto\nthen corresponds to the negative log-probability of emitting\nobserved data\nat position\nand going from state\nto\nstate\nin the time interval\nWith this probabilistic\ninterpretation, the forward penalty is the negative logarithm\nof the likelihood of whole observed data sequence (given\nthe model).\nIn Section VI we mentioned that the collapsing phe-\nnomenon can occur when nondiscriminative loss functions\nare used to train NN’s/HMM hybrid systems. With classi-\ncal HMM’s with ﬁxed preprocessing, this problem does\nnot occur because the parameters of the emission and\ntransition probability models are forced to satisfy certain\nprobabilistic constraints: the sum or the integral of the\nprobabilities of a random variable over its possible values\nmust be one. Therefore, when the probability of certain\nevents is increased, the probability of other events must\nautomatically be decreased. On the other hand, if the\nprobabilistic assumptions in an HMM (or other probabilistic\nmodel) are not realistic, discriminative training, discussed\nin Section VI, can improve performance as this has been\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2311\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "clearly shown for speech recognition systems [48]–[50],\n[107], [108].\nThe input–output HMM (IOHMM) [105], [109] is\nstrongly related to GT’s. Viewed as a probabilistic model,\nan IOHMM represents the conditional distribution of\noutput sequences given input sequences (of the same or\na different length). It is parameterized from an emission\nprobability module and a transition probability module.\nThe emission probability module computes the conditional\nemission probability of an output variable (given an\ninput value and the value of discrete “state” variable).\nThe transition probability module computes conditional\ntransition probabilities of a change in the value of the\n“state” variable, given the input value. Viewed as a GT,\nit assigns an output graph (representing a probability\ndistribution over the sequences of the output variable)\nto each path in the input graph. All these output graphs\nhave the same structure, and the penalties on their arcs are\nsimply added in order to obtain the complete output graph.\nThe input values of the emission and transition modules are\nread off the data structure on the input arcs of the IOHMM\nGT. In practice, the output graph may be very large, and\nneeds not be completely instantiated (i.e., it is pruned: only\nthe low penalty paths are created).\nIX.\nAN ON-LINE HANDWRITING RECOGNITION SYSTEM\nNatural handwriting is often a mixture of different\n“styles,” i.e., lower case printed, upper case, and cursive.\nA reliable recognizer for such handwriting would greatly\nimprove interaction with pen-based devices, but its imple-\nmentation presents new technical challenges. Characters\ntaken in isolation can be very ambiguous, but considerable\ninformation is available from the context of the whole word.\nWe have built a word recognition system for pen-based\ndevices based on four main modules: 1) a preprocessor that\nnormalizes a word, or word group, by ﬁtting a geometrical\nmodel to the word structure; 2) a module that produces an\n“annotated image” from the normalized pen trajectory; 3)\na replicated convolutional NN that spots and recognizes\ncharacters; and 4) a GTN that interprets the networks\noutput by taking word-level constraints into account. The\nnetwork and the GTN are jointly trained to minimize an\nerror measure deﬁned at the word level.\nIn this work, we have compared a system based on\nSDNN’s (such as described in Section VII), and a system\nbased on HOS (such as described in Section V). Because of\nthe sequential nature of the information in the pen trajectory\n(which reveals more information than the purely optical in-\nput from in image), HOS can be very efﬁcient in proposing\ncandidate character cuts, especially for noncursive script.\nA. Preprocessing\nInput normalization reduces intracharacter variability,\nthereby simplifying character recognition. We have used\na word normalization scheme [92] based on ﬁtting a geo-\nmetrical model of the word structure. Our model has four\n“ﬂexible” lines representing respectively the ascenders line,\nFig. 30.\nAn online handwriting recognition GTN based on HOS.\nthe core line, the base line, and the descenders line. The\nlines are ﬁtted to local minima or maxima of the pen\ntrajectory. The parameters of the lines are estimated with\na modiﬁed version of the EM algorithm to maximize the\njoint probability of observed points and parameter values,\nusing a prior on parameters that prevents the lines from\ncollapsing on each other.\nThe recognition of handwritten characters from a pen\ntrajectory on a digitizing surface is often done in the\ntime domain [44], [110], [111]. Typically, trajectories are\nnormalized and local geometrical or dynamical features are\nextracted. The recognition may then be performed using\ncurve matching [110], or other classiﬁcation techniques\nsuch as TDNN’s [44], [111]. While these representations\nhave several advantages, their dependence on stroke order-\ning and individual writing styles makes them difﬁcult to use\nin high accuracy, writer independent systems that integrate\nthe segmentation with the recognition.\nSince the intent of the writer is to produce a legible\nimage, it seems natural to preserve as much of the pictorial\nnature of the signal as possible, while at the same time\nexploit the sequential information in the trajectory. For this\npurpose we have designed a representation scheme called\nAMAP [38], where pen trajectories are represented by low-\nresolution images in which each picture element contains\ninformation about the local properties of the trajectory. An\nAMAP can be viewed as an “annotated image” in which\neach pixel is a ﬁve-element feature vector: four features are\nassociated to four orientations of the pen trajectory in the\n2312\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 31.\nAn online handwriting recognition GTN based on\nSDNN.\narea around the pixel and the ﬁfth one is associated to local\ncurvature in the area around the pixel. A particularly useful\nfeature of the AMAP representation is that it makes very\nfew assumptions about the nature of the input trajectory.\nIt does not depend on stroke ordering or writing speed,\nand it can be used with all types of handwriting (capital,\nlower case, cursive, punctuation, symbols). Unlike many\nother representations (such as global features), AMAP’s\ncan be computed for complete words without requiring\nsegmentation.\nB. Network Architecture\nOne of the best networks we found for both online and\nofﬂine character recognition is a ﬁve-layer convolutional\nnetwork somewhat similar to LeNet-5 (Fig. 2), but with\nmultiple input planes and different numbers of units on\nthe last two layers—layer one: convolution with eight\nkernels of size 3 3; layer two: 2 2 subsampling; layer\nthree: convolution with 25 kernels of size 5 5; layer\nfour: convolution with 84 kernels of size 4 4; layer ﬁve:\n2 1 subsampling; classiﬁcation layer: 95 RBF units (one\nper class in the full printable ASCII set). The distributed\ncodes on the output are the same as for LeNet-5, except\nthey are adaptive unlike with LeNet-5. When used in the\nHOS system, the input to above network consisted of\nan AMAP with ﬁve planes, 20 rows, and 18 columns.\nIt was determined that this resolution was sufﬁcient for\nrepresenting handwritten characters. In the SDNN version,\nthe number of columns was varied according to the width\nof the input word. Once the number of subsampling layers\nand the sizes of the kernels are chosen, the sizes of all the\nlayers, including the input, are determined unambiguously.\nThe only architectural parameters that remain to be selected\nare the number of feature maps in each layer and the infor-\nmation as to what feature map is connected to what other\nfeature map. In our case, the subsampling rates were chosen\nas small as possible (2 2) and the kernels as small as\npossible in the ﬁrst layer (3 3) to limit the total number of\nconnections. Kernel sizes in the upper layers are chosen to\nbe as small as possible while satisfying the size constraints\nmentioned above. Larger architectures did not necessarily\nperform better and required considerably more time to\nbe trained. A very small architecture with half the input\nﬁeld also performed worse because of insufﬁcient input\nresolution. Note that the input resolution is nonetheless\nmuch less than for OCR because the angle and curvature\nprovide more information than would a single grey level\nat each pixel.\nC. Network Training\nTraining proceeded in two phases. First, we kept the\ncenters of the RBF’s ﬁxed and trained the network weights\nso as to minimize the output distance of the RBF unit\ncorresponding to the correct class. This is equivalent to\nminimizing the MSE between the previous layer and the\ncenter of the correct-class RBF. This bootstrap phase was\nperformed on isolated characters. In the second phase, all\nthe parameters, network weights, and RBF centers were\ntrained globally to minimize a discriminative criterion at\nthe word level.\nWith the HOS approach, the GTN was composed of four\nmain GT’s.\n1) The segmentation transformer performs the HOS and\noutputs the segmentation graph. An AMAP is then\ncomputed for each image attached to the arcs of this\ngraph.\n2) The character recognition transformer applies the\nconvolutional network character recognizer to each\ncandidate segment and outputs the recognition graph\nwith penalties and classes on each arc.\n3) The composition transformer composes the recog-\nnition graph with a grammar graph representing a\nlanguage model incorporating lexical constraints.\n4) The beam search transformer extracts a good in-\nterpretation from the interpretation graph. This task\ncould have been achieved with the usual Viterbi\nTransformer. The beam search algorithm, however,\nimplements pruning strategies which are appropriate\nfor large interpretation graphs.\nWith the SDNN approach, the main GT’s are the fol-\nlowing.\n1) The SDNN transformer replicates the convolutional\nnetwork over the a whole word image and outputs\na recognition graph that is a linear graph with class\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2313\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 32.\nComparative results (character error rates) showing the improvement brought by global\ntraining on the SDNN/HMM hybrid, and on the HOS, without and with a 25 461-word dictionary.\npenalties for every window centered at regular inter-\nvals on the input image.\n2) The character-level composition transformer com-\nposes the recognition graph with a left-to-right HMM\nfor each character class (as in Fig. 27).\n3) The word-level composition transformer composes\nthe output of the previous transformer with a language\nmodel incorporating lexical constraints and outputs\nthe interpretation graph.\n4) The beam search transformer extracts a good inter-\npretation from the interpretation graph.\nIn this application, the language model simply constrains\nthe ﬁnal output graph to represent sequences of character\nlabels from a given dictionary. Furthermore, the interpreta-\ntion graph is not actually completely instantiated: the only\nnodes created are those that are needed by the beam search\nmodule. The interpretation graph is therefore represented\nprocedurally rather than explicitly.\nA crucial contribution of this research was the joint\ntraining of all GT modules within the network with respect\nto a single criterion, as explained in Sections VI and\nVII. We used the discriminative forward loss function on\nthe ﬁnal output graph: minimize the forward penalty of\nthe constrained interpretation (i.e., along all the “correct”\npaths) while maximizing the forward penalty of the whole\ninterpretation graph (i.e., along all the paths).\nDuring global training, the loss function was optimized\nwith the stochastic diagonal Levenberg–Marquardt proce-\ndure described in Appendix C, which uses second deriva-\ntives to compute optimal learning rates. This optimization\noperates on all the parameters in the system, most notably\nthe network weights and the RBF centers.\nD. Experimental Results\nIn the ﬁrst set of experiments, we evaluated the gen-\neralization ability of the NN classiﬁer coupled with the\nword normalization preprocessing and AMAP input rep-\nresentation. All results are in writer independent mode\n(different writers in training and testing). Initial training\non isolated characters was performed on a database of\napproximately 100 000 hand printed characters (95 classes\nof upper case, lower case, digits, and punctuation). Tests on\na database of isolated characters were performed separately\non the four types of characters: upper case (2.99% error on\n9122 patterns), lower case (4.15% error on 8201 patterns),\ndigits (1.4% error on 2938 patterns), and punctuation (4.3%\nerror on 881 patterns). Experiments were performed with\nthe network architecture described above. To enhance the\nrobustness of the recognizer to variations in position, size,\norientation, and other distortions, additional training data\nwas generated by applying local afﬁne transformations to\nthe original characters.\nThe second and third set of experiments concerned the\nrecognition of lower case words (writer independent). The\ntests were performed on a database of 881 words. First we\nevaluated the improvements brought by the word normal-\nization to the system. For the SDNN/HMM system we have\nto use word-level normalization since the network sees one\nwhole word at a time. With the HOS system, and before\ndoing any word-level training, we obtained with character-\nlevel normalization 7.3% and 3.5% word and character\nerrors (adding insertions, deletions and substitutions) when\nthe search was constrained within a 25 461-word dictionary.\nWhen using the word normalization preprocessing instead\nof a character level normalization, error rates dropped to\n4.6% and 2.0% for word and character errors respectively,\ni.e., a relative drop of 37% and 43% in word and character\nerror respectively. This suggests that normalizing the word\nin its entirety is better than ﬁrst segmenting it and then\nnormalizing and processing each of the segments.\nIn the third set of experiments, we measured the im-\nprovements obtained with the joint training of the NN\nand the postprocessor with the word-level criterion, in\ncomparison to training based only on the errors performed\nat the character level. After initial training on individual\ncharacters as above, global word-level discriminative train-\ning was performed with a database of 3500 lower case\nwords. For the SDNN/HMM system, without any dictionary\nconstraints, the error rates dropped from 38% and 12.4%\nword and character error to 26% and 8.2% respectively after\nword-level training, i.e., a relative drop of 32% and 34%.\n2314\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "For the HOS system and a slightly improved architecture,\nwithout any dictionary constraints, the error rates dropped\nfrom 22.5% and 8.5% word and character error to 17% and\n6.3% respectively, i.e., a relative drop of 24.4% and 25.6%.\nWith a 25 461-word dictionary, errors dropped from 4.6%\nand 2.0% word and character errors to 3.2% and 1.4%,\nrespectively, after word-level training, i.e., a relative drop\nof 30.4% and 30.0%. Even lower error rates can be obtained\nby drastically reducing the size of the dictionary to 350\nwords, yielding 1.6% and 0.94% word and character errors.\nThese results clearly demonstrate the usefulness of glob-\nally trained NN/HMM hybrids for handwriting recognition.\nThis conﬁrms similar results obtained earlier in speech\nrecognition [77].\nX.\nA CHECK READING SYSTEM\nThis section describes a GTN based check reading sys-\ntem, intended for immediate industrial deployment. It also\nshows how the use of gradient based-learning and GTN’s\nmake this deployment fast and cost-effective while yielding\nan accurate and reliable solution.\nThe veriﬁcation of the amount on a check is a task that\nis extremely time and money consuming for banks. As\na consequence, there is a very high interest in automat-\ning the process as much as possible (see, for example,\n[112]–[114]). Even a partial automation would result in\nconsiderable cost reductions. The threshold of economic\nviability for automatic check readers, as set by the bank,\nis when 50% of the checks are read with less than 1%\nerror. The other 50% of the check being rejected and\nsent to human operators. In such a case, we describe the\nperformance of the system as 50% correct/49% reject/1%\nerror. The system presented here was one of the ﬁrst to\ncross that threshold on representative mixtures of business\nand personal checks.\nChecks contain at least two versions of the amount. The\ncourtesy amount is written with numerals, while the legal\namount is written with letters. On business checks, which\nare generally machine-printed, these amounts are relatively\neasy to read but quite difﬁcult to ﬁnd due to the lack of\nstandard for business check layout. On the other hand, these\namounts on personal checks are easy to ﬁnd but much\nharder to read.\nFor simplicity (and speed requirements), our initial task\nis to read the courtesy amount only. This task consists of\ntwo main steps.\n1) The system has to ﬁnd, among all the ﬁelds (lines\nof text), the candidates that are the most likely to\ncontain the courtesy amount. This is obvious for many\npersonal checks, where the position of the amount\nis standardized. However, as already noted, ﬁnding\nthe amount can be rather difﬁcult in business checks,\neven for the human eye. There are many strings of\ndigits, such as the check number, the date, or even\n“not to exceed” amounts, that can be confused with\nthe actual amount. In many cases, it is very difﬁcult to\ndecide which candidate is the courtesy amount before\nperforming a full recognition.\nFig. 33.\nA complete check amount reader implemented as a\nsingle cascade of GT modules. Successive graph transformations\nprogressively extract higher level information.\n2) In order to read (and choose) some courtesy amount\ncandidates, the system has to segment the ﬁelds into\ncharacters, read and score the candidate characters,\nand ﬁnally ﬁnd the best interpretation of the amount\nusing contextual knowledge represented by a stochas-\ntic grammar for check amounts.\nThe GTN methodology was used to build a check amount\nreading system that handles both personal checks and\nbusiness checks.\nA. A GTN for Check Amount Recognition\nWe now describe the successive graph transformations\nthat allow this network to read the check amount (cf.\nFig. 33). Each GT produces a graph whose paths encode\nand score the current hypotheses considered at this stage\nof the system.\nThe input to the system is a trivial graph with a single\narc that carries the image of the whole check (cf. Fig. 33).\n1) The Field Location Transformer:\nﬁrst performs\nclassical image analysis (including connected component\nanalysis, ink density histograms, layout analysis, etc.) and\nheuristically extracts rectangular zones that may contain the\ncheck amount.\nproduces an output graph, called the\nﬁeld graph (cf. Fig. 33) such that each candidate zone is\nassociated with one arc that links the start node to the\nend node. Each arc contains the image of the zone and\na penalty term computed from simple features extracted\nfrom the zone (absolute position, size, aspect ratio, etc.).\nThe penalty term is close to zero if the features suggest\nthat the ﬁeld is a likely candidate and is large if the ﬁeld is\ndeemed less likely to be an amount. The penalty function is\ndifferentiable, therefore its parameters are globally tunable.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2315\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "An arc may represent separate dollar and cent amounts\nas a sequence of ﬁelds. In fact, in handwritten checks, the\ncent amount may be written over a fractional bar and not\naligned at all with the dollar amount. In the worst case, one\nmay ﬁnd several cent amount candidates (above and below\nthe fraction bar) for the same dollar amount.\n2) The Segmentation Transformer:\nsimilar to the\none\ndescribed\nin\nSection VIII,\nexamines\neach\nzone\ncontained in the ﬁeld graph and cuts each image into\npieces of ink using heuristic image processing techniques.\nEach piece of ink may be a whole character or a piece\nof character. Each arc in the ﬁeld graph is replaced by\nits corresponding segmentation graph that represents all\npossible groupings of pieces of ink. Each ﬁeld segmentation\ngraph is appended to an arc that contains the penalty of the\nﬁeld in the ﬁeld graph. Each arc carries the segment image,\ntogether with a penalty that provides a ﬁrst evaluation\nof the likelihood that the segment actually contains a\ncharacter. This penalty is obtained with a differentiable\nfunction that combines a few simple features such as\nthe space between the pieces of ink or the compliance\nof the segment image with a global baseline, and a few\ntunable parameters. The segmentation graph represents all\nthe possible segmentations of all the ﬁeld images. We can\ncompute the penalty for one segmented ﬁeld by adding\nthe arc penalties along the corresponding path. As before,\nusing a differentiable function for computing the penalties\nwill ensure that the parameters can be optimized globally.\nThe segmenter uses a variety of heuristics to ﬁnd candi-\ndate cut. One of the most important ones is called “hit and\ndeﬂect” [115]. The idea is to cast lines downward from the\ntop of the ﬁeld image. When a line hits a black pixel, it is\ndeﬂected so as to follow the contour of the object. When a\nline hits a local minimum of the upper proﬁle, i.e., when it\ncannot continue downward without crossing a black pixel,\nit is just propagated vertically downward through the ink.\nWhen two such lines meet each other, they are merged\ninto a single cut. The procedure can be repeated from the\nbottom up. This strategy allows the separation of touching\ncharacters such as double zeros.\n3) The Recognition Transformer:\niterates over all\nsegment arcs in the segmentation graph and runs a character\nrecognizer on the corresponding segment image. In our\ncase, the recognizer is LeNet-5, the convolutional NN\ndescribed in Section II, whose weights constitute the largest\nand most important subset of tunable parameters. The\nrecognizer classiﬁes segment images into one of 95 classes\n(fully printable ASCII set) plus a rubbish class for unknown\nsymbols or badly formed characters. Each arc in the input\ngraph\nis replaced by 96 arcs in the output graph.\nEach of those 96 arcs contains the label of one of the\nclasses, and a penalty that is the sum of the penalty of\nthe corresponding arc in the input (segmentation) graph,\nand the penalty associated with classifying the image in\nthe corresponding class, as computed by the recognizer. In\nother words, the recognition graph represents a weighted\ntrellis of scored character classes. Each path in this graph\nrepresents a possible character string for the corresponding\nﬁeld. We can compute a penalty for this interpretation\nby adding the penalties along the path. This sequence of\ncharacters may or may not be a valid check amount.\n4) The Composition Transformer:\nselects the paths\nof the recognition graph that represent valid character\nsequences for check amounts. This transformer takes two\ngraphs as input: the recognition graph and the grammar\ngraph. The grammar graph contains all possible sequences\nof symbols that constitute a well-formed amount. The out-\nput of the composition transformer, called the interpretation\ngraph, contains all the paths in the recognition graph that are\ncompatible with the grammar. The operation that combines\nthe two input graphs to produce the output is a generalized\ntransduction (see Section IX). A differentiable function is\nused to compute the data attached to the output arc from\nthe data attached to the input arcs. In our case, the output\narc receives the class label of the two arcs and a penalty\ncomputed by simply summing the penalties of the two\ninput arcs (the recognizer penalty and the arc penalty in\nthe grammar graph). Each path in the interpretation graph\nrepresents one interpretation of one segmentation of one\nﬁeld on the check. The sum of the penalties along the path\nrepresents the “badness” of the corresponding interpretation\nand combines evidence from each of the modules along the\nprocess, as well as from the grammar.\n5) The Viterbi Transformer: The Viterbi transformer ﬁ-\nnally selects the path with the lowest accumulated penalty\ncorresponding to the best grammatically correct interpreta-\ntions.\nB. Gradient-Based Learning\nEach stage of this check reading system contains tunable\nparameters. While some of these parameters could be\nmanually adjusted (e.g., the parameters of the ﬁeld locator\nand segmenter), the vast majority of them must be learned,\nparticularly the weights of the NN recognizer.\nPrior to globally optimizing the system, each module pa-\nrameters are initialized with reasonable values. The param-\neters of the ﬁeld locator and the segmenter are initialized by\nhand, while the parameters of the NN character recognizer\nare initialized by training on a database of presegmented\nand labeled characters. Then, the entire system is trained\nglobally from whole check images labeled with the correct\namount. No explicit segmentation of the amounts is needed\nto train the system: it is trained at the check level.\nThe loss function\nminimized by our global training\nprocedure is the discriminative forward criterion described\nin Section VI: the difference between 1) the forward penalty\nof the constrained interpretation graph (constrained by the\ncorrect label sequence) and 2) the forward penalty of the\nunconstrained interpretation graph. Derivatives can be back\npropagated through the entire structure, although it is only\npractical to do it down to the segmenter.\nC. Rejecting Low Conﬁdence Checks\nIn order to be able to reject checks which are the\nmost likely to carry erroneous Viterbi answers, we must\nrate them with a conﬁdence and reject the check if this\n2316\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Fig. 34.\nAdditional processing required to compute the conﬁ-\ndence.\nconﬁdence is below a given threshold. To compare the\nunnormalized Viterbi penalties of two different checks\nwould be meaningless when it comes to decide which\nanswer we trust the most.\nThe optimal measure of conﬁdence is the probability\nof the Viterbi answer given the input image. As seen\nin Section VI-E, given a target sequence (which, in this\ncase, would be the Viterbi answer), the discriminative\nforward loss function is an estimate of the logarithm of\nthis probability. Therefore, a simple solution to obtain a\ngood estimate of the conﬁdence is to reuse the interpretation\ngraph (see Fig. 33) to compute the discriminative forward\nloss as described in Fig. 21, using as our desired sequence\nthe Viterbi answer. This is summarized in Fig. 34, with\nD. Results\nA version of the above system was fully implemented\nand tested on machine-print business checks. This system is\nbasically a generic GTN engine with task speciﬁc heuristics\nencapsulated in the check and fprop method. As a con-\nsequence, the amount of code to write was minimal: mostly\nthe adaptation of an earlier segmenter into the segmentation\ntransformer. The system that deals with handwritten or\npersonal checks was based on earlier implementations that\nused the GTN concept in a restricted way.\nThe NN classiﬁer was initially trained on 500 000 images\nof character images from various origins spanning the entire\nprintable ASCII set. This contained both handwritten and\nmachine-printed characters that had been previously size\nnormalized at the string level. Additional images were\ngenerated by randomly distorting the original images using\nsimple afﬁne transformations of the images. The network\nwas then further trained on character images that had been\nautomatically segmented from check images and manually\ntruthed. The network was also initially trained to reject\nnoncharacters that resulted from segmentation errors. The\nrecognizer was then inserted in the check-reading system\nand a small subset of the parameters were trained globally\n(at the ﬁeld level) on whole check images.\nOn 646 business checks that were automatically cat-\negorized as machine printed, the performance was 82%\ncorrectly recognized checks, 1% errors, and 17% rejects.\nThis can be compared to the performance of the previous\nsystem on the same test set: 68% correct, 1% errors, and\n31% rejects. A check is categorized as machine-printed\nwhen characters that are near a standard position dollar\nsign are detected as machine printed, or when, if nothing is\nfound in the standard position, at least one courtesy amount\ncandidate is found somewhere else. The improvement is\nattributed to three main causes. First the NN recognizer\nwas bigger and trained on more data. Second, because of\nthe GTN architecture, the new system could take advantage\nof grammatical constraints in a much more efﬁcient way\nthan the previous system. Third, the GTN architecture\nprovided extreme ﬂexibility for testing heuristics, adjusting\nparameters, and tuning the system. This last point is more\nimportant than it seems. The GTN framework separates\nthe “algorithmic” part of the system from the “knowledge-\nbased” part of the system, allowing easy adjustments of the\nlatter. The importance of global training was only minor\nin this task because the global training only concerned a\nsmall subset of the parameters.\nAn independent test performed by systems integrators\nin 1995 showed the superiority of this system over other\ncommercial courtesy amount reading systems. The system\nwas integrated in NCR’s line of check reading systems. It\nhas been ﬁelded in several banks across the United States\nsince June 1996, and it has been reading millions of checks\nper day since then.\nXI.\nCONCLUSIONS\nDuring the short history of automatic pattern recognition,\nincreasing the role of learning seems to have invariably\nimproved the overall performance of recognition systems.\nThe systems described in this paper are more evidence to\nthis fact. Convolutional NN’s have been shown to eliminate\nthe need for hand-crafted feature extractors. GTN’s have\nbeen shown to reduce the need for hand-crafted heuristics,\nmanual labeling, and manual parameter tuning in document\nrecognition systems. As training data becomes plentiful, as\ncomputers get faster, and as our understanding of learning\nalgorithms improves, recognition systems will rely more\nand more of learning and their performance will improve.\nJust as the back-propagation algorithm elegantly solved\nthe credit assignment problem in multilayer NN’s, the\ngradient-based learning procedure for GTN’s introduced in\nthis paper solves the credit assignment problem in systems\nwhose functional architecture dynamically changes with\neach new input. The learning algorithms presented here are\nin a sense nothing more than unusual forms of gradient\ndescent in complex, dynamic architectures, with efﬁcient\nback-propagation algorithms to compute the gradient. The\nresults in this paper help establish the usefulness and\nrelevance of gradient-based minimization methods as a\ngeneral organizing principle for learning in large systems.\nIt was shown that all the steps of a document analysis\nsystem can be formulated as GT’s through which gradi-\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2317\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "ents can be back propagated. Even in the nontrainable\nparts of the system, the design philosophy in terms of\ngraph transformation provides a clear separation between\ndomain-speciﬁc heuristics (e.g., segmentation heuristics)\nand generic, procedural knowledge (the generalized trans-\nduction algorithm)\nIt is worth pointing out that data generating models (such\nas HMM’s) and the maximum likelihood principle were not\ncalled upon to justify most of the architectures and the train-\ning criteria described in this paper. Gradient-based learning\napplied to global discriminative loss functions guarantees\noptimal classiﬁcation and rejection without the use of “hard\nto justify” principles that put strong constraints on the\nsystem architecture, often at the expense of performances.\nMore speciﬁcally, the methods and architectures pre-\nsented in this paper offer generic solutions to a large number\nof problems encountered in pattern recognition systems.\n1) Feature extraction is traditionally a ﬁxed transform,\nand it is generally derived from some expert prior\nknowledge about the task. This relies on the probably\nincorrect assumption that the human designer is able\nto capture all the relevant information in the input.\nWe have shown that the application of gradient-based\nlearning to convolutional NN’s allows us to learn ap-\npropriate features from examples. The success of this\napproach was demonstrated in extensive comparative\ndigit recognition experiments on the NIST database.\n2) Segmentation and recognition of objects in images\ncannot be completely decoupled. Instead of taking\nhard segmentation decisions too early, we have used\nHOS to generate and evaluate a large number of\nhypotheses in parallel, postponing any decision until\nthe overall criterion is minimized.\n3) Hand-truthing images to obtain segmented characters\nfor training a character recognizer is expensive and\ndoes not take into account the way in which a whole\ndocument or sequence of characters will be recog-\nnized (in particular, the fact that some segmentation\ncandidates may be wrong, even though they may look\nlike true characters). Instead we train multimodule\nsystems to optimize a global measure of performance,\nwhich does not require time consuming detailed hand-\ntruthing and yields signiﬁcantly better recognition\nperformance because it allows to train these modules\nto cooperate toward a common goal.\n4) Ambiguities inherent in the segmentation, character\nrecognition, and linguistic model should be inte-\ngrated optimally. Instead of using a sequence of task-\ndependent heuristics to combine these sources of in-\nformation, we have proposed a uniﬁed framework in\nwhich generalized transduction methods are applied\nto graphs representing a weighted set of hypotheses\nabout the input. The success of this approach was\ndemonstrated with a commercially deployed check-\nreading system that reads millions of business and\npersonal checks per day: the generalized transduction\nengine resides in only a few hundred lines of code.\n5) Traditional recognition systems rely on many hand-\ncrafted heuristics to isolate individually recognizable\nobjects. The promising SDNN approach draws on the\nrobustness and efﬁciency of convolutional NN’s to\navoid explicit segmentation altogether. Simultaneous\nautomatic learning of segmentation and recognition\ncan be achieved with gradient-based learning meth-\nods.\nThis paper presents a small number of examples of GT\nmodules, but it is clear that the concept can be applied to\nmany situations where the domain knowledge or the state\ninformation can be represented by graphs. This is the case\nin many audio signal recognition tasks, and visual scene\nanalysis applications. Future work will attempt to apply\nGT networks to such problems, with the hope of allowing\nmore reliance on automatic learning and less on detailed\nengineering.\nAPPENDIX A\nPRECONDITIONS FOR FASTER CONVERGENCE\nAs seen before, the squashing function used in our\nconvolutional networks is\nSymmetric\nfunctions are believed to yield faster convergence, although\nthe learning can become extremely slow if the weights\nare too small. The cause of this problem is that in weight\nspace the origin is a ﬁxed point of the learning dynamics\nand, although it is a saddle point, it is attractive in almost\nall directions [116]. For our simulations, we use\nand\n(see [20], [34]). With this choice of\nparameters, the equalities\nand\nare\nsatisﬁed. The rationale behind this is that the overall gain\nof the squashing transformation is around one in normal\noperating conditions, and the interpretation of the state of\nthe network is simpliﬁed. Moreover, the absolute value of\nthe second derivative of\nis a maximum at\n1 and\n1,\nwhich improves the convergence toward the end of the\nlearning session. This particular choice of parameters is\nmerely a convenience, and does not affect the result.\nBefore training, the weights are initialized with random\nvalues using a uniform distribution between\nand\n, where\nis the number of inputs (fan-in) of the unit\nwhich the connection belongs to. Since several connections\nshare a weight, this rule could be difﬁcult to apply, but in\nour case all connections sharing a same weight belong to\nunits with identical fan-ins. The reason for dividing by the\nfan-in is that we would like the initial standard deviation\nof the weighted sums to be in the same range for each\nunit and to fall within the normal operating region of the\nsigmoid. If the initial weights are too small, the gradients\nare very small and the learning is slow. If they are too\nlarge, the sigmoids are saturated and the gradient is also\nvery small. The standard deviation of the weighted sum\nscales like the square root of the number of inputs when\nthe inputs are independent, and it scales linearly with the\nnumber of inputs if the inputs are highly correlated. We\nchose to assume the second hypothesis since some units\nreceive highly correlated signals.\n2318\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "APPENDIX B\nSTOCHASTIC GRADIENT VERSUS BATCH GRADIENT\nGradient-based learning algorithms can use one of two\nclasses of methods to update the parameters. The ﬁrst\nmethod, dubbed “batch gradient,” is the classical one: the\ngradients are accumulated over the entire training set, and\nthe parameters are updated after the exact gradient has\nbeen so computed. In the second method, called “stochastic\ngradient,” a partial, or noisy, gradient is evaluated on the\nbasis of one single training sample (or a small number\nof samples), and the parameters are updated using this\napproximate gradient. The training samples can be selected\nrandomly or according to a properly randomized sequence.\nIn the stochastic version the gradient estimates are noisy,\nbut the parameters are updated much more often than\nwith the batch version. An empirical result of considerable\npractical importance is that on tasks with large, redundant\ndata sets, the stochastic version is considerably faster than\nthe batch version, sometimes by orders of magnitude [117].\nAlthough the reasons for this are not totally understood\ntheoretically, an intuitive explanation can be found in the\nfollowing extreme example. Let us take an example where\nthe training database is composed of two copies of the\nsame subset. Then accumulating the gradient over the whole\nset would cause redundant computations to be performed.\nOn the other hand, running Stochastic Gradient once on\nthis training set would amount to performing two complete\nlearning iterations over the small subset. This idea can be\ngeneralized to training sets where there exist no precise\nrepetition of the same pattern but where some redundancy is\npresent. In fact stochastic update must be better when there\nis redundancy, i.e., when a certain level of generalization\nis expected.\nMany authors have claimed that second-order methods\nshould be used in lieu of gradient descent for NN training.\nThe literature abounds with recommendations [118] for\nclassical second-order methods such as the Gauss–Newton\nor Levenberg–Marquardt algorithms for quasi-Newton\nmethods\nsuch\nas\nBroyden–Fletcher–Goldfarb–Shanno,\nlimited-storage\nBroyden–Fletcher–Goldfarb–Shanno,\nor\nfor various versions of the conjugate gradients method.\nUnfortunately, all of the above methods are unsuit-\nable for training large NN’s on large data sets. The\nGauss–Newton and Levenberg–Marquardt methods require\noperations per update, where\nis the number\nof parameters, which makes them impractical for even\nmoderate size networks. Quasi-Newton methods require\n“only”\noperations per update, but that still makes\nthem impractical for large networks. Limited-storage Broy-\nden–Fletcher–Goldfarb–Shanno’s and conjugate gradients\nrequire only\noperations per update so they would\nappear appropriate. Unfortunately, their convergence speed\nrelies on an accurate evaluation of successive “conjugate\ndescent directions” which only makes sense in “batch”\nmode. For large data sets, the speed-up brought by\nthese methods over regular batch gradient descent cannot\nmatch the enormous speed up brought by the use of\nstochastic gradient. Several authors have attempted to\nuse conjugate gradient with small batches or batches of\nincreasing sizes [119], [120], but those attempts have\nnot yet been demonstrated to surpass a carefully tuned\nstochastic gradient. Our experiments were performed with\na stochastic method that scales the parameter axes so as to\nminimize the eccentricity of the error surface.\nAPPENDIX C\nSTOCHASTIC DIAGONAL LEVENBERG–MARQUARDT\nOwing to the reasons given in Appendix B, we prefer\nto update the weights after each presentation of a single\npattern in accordance with stochastic update methods. The\npatterns are presented in a constant random order, and the\ntraining set is typically repeated 20 times.\nOur update algorithm is dubbed the stochastic diagonal\nLevenberg–Marquardt method where an individual learning\nrate (step size) is computed for each parameter (weight)\nbefore each pass through the training set [20], [34], [121].\nThese learning rates are computed using the diagonal terms\nof an estimate of the Gauss–Newton approximation to\nthe Hessian (second derivative) matrix. This algorithm is\nnot believed to bring a tremendous increase in learning\nspeed but it converges reliably without requiring extensive\nadjustments of the learning parameters. It corrects major\nill-conditioning of the loss function that are due to the\npeculiarities of the network architecture and the training\ndata. The additional cost of using this procedure over\nstandard stochastic gradient descent is negligible.\nAt each learning iteration a particular parameter\nis\nupdated according to the following stochastic update rule:\n(18)\nwhere\nis the instantaneous loss function for pattern\nIn convolutional NN’s, because of the weight sharing,\nthe partial derivative\nis the sum of the partial\nderivatives with respect to the connections that share the\nparameter\n(19)\nwhere\nis the connection weight from unit\nto unit\nis the set of unit index pairs\nsuch that the connection\nbetween\nand\nshare the parameter\ni.e.,\n(20)\nAs stated previously, the step sizes\nare not constant but\nare function of the second derivative of the loss function\nalong the axis\n(21)\nwhere\nis a hand-picked constant and\nis an estimate\nof the second derivative of the loss function\nwith respect\nto\nThe larger\nis, the smaller the weight update.\nThe parameter\nprevents the step size from becoming too\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2319\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "large when the second derivative is small, very much like\nthe “model-trust” methods, and the Levenberg–Marquardt\nmethods in nonlinear optimization [8]. The exact formula\nto compute\nfrom the second derivatives with respect\nto the connection weights is\n(22)\nHowever, we make three approximations. The ﬁrst approx-\nimation is to drop the off-diagonal terms of the Hessian\nwith respect to the connection weights in (22)\n(23)\nNaturally, the terms\nare the average over the\ntraining set of the local second derivatives\n(24)\nThose local second derivatives with respect to connection\nweights can be computed from local second derivatives with\nrespect to the total input of the downstream unit\n(25)\nwhere\nis the state of unit\nand\nis the second\nderivative of the instantaneous loss function with respect to\nthe total input to unit\n(denoted\nInterestingly, there is\nan efﬁcient algorithm to compute those second derivatives\nwhich is very similar to the back-propagation procedure\nused to compute the ﬁrst derivatives [20], [21]\n(26)\nUnfortunately, using those derivatives leads to well-known\nproblems associated with every Newton-like algorithm:\nthese terms can be negative and can cause the gradient\nalgorithm to move uphill instead of downhill. Therefore,\nour second approximation is a well-known trick called\nthe Gauss–Newton approximation, which guarantees that\nthe second derivative estimates are nonnegative. The\nGauss–Newton\napproximation\nessentially\nignores\nthe\nnonlinearity of the estimated function (the NN, in our case),\nbut not that of the loss function. The back propagation\nequation for Gauss-Newton approximations of the second\nderivatives is\n(27)\nThis is very similar to the formula for back propagating the\nﬁrst derivatives, except that the sigmoid’s derivative and\nthe weight values are squared. The right-hand side is a sum\nof products of nonnegative terms, therefore the left-hand\nside term is nonnegative.\nThe third approximation we make is that we do not run\nthe average in (24) over the entire training set, but run it\non a small subset of the training set instead. In addition\nthe re-estimation does not need to be done often since the\nsecond-order properties of the error surface change rather\nslowly. In the experiments described in this paper, we re-\nestimate the\non 500 patterns before each training pass\nthrough the training set. Since the size of the training set\nis 60 000, the additional cost of re-estimating the\nis\nnegligible. The estimates are not particularly sensitive to the\nparticular subset of the training set used in the averaging.\nThis seems to suggest that the second-order properties of\nthe error surface are mainly determined by the structure\nof the network, rather than by the detailed statistics of the\nsamples. This algorithm is particularly useful for shared-\nweight networks because the weight sharing creates ill\nconditioning of the error surface. Because of the sharing,\none single parameter in the ﬁrst few layers can have\nan enormous inﬂuence on the output. Consequently, the\nsecond derivative of the error with respect to this parameter\nmay be very large, while it can be quite small for other\nparameters elsewhere in the network. The above algorithm\ncompensates for that phenomenon.\nUnlike most other second-order acceleration methods for\nback-propagation, the above method works in stochastic\nmode. It uses a diagonal approximation of the Hessian.\nLike the classical Levenberg–Marquardt algorithm, it uses\na “safety” factor\nto prevent the step sizes from getting\ntoo large if the second derivative estimates are small.\nHence the method is called the stochastic diagonal Lev-\nenberg–Marquardt method.\nACKNOWLEDGMENT\nSome of the systems described in this paper are the work\nof many researchers now at AT&T and Lucent Technolo-\ngies. In particular, C. Burges, C. Nohl, T. Cauble, and J.\nBromley contributed much to the check reading system.\nExperimental results described in Section III include con-\ntributions by C. Burges, A. Brunot, C. Cortes, H. Drucker,\nL. Jackel, U. M¨uller, B. Sch¨olkopf, and P. Simard. The\nauthors wish to thank F. Pereira, V. Vapnik, J. Denker, and\nI. Guyon for helpful discussions, C. Stenard and R. Higgins\nfor providing the applications that motivated some of this\nwork, and L. R. Rabiner and L. D. Jackel for relentless\nsupport and encouragement.\nREFERENCES\n[1] R. O. Duda and P. E. Hart, Pattern Classiﬁcation and Scene\nAnalysis.\nNew York: Wiley, 1973.\n[2] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard,\nW. Hubbard, and L. D. Jackel, “Backpropagation applied to\nhandwritten zip code recognition,” Neural Computation, vol. 1,\nno. 4, pp. 541–551, Winter 1989.\n[3] S. Seung, H. Sompolinsky, and N. Tishby, “Statistical mechan-\nics of learning from examples,” Phys. Rev. A, vol. 45, pp.\n6056–6091, 1992.\n[4] V. N. Vapnik, E. Levin, and Y. LeCun, “Measuring the vc-\ndimension of a learning machine,” Neural Computation, vol. 6,\nno. 5, pp. 851–876, 1994.\n[5] C. Cortes, L. Jackel, S. Solla, V. N. Vapnik, and J. Denker,\n“Learning curves: Asymptotic values and rate of convergence,”\n2320\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "in Advances in Neural Information Processing Systems 6, J. D.\nCowan, G. Tesauro, and J. Alspector, Eds.\nSan Mateo, CA:\nMorgan Kaufmann, 1994, pp. 327–334.\n[6] V. N. Vapnik, The Nature of Statistical Learning Theory.\nNew\nYork: Springer, 1995.\n[7]\n, Statistical Learning Theory.\nNew York: Wiley, 1998.\n[8] W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T.\nVetterling, Numerical Recipes: The Art of Scientiﬁc Computing.\nCambridge, UK: Cambridge Univ., 1986.\n[9] S. I. Amari, “A theory of adaptive pattern classiﬁers,” IEEE\nTrans. Electron. Comput., vol. EC-16, pp. 299–307, 1967.\n[10] Y. Tsypkin, Adaptation and Learning in Automatic Systems\nNew York: Academic, 1971.\n[11]\n, Foundations of the Theory of Learning Systems.\nNew\nYork: Academic, 1973.\n[12] M. Minsky and O. Selfridge, “Learning in random nets,” in\nProc. 4th London Symp. Information Theory, pp. 335–347, 1961.\n[13] D. H. Ackley, G. E. Hinton, and T. J. Sejnowski, “A learning\nalgorithm for Boltzmann machines,” Cognitive Sci., vol. 9, pp.\n147–169, 1985.\n[14] G. E. Hinton and T. J. Sejnowski, “Learning and relearning\nin Boltzmann machines,” in Parallel Distributed Processing:\nExplorations in the Microstructure of Cognition. Volume 1:\nFoundations, D. E. Rumelhart and J. L. McClelland, Eds.\nCambridge, MA: MIT, 1986.\n[15] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learn-\ning internal representations by error propagation,” in Parallel\nDistributed Processing: Explorations in the Microstructure of\nCognition, vol. I.\nCambridge, MA: Bradford Books, 1986,\npp. 318–362,\n[16] A. E. Bryson, Jr. and Y.-C. Ho, Applied Optimal Control.\nLondon, UK: Blaisdell, 1969.\n[17] Y. LeCun, “A learning scheme for asymmetric threshold\nnetworks,” in Proc. Cognitiva ’85, Paris, France, 1985, pp.\n599–604.\n[18]\n, “Learning processes in an asymmetric threshold net-\nwork,” in Disordered Systems and Biological Organization, E.\nBienenstock, F. Fogelman-Souli¨e, and G. Weisbuch, Eds.\nLes\nHouches, France: Springer-Verlag, 1986, pp. 233–240.\n[19] D. B. Parker, “Learning-logic,” Sloan School Manage., MIT,\nCambridge, MA, Tech. Rep., TR-47, Apr. 1985.\n[20] Y. LeCun, Mod´eles Connexionnistes de l’Apprentissage (Con-\nnectionist Learning Models), Ph.D. dissertation, Universit´e P.\net M. Curie (Paris 6), June 1987.\n[21]\n, “A theoretical framework for back-propagation,” in Proc.\n1988 Connectionist Models Summer School, D. Touretzky, G.\nHinton, and T. Sejnowski, Eds.\nPittsburgh, PA: CMU, Morgan\nKaufmann, 1988, pp. 21–28.\n[22] L. Bottou and P. Gallinari, “A framework for the cooperation\nof learning algorithms,” in Advances in Neural Information\nProcessing Systems, vol. 3, D. Touretzky and R. Lippmann,\nEds.\nDenver, CO: Morgan Kaufmann, 1991.\n[23] C. Y. Suen, C. Nadal, R. Legault, T. A. Mai, and L. Lam,\n“Computer recognition of unconstrained handwritten numerals,”\nProc. IEEE, vol. 80, pp. 1162–1180, July 1992.\n[24] S. N. Srihari, “High-performance reading machines,” Proc.\nIEEE., vol. 80, pp. 1120–1132, July 1992.\n[25] Y. LeCun, L. D. Jackel, B. Boser, J. S. Denker, H. P. Graf,\nI. Guyon, D. Henderson, R. E. Howard, and W. Hubbard,\n“Handwritten digit recognition: Applications of neural net chips\nand automatic learning,” IEEE Trans. Commun., vol. 37, pp.\n41–46, Nov. 1989.\n[26] J. Keeler, D. Rumelhart, and W. K. Leow, “Integrated seg-\nmentation and recognition of hand-printed numerals,” in Neural\nInformation Processing Systems, R. P. Lippmann, J. M. Moody,\nand D. S. Touretzky, Eds.\nSan Mateo, CA: Morgan Kaufmann,\nvol. 3, pp. 557–563, 1991.\n[27] O. Matan, C. J. C. Burges, Y. LeCun, and J. S. Denker, “Multi-\ndigit recognition using a space displacement neural network,”\nvol. 4, in Neural Information Processing Systems, J. M. Moody,\nS. J. Hanson, and R. P. Lippman, Eds.\nSan Mateo, CA:\nMorgan Kaufmann, 1992.\n[28] L. R. Rabiner, “A tutorial on hidden Markov models and\nselected applications in speech recognition,” Proc. IEEE, vol.\n77, pp. 257–286, Feb. 1989.\n[29] H. A. Bourland and N. Morgan, Connectionist Speech Recog-\nnition: A Hybrid Approach.\nBoston: Kluwer, 1994.\n[30] D. H. Hubel and T. N. Wiesel, “Receptive ﬁelds, binocular in-\nteraction, and functional architecture in the cat’s visual cortex,”\nJ. Physiology (London), vol. 160, pp. 106–154, 1962.\n[31] K. Fukushima, “Cognition: A self-organizing multilayered neu-\nral network,” Biological Cybern., vol. 20, pp. 121–136, 1975.\n[32] K. Fukushima and S. Miyake, “Neocognitron: A new algorithm\nfor pattern recognition tolerant of deformations and shifts in\nposition,” Pattern Recognit., vol. 15, no. 6, pp. 455–469, Nov.\n1982.\n[33] M. C. Mozer, The Perception of Multiple Objects: A Con-\nnectionist Approach.\nCambridge, MA: MIT-Bradford Books,\n1991.\n[34] Y. LeCun, “Generalization and network design strategies,”\nin Connectionism in Perspective, R. Pfeifer, Z. Schreter, F.\nFogelman, and L. Steels, Eds.\nZurich, Switzerland: Elsevier,\n1989.\n[35] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E.\nHoward, W. Hubbard, and L. D. Jackel, “Handwritten digit\nrecognition with a back-propagation network,” in Advances\nin Neural Information Processing Systems 2 (NIPS’89), David\nTouretzky, Ed.\nDenver, CO: Morgan Kaufmann, 1990.\n[36] G. L. Martin, “Centered-object integrated segmentation and\nrecognition of overlapping hand-printed characters,” Neural\nComputation, vol. 5, no. 3, pp. 419–429, 1993.\n[37] J. Wang and J. Jean, “Multi-resolution neural networks for\nomnifont character recognition,” in Proc. Int. Conf. Neural\nNetworks, vol. III, 1993, pp. 1588–1593.\n[38] Y. Bengio, Y. LeCun, C. Nohl, and C. Burges, “Lerec: A\nNN/HMM hybrid for on-line handwriting recognition,” Neural\nComputation, vol. 7, no. 5, 1995.\n[39] S. Lawrence, C. L. Giles, A. C. Tsoi, and A. D. Back, “Face\nrecognition: A convolutional neural network approach,” IEEE\nTrans. Neural Networks, vol. 8, pp. 98–113, Jan. 1997.\n[40] K. J. Lang and G. E. Hinton, “A time delay neural network\narchitecture for speech recognition,” Carnegie-Mellon Univ.,\nPittsburgh, PA, Tech. Rep. CMU-CS-88-152, 1988.\n[41] A. H. Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K.\nLang, “Phoneme recognition using time-delay neural networks,”\nIEEE Trans. Acoustics, Speech, Signal Processing, vol. 37, pp.\n328–339, Mar. 1989.\n[42] L. Bottou, F. Fogelman, P. Blanchet, and J. S. Lienard, “Speaker\nindependent isolated digit recognition: Multilayer perceptron\nversus dynamic time warping,” Neural Networks, vol. 3, pp.\n453–465, 1990.\n[43] P. Haffner and A. H. Waibel, “Time-delay neural networks\nembedding time alignment: A performance analysis,” in Proc.\nEUROSPEECH’91, 2nd Europ. Conf. Speech Communication\nand Technology, Genova, Italy.\n[44] I. Guyon, P. Albrecht, Y. LeCun, J. S. Denker, and W. Hubbard,\n“Design of a neural network character recognizer for a touch\nterminal,” Pattern Recognit., vol. 24, no. 2, pp. 105–119, 1991.\n[45] J. Bromley, J. W. Bentz, L. bottou, I. Guyon, Y. LeCun, C.\nMoore, E. S¨ackinger, and R. Shah, “Signature veriﬁcation using\na siamese time delay neural network,” Int. J. Pattern Recognit.\nArtiﬁcial Intell., vol. 7, no. 4, pp. 669–687, Aug. 1993.\n[46] Y. LeCun, I. Kanter, and S. Solla, “Eigenvalues of covariance\nmatrices: Application to neural-network learning,” Phys. Rev.\nLett., vol. 66, no. 18, pp. 2396–2399, May 1991.\n[47] T. G. Dietterich and G. Bakiri, “Solving multiclass learning\nproblems via error-correcting output codes,” J. Artiﬁcial Intell.\nRes., vol. 2, pp. 263–286, 1995.\n[48] L. R. Bahl, P. F. Brown, P. V. de Souza, and R. L. Mercer,\n“Maximum mutual information of hidden Markov model pa-\nrameters for speech recognition,” in Proc. Int. Conf. Acoustics,\nSpeech, Signal Processing, 1986, pp. 49–52.\n[49]\n, “Speech recognition with continuous-parameter hidden\nMarkov models,” Comput., Speech Language, vol. 2, pp.\n219–234, 1987.\n[50] B. H. Juang and S. Katagiri, “Discriminative learning for\nminimum error classiﬁcation,” IEEE Trans. Acoustics, Speech,\nSignal Processing, vol. 40, pp. 3043–3054, Dec. 1992.\n[51] Y. LeCun, L. D. Jackel, L. Bottou, A. Brunot, C. Cortes, J. S.\nDenker, H. Drucker, I. Guyon, U. A. Muller, E. S¨ackinger, P.\nSimard, and V. N. Vapnik, “Comparison of learning algorithms\nfor handwritten digit recognition,” in Int. Conf. Artiﬁcial Neural\nNetworks, F. Fogelman and P. Gallinari, Eds.\nParis: EC2 &\nCie, 1995, pp. 53–60.\n[52] I. Guyon, I. Poujaud, L. Personnaz, G. Dreyfus, J. Denker, and\nY. LeCun, “Comparing different neural net architectures for\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2321\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "classifying handwritten digits,” in Proc. IEEE IJCNN, Wash-\nington, DC, vol. II, 1989, pp. 127–132,.\n[53] R. Ott, “Construction of quadratic polynomial classiﬁers,” in\nProc. IEEE Int. Conf. Pattern Recognition, 1976, pp. 161–165.\n[54] J. Sch¨urmann, “A multifont word recognition system for postal\naddress reading,” IEEE Trans. Comput., vol. C-27, pp. 721–732,\nAug. 1978.\n[55] Y. Lee, “Handwritten digit recognition using k-nearest neigh-\nbor, radial-basis functions, and backpropagation neural net-\nworks,” Neural Computation, vol. 3, no. 3, pp. 440–449, 1991.\n[56] D. Saad and S. A. Solla, “Dynamics of on-line gradient descent\nlearning for multilayer neural networks,” in Advances in Neural\nInformation Processing Systems, vol. 8, D. S. Touretzky, M.\nC. Mozer, and M. E. Hasselmo, Eds.\nCambridge, MA: MIT,\n1996, pp. 302–308.\n[57] G. Cybenko, “Approximation by superpositions of sigmoidal\nfunctions,” Math. Control, Signals, Syst., vol. 2, no. 4, pp.\n303–314, 1989.\n[58] L. Bottou and V. N. Vapnik, “Local learning algorithms,”\nNeural Computation, vol. 4, no. 6, pp. 888–900, 1992.\n[59] R. E. Schapire, “The strength of weak learnability,” Machine\nLearning, vol. 5, no. 2, pp. 197–227, 1990.\n[60] H. Drucker, R. Schapire, and P. Simard, “Improving per-\nformance inneural networks using a boosting algorithm,” in\nAdvances in Neural Information Processing Systems 5, S. J.\nHanson, J. D. Cowan, and C. L. Giles, Eds.\nSan Mateo, CA:\nMorgan Kaufmann, 1993, pp. 42–49.\n[61] P. Simard, Y. LeCun, and J. Denker, “Efﬁcient pattern recog-\nnition using a new transformation distance,” in Advances in\nNeural Information Processing Systems, vol. 5, S. Hanson, J.\nCowan, and L. Giles, Eds.\nSan Mateo, CA: Morgan Kauf-\nmann, 1993.\n[62] B. Boser, I. Guyon, and V. Vapnik, “A training algorithm\nfor optimal margin classiﬁers,” in Proc. 5th Annu. Workshop\nComputational Learning Theory, vol. 5, 1992, pp. 144–152.\n[63] C. J. C. Burges and B. Schoelkopf, “Improving the accuracy\nand speed of support vector machines,” in Advances in Neural\nInformation Processing Systems 9, M. Jordan, M. Mozer, and\nT. Petsche, Eds.\nCambridge, MA: MIT, 1997.\n[64] E. S¨ackinger, B. Boser, J. Bromley, Y. LeCun, and L. D. Jackel,\n“Application of the ANNA neural network chip to high-speed\ncharacter recognition,” IEEE Trans. Neural Networks, vol. 3,\nno. 3, pp. 498–505, Mar. 1992.\n[65] J. S. Bridle, “Probabilistic interpretation of feedforward classi-\nﬁcation networks outputs, with relationship to statistical pattern\nrecognition,” in Neurocomputing, Algorithms, Architectures and\nApplications, F. Fogelman, J. Herault, and Y. Burnod, Eds.\nLes Arcs, France: Springer, 1989.\n[66] Y. LeCun, L. Bottou, and Y. Bengio, “Reading checks with\ngraph transformer networks,” in Proc. IEEE Int. Conf. Acous-\ntics, Speech, Signal Processing. Munich, Germany, vol. 1, 1997,\npp. 151–154,.\n[67] Y. Bengio, Neural Networks for Speech and Sequence Recogni-\ntion.\nLondon, UK: International Thompson, 1996.\n[68] C. Burges, O. Matan, Y. LeCun, J. Denker, L. Jackel, C.\nStenard, C. Nohl, and J. Ben, “Shortest path segmentation: A\nmethod for training a neural network to recognize character\nstrings,” in Proc. Int. Joint Conf. Neural Networks, Baltimore,\nMD, vol. 3, 1992, pp. 165–172.\n[69] T. M. Breuel, “A system for the off-line recognition of hand-\nwritten text,” in Proc. IEEE ICPR’94, Jerusalem, pp. 129–134.\n[70] A. Viterbi, “Error bounds for convolutional codes and an\nasymptotically optimum decoding algorithm,” IEEE Trans. In-\nform. Theory, vol. 15, pp. 260–269, Apr. 1967.\n[71] R. P. Lippmann and B. Gold, “Neural-net classiﬁers useful\nfor speech recognition,” in Proc. IEEE 1st Int. Conf. Neural\nNetworks, San Diego, CA, June 1987, pp. 417–422.\n[72] H. Sakoe, R. Isotani, K. Yoshida, K. Iso, and T. Watan-\nabe, “Speaker-independent word recognition using dynamic\nprogramming neural networks,” in Proc. Int. Conf. Acoustics,\nSpeech, Signal Processing, Glasgow, 1989, pp. 29–32.\n[73] J. S. Bridle, “Alphanets: A recurrent ‘neural’ network archi-\ntecture with a hidden Markov model interpretation,” Speech\nCommun., vol. 9, no. 1, pp. 83–92, 1990.\n[74] M. A. Franzini, K. F. Lee, and A. H. Waibel, “Connectionist\nviterbi training: A new hybrid method for continuous speech\nrecognition,” in Proc. Int. Conf. Acoustics, Speech, Signal Pro-\ncessing, Albuquerque, NM, 1990, pp. 425–428.\n[75] L. T. Niles and H. F. Silverman, “Combining hidden Markov\nmodels and neural network classiﬁers,” in Proc. Int. Conf.\nAcoustics, Speech, Signal Processing, Albuquerque, NM, 1990,\npp. 417–420.\n[76] X. Driancourt and L. Bottou, “MLP, LVQ and DP: Comparison\n& cooperation,” in Proc. Int. Joint Conf. Neural Networks,\nSeattle, WA, vol. 2, 1991, pp. 815–819.\n[77] Y. Bengio, R. De Mori, G. Flammia, and R. Kompe, “Global\noptimization of a neural network-hidden Markov model hybrid,”\nIEEE Trans. Neural Networks, vol. 3, pp. 252–259, March 1992.\n[78] P. Haffner and A. H. Waibel, “Multi-state time-delay neural net-\nworks for continuous speech recognition,” vol. 4, in Advances\nin Neural Information Processing Systems.\nSan Mateo, CA:\nMorgan Kaufmann, pp. 579–588, 1992.\n[79] Y. Bengio, P. Simard, and P. Frasconi, “Learning long-term\ndependencies with gradient descent is difﬁcult,” IEEE Trans.\nNeural Networks, vol. 5, no. 2, pp. 157–166, Mar. 1994.\n[80] T. Kohonen, G. Barna, and R. Chrisley, “Statistical pattern\nrecognition with neural network: Benchmarking studies,” in\nProc. IEEE 2nd Int. Conf. Neural Networks, San Diego, CA,\nvol. 1, 1988, pp. 61–68.\n[81] P. Haffner, “Connectionist speech recognition with a global\nMMI algorithm,” in Proc. EUROSPEECH’93, 3rd Europ. Conf.\nSpeech Communication and Technology, Berlin, pp. 1929–1932.\n[82] J. S. Denker and C. J. Burges, “Image segmentation and\nrecognition,” in The Mathematics of Induction.\nReading, MA:\nAddison Wesley, 1995.\n[83] L. Bottou, Une Approche th´eorique de l’Apprentissage Connex-\nionniste: Applications `a la Reconnaissance de la Parole, Ph.D.\ndissertation, Univ. Paris XI, France, 1991.\n[84] M. Rahim, Y. Bengio, and Y. LeCun, “Disriminative feature\nand model design for automatic speech recognition,” in Proc.\nEurospeech, Rhodes, Greece, 1997, pp. 75–78.\n[85] U. Bodenhausen, S. Manke, and A. Waibel, “Connectionist\narchitectural learning for high performance character and speech\nrecognition,” in Proc. Int. Conf. Acoustics, Speech, Signal Pro-\ncessing, Minneapolis, MN, vol. 1, 1993, pp. 625–628.\n[86] F. Pereira, M. Riley, and R. Sproat, “Weighted rational trans-\nductions and their application to human language processing,”\nin ARPA Natural Language Processing Workshop, 1994.\n[87] M. Lades, J. C. Vorbr¨uggen, J. Buhmann, and C. von der Mals-\nburg, “Distortion invariant object recognition in the dynamic\nlink architecture,” IEEE Trans. Comput., vol. 42, pp. 300–311,\nMarch 1993.\n[88] B. Boser, E. S¨ackinger, J. Bromley, Y. LeCun, and L. Jackel,\n“An analog neural network processor with programmable topol-\nogy,” IEEE J. Solid-State Circuits, vol. 26, pp. 2017–2025, Dec.\n1991.\n[89] M. Schenkel, H. Weissman, I. Guyon, C. Nohl, and D. Hender-\nson, “Recognition-based segmentation of on-line hand-printed\nwords,” in Advances in Neural Information Processing Systems\n5, S. J. Hanson, J. D. Cowan, and C. L. Giles, Eds.\nDenver,\nCO: Morgan Kaufmann, 1993, pp. 723–730.\n[90] C. Dugust, L. Devillers, and X. Aubert, “Combining TDNN\nand HMM in a hybrid system for improved continuous-speech\nrecognition,” IEEE Trans. Speech Audio Processing, vol. 2, pp.\n217–224, Jan. 1994.\n[91] O. Matan, H. S. Baird, J. Bromley, C. J. C. Burges, J. S. Denker,\nL. D. Jackel, Y. LeCun, E. P. D. Pednault, W. Satterﬁeld, C. E.\nStenard, and T. J. Thompson, “Reading handwritten digits: A\nZIP code recognition system,” IEEE Trans. Comput., vol. 25,\nno. 7, pp. 59–63, July 1992.\n[92] Y. Bengio and Y. LeCun, “Word normalization for on-line\nhandwritten word recognition,” in Proc. IEEE Int. Conf. Pattern\nRecognition, Jerusalem, 1994.\n[93] R. Vaillant, C. Monrocq, and Y. LeCun, “Original approach for\nthe localization of objects in images,” Proc. Inst. Elect. Eng.,\nvol. 141, no. 4, pp. 245–250, Aug. 1994.\n[94] R. Wolf and J. Platt, “Postal address block location using a\nconvolutional locator network,” in Advances in Neural Infor-\nmation Processing Systems 6, J. D. Cowan, G. Tesauro, and\nJ. Alspector, Eds.\nSan Mateo, CA: Morgan Kaufmann, 1994,\npp. 745–752.\n[95] S. Nowlan and J. Platt, “A convolutional neural network hand\ntracker,” in Advances in Neural Information Processing Systems\n7, G. Tesauro, D. Touretzky, and T. Leen, Eds.\nSan Mateo,\nCA: Morgan Kaufmann, 1995, pp. 901–908.\n[96] H. A. Rowley, S. Baluja, and T. Kanade, “Neural network-based\n2322\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "face detection,” in Proc. IEEE CVPR’96, pp. 203–208.\n[97] E. Osuna, R. Freund, and F. Girosi, “Training support vector\nmachines: An application to face detection,” in Proc. IEEE\nCVPR’96, pp. 130–136.\n[98] H. Bourlard and C. J. Wellekens, “Links between Markov\nmodels and multilayer perceptrons,” in Advances in Neural\nInformation Processing Systems, D. Touretzky, Ed.\nDenver:\nMorgan-Kaufmann, vol. 1, 1989, pp. 186–187.\n[99] Y. Bengio, R. De Mori, G. Flammia, and R. Kompe, “Neural\nnetwork—Gaussian mixture hybrid for speech recognition or\ndensity estimation,” in Advances in Neural Information Process-\ning Systems 4, J. E. Moody, S. J. Hanson, and R. P. Lippmann,\nEds.\nDenver, CO: Morgan Kaufmann, 1992, pp. 175–182.\n[100] F. C. N. Pereira and M. Riley, “Speech recognition by compo-\nsition of weighted ﬁnite automata,” in Finite-State Devices for\nNatural Lague Processing.\nCambridge, MA: MIT, 1997.\n[101] M. Mohri, “Finite-state transducers in language and speech\nprocessing,” Computational Linguistics, vol. 23, no. 2, pp.\n269–311, 1997.\n[102] I. Guyon, M. Schenkel, and J. Denker, “Overview and syn-\nthesis of on-line cursive handwriting recognition techniques,”\nin Handbook on Optical Character Recognition and Document\nImage Analysis, P. S. P. Wang and H. Bunke, Eds.\nNew York:\nWorld Scientiﬁc, 1996.\n[103] M. Mohri and M. Riley, “Weighted determinization and mini-\nmization for large vocabulary recognition,” in Proc. Eurospeech\n’97, Rhodes, Greece, pp. 131–134.\n[104] Y. Bengio and P. Frasconi, “An input/output HMM architec-\nture,” in Advances in Neural Information Processing Systems,\nvol. 7, G. Tesauro, D. Touretzky, and T. Leen, Eds.\nCam-\nbridge, MA: MIT, pp. 427–434, 1996.\n[105]\n, “Input/output HMM’s for sequence processing,” IEEE\nTrans. Neural Networks, vol. 7, no. 5, pp. 1231–1249, 1996.\n[106] M. Mohri, F. C. N. Pereira, and M. Riley, A Rational Design\nfor a Weighted Finite-State Transducer Library (Lecture Notes\nin Computer Science).\nNew York: Springer Verlag, 1997.\n[107] M. Rahim, C. H. Lee, and B. H. Juang, “Discriminative\nutterance veriﬁcation for connected digits recognition,” IEEE\nTrans. Speech Audio Processing, vol. 5, pp. 266–277, 1997.\n[108] M. Rahim, Y. Bengio, and Y. LeCun, “Discriminative feature\nand model design for automatic speech recognition,” in Proc.\nEurospeech ’97, Rhodes, Greece.\n[109] S. Bengio and Y. Bengio, “An EM algorithm for asynchronous\ninput/output hidden Markov models,” in Proc. International\nConference on Neural Information Processing, Hong-King,\n1996, pp. 328–334.\n[110] C. Tappert, C. Suen, and T. Wakahara, “The state of the art\nin on-line handwriting recognition,” IEEE Trans. Pattern Anal.\nMachine Intell., vol. 8, pp. 787–808, Dec. 1990.\n[111] S. Manke and U. Bodenhausen, “A connectionist recognizer\nfor on-line cursive handwriting recognition,” in Proc. Int. Conf.\nAcoustics, Speech, Signal Processing, Adelaide, vol. 2, 1994,\npp. 633–636.\n[112] M. Gilloux and M. Leroux, “Recognition of cursive script\namounts on postal checks,” in Proc. Europ. Conf. Postal Tech-\nnol., Nantes, France, June 1993, pp. 705–712.\n[113] D. Guillevic and C. Y. Suen, “Cursive script recognition applied\nto the processing of bank checks,” in Proc. Int. Conf. Document\nAnalysis Recognition, Montreal, Canada, Aug. 1995, pp. 11–14.\n[114] L. Lam, C. Y. Suen, D. Guillevic, N. W. Strathy, M. Cheriet,\nK. Liu, and J. N. Said, “Automatic processing of informa-\ntion on checks,” in Int. Conf. Systems, Man, and Cybernetics,\nVancouver, Canada, Oct. 1995, pp. 2353–2358.\n[115] C. J. C. Burges, J. I. Ben, J. S. Denker, Y. LeCun, and C. R.\nNohl, “Off line recognition of handwritten postal words using\nneural networks,” Int. J. Pattern Recognit. Artiﬁcial Intell., vol.\n7, no. 4, p. 689, 1993.\n[116] Y. LeCun, Y. Bengio, D. Henderson, A. Weisbuch, H. Weiss-\nman, and L. Jackel, “On-line handwriting recognition with\nneural networks: Spatial representation versus temporal repre-\nsentation,” in Proc. Int. Conf. Handwriting Drawing, 1993.\n[117] U. M¨uller, A. Gunzinger, and W. Guggenb¨uhl, “Fast neural net\nsimulation with a DSP processor array,” IEEE Trans. Neural\nNetworks, vol. 6, pp. 203–213, Jan. 1995.\n[118] R. Battiti, “First- and second-order methods for learning: Be-\ntween steepest descent and Newton’s method,” Neural Compu-\ntation, vol. 4, no. 2, pp. 141–166, 1992.\n[119] A. H. Kramer and A. Sangiovanni-Vincentelli, “Efﬁcient par-\nallel learning algorithms for neural networks,” in Advances in\nNeural Information Processing Systems, vol. 1, D. S. Touretzky,\nEd.\nSan Mateo, CA: Morgan Kaufmann, 1988, pp. 40–48.\n[120] M. Moller, Efﬁcient Training of Feed-Forward Neural Net-\nworks, Ph.D. dissertation, Aarhus Univ., Aarhus, Denmark,\n1993.\n[121] S. Becker and Y. LeCun, “Improving the convergence of\nback-propagation learning with second-order methods,” Univ.\nToronto Connectionist Res. Group, Toronto, Ontario, Canada,\nTech. Rep. CRG-TR-88-5, Sept. 1988.\nYann LeCun (Member, IEEE) received the\nDiplˆome d’Ing´enieur degree from the Ecole\nSup´erieure\nd’Ing´enieur\nen\nElectrotechnique\net Electronique, Paris, in 1983 and the Ph.D.\ndegree in computer science from the Universit´e\nPierre et Marie Curie, Paris, in 1987.\nDuring his time at the Universit´e Pierre et\nMarie Curie, he proposed an early version of\nthe back-propagation learning algorithm for\nneural networks. He joined the Department of\nComputer Science at the University of Toronto,\nToronto, Ont., Canada, as a Research Associate in 1987. In 1988, he joined\nthe Adaptive Systems Research Department at AT&T Bell Laboratories,\nHolmdel, NJ, where he worked on neural networks, machine learning, and\nhandwriting recognition. In 1996 he became Head of the Image Processing\nServices Research Department at AT&T Labs-Research, Red Bank, NJ.\nHe has published over 70 technical papers and book chapters on neural\nnetworks, machine learning, pattern recognition, handwriting recognition,\ndocument understanding, image processing, very large scale integration\n(VLSI) design, and information theory. In addition to the above topics, his\ncurrent interests include video-based user interfaces, image compression,\nand content-based indexing of multimedia material.\nDr. LeCun serves on the board of the Machine Learning Journal and\nhas served as Associate Editor of the IEEE TRANSACTIONS ON NEURAL\nNETWORKS. He is General Chair of the “Machines That Learn” workshop,\nwhich has been held every year since 1986 in Snowbird, UT. He has\nserved as Program Co-Chair of IJCNN’89, INNC’90, and NIPS’90,\n’94, and ’95. He is a member of the IEEE Neural Network for Signal\nProcessing Technical Committee.\nL´eon Bottou received the Dipˆome degree from\nEcole Polytechnique, Paris, in 1987, the Mag-\nist`ere en Math´ematiques Fondamentales et Ap-\npliqu´ees et Informatiques degree from Ecole\nNormale Sup´erieure, Paris in 1988, and the\nPh.D. degree in computer science from Univer-\nsit´e de Paris-Sud in 1991.\nDuring his time at Universit´e de Paris-Sud he\nworked on speech recognition and proposed a\nframework for stochastic gradient learning and\nglobal training. He then joined the Adaptive\nSystems Research Department at AT&T Bell Laboratories, Holmdel, NJ,\nwhere he worked on neural networks, statistical learning theory, and local\nlearning algorithms. He returned to France in 1992 as a Research Engineer\nat ONERA. He then became Chairman of Neuristique S.A., a company\nthat makes neural network simulators and trafﬁc forecasting software.\nHe returned to AT&T Bell Laboratories in 1995 where he worked on\ngraph transformer networks for optical character recognition. He is now a\nMember of the Image Processing Services Research Department at AT&T\nLabs-Research, Red Bank, NJ. Besides learning algorithms, his current\ninterests include arithmetic coding, image compression, and indexing.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2323\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n",
    "Yoshua Bengio received the B.Eng. degree in\nelectrical engineering and the M.Sc. and Ph.D.\ndegrees in computer science from McGill Uni-\nversity, Montreal, P.Q., Canada, in 1986, 1988,\nand 1991, respectively.\nIn 1991–1992 he was a Postdoctoral Fel-\nlow at the Massachusetts Institute of Technol-\nogy, Cambridge. In 1992 he joined AT&T Bell\nLaboratories, which later became AT&T Labs-\nResearch, Red Bank, NJ. In 1993 he joined the\nfaculty of the computer science department of\nthe Universit´e de Montr´eal, Montr´eal, P.Q., Canada, where he is now an\nAssociate Professor. Since his ﬁrst work on neural networks in 1986,\nhis research interests have been centered around learning algorithms,\nespecially for data with a sequential or spatial nature, such as speech,\nhandwriting, and time-series.\nPatrick Haffner graduated from Ecole Poly-\ntechnique, Paris, in 1987 and from Ecole\nNationale Sup´erieure des T´el´ecommunications\n(ENST), Paris, in 1989. He received the Ph.D\ndegree in speech and signal processing from\nENST in 1994.\nIn 1988 and 1990, he worked on the design of\nthe TDNN and the MS-TDNN architectures at\nATR (Japan) and Carnegie Mellon University.\nFrom 1989 to 1995, as a Research Scientist\nfor CNET/France-T´el´ecom in Lannion, France,\nhe developed connectionist learning algorithms for telephone speech\nrecognition. In 1995, he joined AT&T Bell Laboratories, Holmdel, NJ, and\nworked on the application of optical character recognition and transducers\nto the processing of ﬁnancial documents. In 1997, he joined the Image\nProcessing Services Research Department at AT&T Labs-Research, Red\nBank, NJ. His research interests include statistical and connectionist\nmodels for sequence recognition, machine learning, speech and image\nrecognition, and information theory.\n2324\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n"
  ],
  "full_text": "Gradient-Based Learning Applied\nto Document Recognition\nYANN LECUN, MEMBER, IEEE, L´EON BOTTOU, YOSHUA BENGIO, AND PATRICK HAFFNER\nInvited Paper\nMultilayer neural networks trained with the back-propagation\nalgorithm constitute the best example of a successful gradient-\nbased\nlearning\ntechnique.\nGiven\nan\nappropriate\nnetwork\narchitecture, gradient-based learning algorithms can be used\nto synthesize a complex decision surface that can classify\nhigh-dimensional patterns, such as handwritten characters, with\nminimal preprocessing. This paper reviews various methods\napplied to handwritten character recognition and compares them\non a standard handwritten digit recognition task. Convolutional\nneural networks, which are speciﬁcally designed to deal with\nthe variability of two dimensional (2-D) shapes, are shown to\noutperform all other techniques.\nReal-life document recognition systems are composed of multiple\nmodules including ﬁeld extraction, segmentation, recognition,\nand language modeling. A new learning paradigm, called graph\ntransformer networks (GTN’s), allows such multimodule systems\nto be trained globally using gradient-based methods so as to\nminimize an overall performance measure.\nTwo systems for online handwriting recognition are described.\nExperiments demonstrate the advantage of global training, and\nthe ﬂexibility of graph transformer networks.\nA graph transformer network for reading a bank check is\nalso described. It uses convolutional neural network character\nrecognizers combined with global training techniques to provide\nrecord accuracy on business and personal checks. It is deployed\ncommercially and reads several million checks per day.\nKeywords— Convolutional neural networks, document recog-\nnition, ﬁnite state transducers, gradient-based learning, graph\ntransformer networks, machine learning, neural networks, optical\ncharacter recognition (OCR).\nNOMENCLATURE\nGT\nGraph transformer.\nGTN\nGraph transformer network.\nHMM\nHidden Markov model.\nHOS\nHeuristic oversegmentation.\nK-NN\nK-nearest neighbor.\nManuscript received November 1, 1997; revised April 17, 1998.\nY. LeCun, L. Bottou, and P. Haffner are with the Speech and Image\nProcessing Services Research Laboratory, AT&T Labs-Research, Red\nBank, NJ 07701 USA.\nY. Bengio is with the D´epartement d’Informatique et de Recherche\nOp´erationelle, Universit´e de Montr´eal, Montr´eal, Qu´ebec H3C 3J7 Canada.\nPublisher Item Identiﬁer S 0018-9219(98)07863-3.\nNN\nNeural network.\nOCR\nOptical character recognition.\nPCA\nPrincipal component analysis.\nRBF\nRadial basis function.\nRS-SVM\nReduced-set support vector method.\nSDNN\nSpace displacement neural network.\nSVM\nSupport vector method.\nTDNN\nTime delay neural network.\nV-SVM\nVirtual support vector method.\nI.\nINTRODUCTION\nOver the last several years, machine learning techniques,\nparticularly when applied to NN’s, have played an increas-\ningly important role in the design of pattern recognition\nsystems. In fact, it could be argued that the availability\nof learning techniques has been a crucial factor in the\nrecent success of pattern recognition applications such as\ncontinuous speech recognition and handwriting recognition.\nThe main message of this paper is that better pattern\nrecognition systems can be built by relying more on auto-\nmatic learning and less on hand-designed heuristics. This\nis made possible by recent progress in machine learning\nand computer technology. Using character recognition as a\ncase study, we show that hand-crafted feature extraction can\nbe advantageously replaced by carefully designed learning\nmachines that operate directly on pixel images. Using\ndocument understanding as a case study, we show that the\ntraditional way of building recognition systems by manually\nintegrating individually designed modules can be replaced\nby a uniﬁed and well-principled design paradigm, called\nGTN’s, which allows training all the modules to optimize\na global performance criterion.\nSince the early days of pattern recognition it has been\nknown that the variability and richness of natural data,\nbe it speech, glyphs, or other types of patterns, make it\nalmost impossible to build an accurate recognition system\nentirely by hand. Consequently, most pattern recognition\nsystems are built using a combination of automatic learning\ntechniques and hand-crafted algorithms. The usual method\n0018–9219/98$10.00 1998 IEEE\n2278\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 1.\nTraditional pattern recognition is performed with two\nmodules: a ﬁxed feature extractor and a trainable classiﬁer.\nof recognizing individual patterns consists in dividing the\nsystem into two main modules shown in Fig. 1. The ﬁrst\nmodule, called the feature extractor, transforms the input\npatterns so that they can be represented by low-dimensional\nvectors or short strings of symbols that: 1) can be easily\nmatched or compared and 2) are relatively invariant with\nrespect to transformations and distortions of the input pat-\nterns that do not change their nature. The feature extractor\ncontains most of the prior knowledge and is rather speciﬁc\nto the task. It is also the focus of most of the design effort,\nbecause it is often entirely hand crafted. The classiﬁer,\non the other hand, is often general purpose and trainable.\nOne of the main problems with this approach is that the\nrecognition accuracy is largely determined by the ability of\nthe designer to come up with an appropriate set of features.\nThis turns out to be a daunting task which, unfortunately,\nmust be redone for each new problem. A large amount of\nthe pattern recognition literature is devoted to describing\nand comparing the relative merits of different feature sets\nfor particular tasks.\nHistorically, the need for appropriate feature extractors\nwas due to the fact that the learning techniques used\nby the classiﬁers were limited to low-dimensional spaces\nwith easily separable classes [1]. A combination of three\nfactors has changed this vision over the last decade. First,\nthe availability of low-cost machines with fast arithmetic\nunits allows for reliance on more brute-force “numerical”\nmethods than on algorithmic reﬁnements. Second, the avail-\nability of large databases for problems with a large market\nand wide interest, such as handwriting recognition, has\nenabled designers to rely more on real data and less on\nhand-crafted feature extraction to build recognition systems.\nThe third and very important factor is the availability\nof powerful machine learning techniques that can handle\nhigh-dimensional inputs and can generate intricate decision\nfunctions when fed with these large data sets. It can be\nargued that the recent progress in the accuracy of speech\nand handwriting recognition systems can be attributed in\nlarge part to an increased reliance on learning techniques\nand large training data sets. As evidence of this fact, a large\nproportion of modern commercial OCR systems use some\nform of multilayer NN trained with back propagation.\nIn this study, we consider the tasks of handwritten\ncharacter recognition (Sections I and II) and compare the\nperformance of several learning techniques on a benchmark\ndata set for handwritten digit recognition (Section III).\nWhile more automatic learning is beneﬁcial, no learning\ntechnique can succeed without a minimal amount of prior\nknowledge about the task. In the case of multilayer NN’s,\na good way to incorporate knowledge is to tailor its archi-\ntecture to the task. Convolutional NN’s [2], introduced in\nSection II, are an example of specialized NN architectures\nwhich incorporate knowledge about the invariances of two-\ndimensional (2-D) shapes by using local connection patterns\nand by imposing constraints on the weights. A comparison\nof several methods for isolated handwritten digit recogni-\ntion is presented in Section III. To go from the recognition\nof individual characters to the recognition of words and\nsentences in documents, the idea of combining multiple\nmodules trained to reduce the overall error is introduced\nin Section IV. Recognizing variable-length objects such as\nhandwritten words using multimodule systems is best done\nif the modules manipulate directed graphs. This leads to the\nconcept of trainable GTN, also introduced in Section IV.\nSection V describes the now classical method of HOS for\nrecognizing words or other character strings. Discriminative\nand nondiscriminative gradient-based techniques for train-\ning a recognizer at the word level without requiring manual\nsegmentation and labeling are presented in Section VI.\nSection VII presents the promising space-displacement NN\napproach that eliminates the need for segmentation heuris-\ntics by scanning a recognizer at all possible locations on\nthe input. In Section VIII, it is shown that trainable GTN’s\ncan be formulated as multiple generalized transductions\nbased on a general graph composition algorithm. The\nconnections between GTN’s and HMM’s, commonly used\nin speech recognition, is also treated. Section IX describes\na globally trained GTN system for recognizing handwriting\nentered in a pen computer. This problem is known as\n“online” handwriting recognition since the machine must\nproduce immediate feedback as the user writes. The core\nof the system is a convolutional NN. The results clearly\ndemonstrate the advantages of training a recognizer at\nthe word level, rather than training it on presegmented,\nhand-labeled, isolated characters. Section X describes a\ncomplete GTN-based system for reading handwritten and\nmachine-printed bank checks. The core of the system is\nthe convolutional NN called LeNet-5, which is described\nin Section II. This system is in commercial use in the\nNCR Corporation line of check recognition systems for the\nbanking industry. It is reading millions of checks per month\nin several banks across the United States.\nA. Learning from Data\nThere are several approaches to automatic machine learn-\ning, but one of the most successful approaches, popularized\nin recent years by the NN community, can be called “nu-\nmerical” or gradient-based learning. The learning machine\ncomputes a function\nwhere\nis the\nth\ninput pattern, and\nrepresents the collection of adjustable\nparameters in the system. In a pattern recognition setting,\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2279\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nthe output\nmay be interpreted as the recognized class\nlabel of pattern\nor as scores or probabilities associated\nwith each class. A loss function\nmeasures the discrepancy between\nthe “correct” or\ndesired output for pattern\nand the output produced by\nthe system. The average loss function\nis the\naverage of the errors\nover a set of labeled examples\ncalled the training set\nIn the\nsimplest setting, the learning problem consists in ﬁnding\nthe value of\nthat minimizes\nIn practice,\nthe performance of the system on a training set is of little\ninterest. The more relevant measure is the error rate of the\nsystem in the ﬁeld, where it would be used in practice.\nThis performance is estimated by measuring the accuracy\non a set of samples disjoint from the training set, which is\ncalled the test set. Much theoretical and experimental work\n[3]–[5] has shown that the gap between the expected error\nrate on the test set\nand the error rate on the training\nset\ndecreases with the number of training samples\napproximately as\n(1)\nwhere\nis the number of training samples,\nis a measure\nof “effective capacity” or complexity of the machine [6],\n[7],\nis a number between 0.5 and 1.0, and\nis a constant.\nThis gap always decreases when the number of training\nsamples increases. Furthermore, as the capacity\nincreases,\ndecreases. Therefore, when increasing the capacity\nthere is a tradeoff between the decrease of\nand the\nincrease of the gap, with an optimal value of the capacity\nthat achieves the lowest generalization error\nMost\nlearning algorithms attempt to minimize\nas well as\nsome estimate of the gap. A formal version of this is called\nstructural risk minimization [6], [7], and it is based on deﬁn-\ning a sequence of learning machines of increasing capacity,\ncorresponding to a sequence of subsets of the parameter\nspace such that each subset is a superset of the previous\nsubset. In practical terms, structural risk minimization is\nimplemented by minimizing\nwhere the\nfunction\nis called a regularization function and\nis\na constant.\nis chosen such that it takes large values\non parameters\nthat belong to high-capacity subsets of\nthe parameter space. Minimizing\nin effect limits the\ncapacity of the accessible subset of the parameter space,\nthereby controlling the tradeoff between minimizing the\ntraining error and minimizing the expected gap between\nthe training error and test error.\nB. Gradient-Based Learning\nThe general problem of minimizing a function with\nrespect to a set of parameters is at the root of many\nissues in computer science. Gradient-based learning draws\non the fact that it is generally much easier to minimize\na reasonably smooth, continuous function than a discrete\n(combinatorial) function. The loss function can be mini-\nmized by estimating the impact of small variations of the\nparameter values on the loss function. This is measured\nby the gradient of the loss function with respect to the\nparameters. Efﬁcient learning algorithms can be devised\nwhen the gradient vector can be computed analytically (as\nopposed to numerically through perturbations). This is the\nbasis of numerous gradient-based learning algorithms with\ncontinuous-valued parameters. In the procedures described\nin this article, the set of parameters\nis a real-valued\nvector, with respect to which\nis continuous, as well\nas differentiable almost everywhere. The simplest mini-\nmization procedure in such a setting is the gradient descent\nalgorithm where\nis iteratively adjusted as follows:\n(2)\nIn the simplest case,\nis a scalar constant. More sophis-\nticated procedures use variable\nor substitute it for a\ndiagonal matrix, or substitute it for an estimate of the\ninverse Hessian matrix as in Newton or quasi-Newton\nmethods. The conjugate gradient method [8] can also be\nused. However, Appendix B shows that despite many\nclaims to the contrary in the literature, the usefulness of\nthese second-order methods to large learning machines is\nvery limited.\nA popular minimization procedure is the stochastic gra-\ndient algorithm, also called the online update. It consists\nin updating the parameter vector using a noisy, or approxi-\nmated, version of the average gradient. In the most common\ninstance of it,\nis updated on the basis of a single sample\n(3)\nWith this procedure the parameter vector ﬂuctuates around\nan average trajectory, but usually it converges considerably\nfaster than regular gradient descent and second-order meth-\nods on large training sets with redundant samples (such\nas those encountered in speech or character recognition).\nThe reasons for this are explained in Appendix B. The\nproperties of such algorithms applied to learning have been\nstudied theoretically since the 1960’s [9]–[11], but practical\nsuccesses for nontrivial tasks did not occur until the mid\neighties.\nC. Gradient Back Propagation\nGradient-based learning procedures have been used since\nthe late 1950’s, but they were mostly limited to linear\nsystems [1]. The surprising usefulness of such simple\ngradient descent techniques for complex machine learning\ntasks was not widely realized until the following three\nevents occurred. The ﬁrst event was the realization that,\ndespite early warnings to the contrary [12], the presence of\nlocal minima in the loss function does not seem to be a\nmajor problem in practice. This became apparent when it\nwas noticed that local minima did not seem to be a major\nimpediment to the success of early nonlinear gradient-based\nlearning techniques such as Boltzmann machines [13], [14].\nThe second event was the popularization by Rumelhart et\nal. [15] and others of a simple and efﬁcient procedure\nto compute the gradient in a nonlinear system composed\n2280\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nof several layers of processing, i.e., the back-propagation\nalgorithm. The third event was the demonstration that the\nback-propagation procedure applied to multilayer NN’s\nwith sigmoidal units can solve complicated learning tasks.\nThe basic idea of back propagation is that gradients can\nbe computed efﬁciently by propagation from the output to\nthe input. This idea was described in the control theory\nliterature of the early 1960’s [16], but its application to ma-\nchine learning was not generally realized then. Interestingly,\nthe early derivations of back propagation in the context\nof NN learning did not use gradients but “virtual targets”\nfor units in intermediate layers [17], [18], or minimal\ndisturbance arguments [19]. The Lagrange formalism used\nin the control theory literature provides perhaps the best\nrigorous method for deriving back propagation [20] and for\nderiving generalizations of back propagation to recurrent\nnetworks [21] and networks of heterogeneous modules [22].\nA simple derivation for generic multilayer systems is given\nin Section I-E.\nThe fact that local minima do not seem to be a problem\nfor multilayer NN’s is somewhat of a theoretical mystery.\nIt is conjectured that if the network is oversized for the\ntask (as is usually the case in practice), the presence of\n“extra dimensions” in parameter space reduces the risk\nof unattainable regions. Back propagation is by far the\nmost widely used neural-network learning algorithm, and\nprobably the most widely used learning algorithm of any\nform.\nD. Learning in Real Handwriting Recognition Systems\nIsolated handwritten character recognition has been ex-\ntensively studied in the literature (see [23] and [24] for\nreviews), and it was one of the early successful applications\nof NN’s [25]. Comparative experiments on recognition of\nindividual handwritten digits are reported in Section III.\nThey show that NN’s trained with gradient-based learning\nperform better than all other methods tested here on the\nsame data. The best NN’s, called convolutional networks,\nare designed to learn to extract relevant features directly\nfrom pixel images (see Section II).\nOne of the most difﬁcult problems in handwriting recog-\nnition, however, is not only to recognize individual charac-\nters, but also to separate out characters from their neighbors\nwithin the word or sentence, a process known as seg-\nmentation. The technique for doing this that has become\nthe “standard” is called HOS. It consists of generating a\nlarge number of potential cuts between characters using\nheuristic image processing techniques, and subsequently\nselecting the best combination of cuts based on scores\ngiven for each candidate character by the recognizer. In\nsuch a model, the accuracy of the system depends upon the\nquality of the cuts generated by the heuristics, and on the\nability of the recognizer to distinguish correctly segmented\ncharacters from pieces of characters, multiple characters,\nor otherwise incorrectly segmented characters. Training a\nrecognizer to perform this task poses a major challenge\nbecause of the difﬁculty in creating a labeled database\nof incorrectly segmented characters. The simplest solution\nconsists of running the images of character strings through\nthe segmenter and then manually labeling all the character\nhypotheses. Unfortunately, not only is this an extremely\ntedious and costly task, it is also difﬁcult to do the labeling\nconsistently. For example, should the right half of a cut-up\nfour be labeled as a one or as a noncharacter? Should the\nright half of a cut-up eight be labeled as a three?\nThe ﬁrst solution, described in Section V, consists of\ntraining the system at the level of whole strings of char-\nacters rather than at the character level. The notion of\ngradient-based learning can be used for this purpose. The\nsystem is trained to minimize an overall loss function which\nmeasures the probability of an erroneous answer. Section V\nexplores various ways to ensure that the loss function\nis differentiable and therefore lends itself to the use of\ngradient-based learning methods. Section V introduces the\nuse of directed acyclic graphs whose arcs carry numerical\ninformation as a way to represent the alternative hypotheses\nand introduces the idea of GTN.\nThe second solution, described in Section VII, is to\neliminate segmentation altogether. The idea is to sweep\nthe recognizer over every possible location on the input\nimage, and to rely on the “character spotting” property\nof the recognizer, i.e., its ability to correctly recognize\na well-centered character in its input ﬁeld, even in the\npresence of other characters besides it, while rejecting\nimages containing no centered characters [26], [27]. The\nsequence of recognizer outputs obtained by sweeping the\nrecognizer over the input is then fed to a GTN that takes\nlinguistic constraints into account and ﬁnally extracts the\nmost likely interpretation. This GTN is somewhat similar\nto HMM’s, which makes the approach reminiscent of the\nclassical speech recognition [28], [29]. While this technique\nwould be quite expensive in the general case, the use of\nconvolutional NN’s makes it particularly attractive because\nit allows signiﬁcant savings in computational cost.\nE. Globally Trainable Systems\nAs stated earlier, most practical pattern recognition sys-\ntems are composed of multiple modules. For example, a\ndocument recognition system is composed of a ﬁeld loca-\ntor (which extracts regions of interest), a ﬁeld segmenter\n(which cuts the input image into images of candidate\ncharacters), a recognizer (which classiﬁes and scores each\ncandidate character), and a contextual postprocessor, gen-\nerally based on a stochastic grammar (which selects the\nbest grammatically correct answer from the hypotheses\ngenerated by the recognizer). In most cases, the information\ncarried from module to module is best represented as\ngraphs with numerical information attached to the arcs.\nFor example, the output of the recognizer module can be\nrepresented as an acyclic graph where each arc contains the\nlabel and the score of a candidate character, and where each\npath represents an alternative interpretation of the input\nstring. Typically, each module is manually optimized, or\nsometimes trained, outside of its context. For example, the\ncharacter recognizer would be trained on labeled images\nof presegmented characters. Then the complete system is\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2281\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nassembled, and a subset of the parameters of the modules\nis manually adjusted to maximize the overall performance.\nThis last step is extremely tedious, time consuming, and\nalmost certainly suboptimal.\nA better alternative would be to somehow train the entire\nsystem so as to minimize a global error measure such\nas the probability of character misclassiﬁcations at the\ndocument level. Ideally, we would want to ﬁnd a good\nminimum of this global loss function with respect to all the\nparameters in the system. If the loss function\nmeasuring\nthe performance can be made differentiable with respect\nto the system’s tunable parameters\nwe can ﬁnd a local\nminimum of\nusing gradient-based learning. However, at\nﬁrst glance, it appears that the sheer size and complexity\nof the system would make this intractable.\nTo ensure that the global loss function\nis\ndifferentiable, the overall system is built as a feedforward\nnetwork of differentiable modules. The function imple-\nmented by each module must be continuous and differ-\nentiable almost everywhere with respect to the internal\nparameters of the module (e.g., the weights of an NN\ncharacter recognizer in the case of a character recognition\nmodule), and with respect to the module’s inputs. If this is\nthe case, a simple generalization of the well-known back-\npropagation procedure can be used to efﬁciently compute\nthe gradients of the loss function with respect to all the\nparameters in the system [22]. For example, let us consider\na system built as a cascade of modules, each of which\nimplements a function\nwhere\nis a vector representing the output of the module,\nis\nthe vector of tunable parameters in the module (a subset of\nand\nis the module’s input vector (as well as the\nprevious module’s output vector). The input\nto the ﬁrst\nmodule is the input pattern\nIf the partial derivative of\nwith respect to\nis known, then the partial derivatives\nof\nwith respect to\nand\ncan be computed using\nthe backward recurrence\n(4)\nwhere\nis the Jacobian of\nwith\nrespect to\nevaluated at the point\nand\nis the Jacobian of\nwith respect to\nThe Jacobian of a vector function is a matrix containing\nthe partial derivatives of all the outputs with respect to\nall the inputs. The ﬁrst equation computes some terms\nof the gradient of\nwhile the second equation\ngenerates a backward recurrence, as in the well-known\nback-propagation procedure for NN’s. We can average\nthe gradients over the training patterns to obtain the full\ngradient. It is interesting to note that in many instances\nthere is no need to explicitly compute the Jacobian ma-\ntrix. The above formula uses the product of the Jacobian\nwith a vector of partial derivatives, and it is often easier\nto compute this product directly without computing the\nJacobian beforehand. In analogy with ordinary multilayer\nNN’s, all but the last module are called hidden layers\nbecause their outputs are not observable from the outside.\nIn more complex situations than the simple cascade of\nmodules described above, the partial derivative notation\nbecomes somewhat ambiguous and awkward. A completely\nrigorous derivation in more general cases can be done using\nLagrange functions [20]–[22].\nTraditional multilayer NN’s are a special case of the\nabove where the state information\nis represented\nwith ﬁxed-sized vectors, and where the modules are\nalternated layers of matrix multiplications (the weights)\nand component-wise sigmoid functions (the neurons).\nHowever, as stated earlier, the state information in complex\nrecognition system is best represented by graphs with\nnumerical information attached to the arcs. In this case,\neach module, called a GT, takes one or more graphs as input\nand produces a graph as output. Networks of such modules\nare called GTN’s. Sections IV, VI, and VIII develop the\nconcept of GTN’s and show that gradient-based learning\ncan be used to train all the parameters in all the modules\nso as to minimize a global loss function. It may seem\nparadoxical that gradients can be computed when the state\ninformation is represented by essentially discrete objects\nsuch as graphs, but that difﬁculty can be circumvented,\nas shown later.\nII.\nCONVOLUTIONAL NEURAL NETWORKS FOR\nISOLATED CHARACTER RECOGNITION\nThe ability of multilayer networks trained with gradi-\nent descent to learn complex, high-dimensional, nonlinear\nmappings from large collections of examples makes them\nobvious candidates for image recognition tasks. In the\ntraditional model of pattern recognition, a hand-designed\nfeature extractor gathers relevant information from the input\nand eliminates irrelevant variabilities. A trainable classiﬁer\nthen categorizes the resulting feature vectors into classes. In\nthis scheme, standard, fully connected multilayer networks\ncan be used as classiﬁers. A potentially more interesting\nscheme is to rely as much as possible on learning in the\nfeature extractor itself. In the case of character recognition,\na network could be fed with almost raw inputs (e.g.,\nsize-normalized images). While this can be done with an\nordinary fully connected feedforward network with some\nsuccess for tasks such as character recognition, there are\nproblems.\nFirst, typical images are large, often with several hundred\nvariables (pixels). A fully connected ﬁrst layer with, e.g.,\none hundred hidden units in the ﬁrst layer would already\ncontain several tens of thousands of weights. Such a large\nnumber of parameters increases the capacity of the system\nand therefore requires a larger training set. In addition, the\nmemory requirement to store so many weights may rule out\ncertain hardware implementations. But the main deﬁciency\nof unstructured nets for image or speech applications is that\nthey have no built-in invariance with respect to translations\nor local distortions of the inputs. Before being sent to\nthe ﬁxed-size input layer of an NN, character images,\n2282\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 2.\nArchitecture of LeNet-5, a convolutional NN, here used for digits recognition. Each plane\nis a feature map, i.e., a set of units whose weights are constrained to be identical.\nor other 2-D or one-dimensional (1-D) signals, must be\napproximately size normalized and centered in the input\nﬁeld. Unfortunately, no such preprocessing can be perfect:\nhandwriting is often normalized at the word level, which\ncan cause size, slant, and position variations for individual\ncharacters. This, combined with variability in writing style,\nwill cause variations in the position of distinctive features\nin input objects. In principle, a fully connected network of\nsufﬁcient size could learn to produce outputs that are invari-\nant with respect to such variations. However, learning such\na task would probably result in multiple units with similar\nweight patterns positioned at various locations in the input\nso as to detect distinctive features wherever they appear on\nthe input. Learning these weight conﬁgurations requires a\nvery large number of training instances to cover the space of\npossible variations. In convolutional networks, as described\nbelow, shift invariance is automatically obtained by forcing\nthe replication of weight conﬁgurations across space.\nSecondly, a deﬁciency of fully connected architectures is\nthat the topology of the input is entirely ignored. The input\nvariables can be presented in any (ﬁxed) order without af-\nfecting the outcome of the training. On the contrary, images\n(or time-frequency representations of speech) have a strong\n2-D local structure: variables (or pixels) that are spatially or\ntemporally nearby are highly correlated. Local correlations\nare the reasons for the well-known advantages of extracting\nand combining local features before recognizing spatial\nor temporal objects, because conﬁgurations of neighboring\nvariables can be classiﬁed into a small number of categories\n(e.g., edges, corners, etc.). Convolutional networks force\nthe extraction of local features by restricting the receptive\nﬁelds of hidden units to be local.\nA. Convolutional Networks\nConvolutional networks combine three architectural ideas\nto ensure some degree of shift, scale, and distortion in-\nvariance: 1) local receptive ﬁelds; 2) shared weights (or\nweight replication); and 3) spatial or temporal subsampling.\nA typical convolutional network for recognizing characters,\ndubbed LeNet-5, is shown in Fig. 2. The input plane\nreceives images of characters that are approximately size\nnormalized and centered. Each unit in a layer receives\ninputs from a set of units located in a small neighborhood\nin the previous layer. The idea of connecting units to local\nreceptive ﬁelds on the input goes back to the perceptron in\nthe early 1960’s, and it was almost simultaneous with Hubel\nand Wiesel’s discovery of locally sensitive, orientation-\nselective neurons in the cat’s visual system [30]. Local\nconnections have been used many times in neural models\nof visual learning [2], [18], [31]–[34]. With local receptive\nﬁelds neurons can extract elementary visual features such\nas oriented edges, endpoints, corners (or similar features in\nother signals such as speech spectrograms). These features\nare then combined by the subsequent layers in order to\ndetect higher order features. As stated earlier, distortions or\nshifts of the input can cause the position of salient features\nto vary. In addition, elementary feature detectors that are\nuseful on one part of the image are likely to be useful across\nthe entire image. This knowledge can be applied by forcing\na set of units, whose receptive ﬁelds are located at different\nplaces on the image, to have identical weight vectors [15],\n[32], [34]. Units in a layer are organized in planes within\nwhich all the units share the same set of weights. The set of\noutputs of the units in such a plane is called a feature map.\nUnits in a feature map are all constrained to perform the\nsame operation on different parts of the image. A complete\nconvolutional layer is composed of several feature maps\n(with different weight vectors), so that multiple features\ncan be extracted at each location. A concrete example of\nthis is the ﬁrst layer of LeNet-5 shown in Fig. 2. Units\nin the ﬁrst hidden layer of LeNet-5 are organized in six\nplanes, each of which is a feature map. A unit in a feature\nmap has 25 inputs connected to a 5 5 area in the input,\ncalled the receptive ﬁeld of the unit. Each unit has 25\ninputs and therefore 25 trainable coefﬁcients plus a trainable\nbias. The receptive ﬁelds of contiguous units in a feature\nmap are centered on corresponding contiguous units in the\nprevious layer. Therefore, receptive ﬁelds of neighboring\nunits overlap. For example, in the ﬁrst hidden layer of\nLeNet-5, the receptive ﬁelds of horizontally contiguous\nunits overlap by four columns and ﬁve rows. As stated\nearlier, all the units in a feature map share the same set of 25\nweights and the same bias, so they detect the same feature\nat all possible locations on the input. The other feature\nmaps in the layer use different sets of weights and biases,\nthereby extracting different types of local features. In the\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2283\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\ncase of LeNet-5, at each input location six different types\nof features are extracted by six units in identical locations\nin the six feature maps. A sequential implementation of\na feature map would scan the input image with a single\nunit that has a local receptive ﬁeld and store the states\nof this unit at corresponding locations in the feature map.\nThis operation is equivalent to a convolution, followed by\nan additive bias and squashing function, hence the name\nconvolutional network. The kernel of the convolution is the\nset of connection weights used by the units in the feature\nmap. An interesting property of convolutional layers is that\nif the input image is shifted, the feature map output will be\nshifted by the same amount, but it will be left unchanged\notherwise. This property is at the basis of the robustness of\nconvolutional networks to shifts and distortions of the input.\nOnce a feature has been detected, its exact location\nbecomes less important. Only its approximate position\nrelative to other features is relevant. For example, once\nwe know that the input image contains the endpoint of a\nroughly horizontal segment in the upper left area, a corner\nin the upper right area, and the endpoint of a roughly\nvertical segment in the lower portion of the image, we can\ntell the input image is a seven. Not only is the precise\nposition of each of those features irrelevant for identifying\nthe pattern, it is potentially harmful because the positions\nare likely to vary for different instances of the character. A\nsimple way to reduce the precision with which the position\nof distinctive features are encoded in a feature map is\nto reduce the spatial resolution of the feature map. This\ncan be achieved with a so-called subsampling layer, which\nperforms a local averaging and a subsampling, thereby\nreducing the resolution of the feature map and reducing\nthe sensitivity of the output to shifts and distortions. The\nsecond hidden layer of LeNet-5 is a subsampling layer. This\nlayer comprises six feature maps, one for each feature map\nin the previous layer. The receptive ﬁeld of each unit is\na 2 2 area in the previous layer’s corresponding feature\nmap. Each unit computes the average of its four inputs,\nmultiplies it by a trainable coefﬁcient, adds a trainable\nbias, and passes the result through a sigmoid function.\nContiguous units have nonoverlapping contiguous receptive\nﬁelds. Consequently, a subsampling layer feature map has\nhalf the number of rows and columns as the feature maps in\nthe previous layer. The trainable coefﬁcient and bias control\nthe effect of the sigmoid nonlinearity. If the coefﬁcient is\nsmall, then the unit operates in a quasi-linear mode, and the\nsubsampling layer merely blurs the input. If the coefﬁcient\nis large, subsampling units can be seen as performing a\n“noisy OR” or a “noisy AND” function depending on\nthe value of the bias. Successive layers of convolutions\nand subsampling are typically alternated resulting in a\n“bipyramid”: at each layer, the number of feature maps\nis increased as the spatial resolution is decreased. Each\nunit in the third hidden layer in Fig. 2 may have input\nconnections from several feature maps in the previous\nlayer. The convolution/subsampling combination, inspired\nby Hubel and Wiesel’s notions of “simple” and “complex”\ncells, was implemented in Fukushima’s Neocognitron [32],\nthough no globally supervised learning procedure such\nas back propagation was available then. A large degree\nof invariance to geometric transformations of the input\ncan be achieved with this progressive reduction of spatial\nresolution compensated by a progressive increase of the\nrichness of the representation (the number of feature maps).\nSince all the weights are learned with back propagation,\nconvolutional networks can be seen as synthesizing their\nown feature extractor. The weight sharing technique has\nthe interesting side effect of reducing the number of free\nparameters, thereby reducing the “capacity” of the machine\nand reducing the gap between test error and training error\n[34]. The network in Fig. 2 contains 345 308 connections,\nbut only 60 000 trainable free parameters because of the\nweight sharing.\nFixed-size convolutional networks have been applied to\nmany applications, among other handwriting recognition\n[35], [36], machine-printed character recognition [37], on-\nline handwriting recognition [38], and face recognition\n[39]. Fixed-size convolutional networks that share weights\nalong a single temporal dimension are known as time-delay\nNN’s (TDNN’s). TDNN’s have been used in phoneme\nrecognition (without subsampling) [40], [41], spoken word\nrecognition (with subsampling) [42], [43], online recogni-\ntion of isolated handwritten characters [44], and signature\nveriﬁcation [45].\nB. LeNet-5\nThis section describes in more detail the architecture of\nLeNet-5, the Convolutional NN used in the experiments.\nLeNet-5 comprises seven layers, not counting the input, all\nof which contain trainable parameters (weights). The input\nis a 32 32 pixel image. This is signiﬁcantly larger than\nthe largest character in the database (at most 20 20 pixels\ncentered in a 28 28 ﬁeld). The reason is that it is desirable\nthat potential distinctive features such as stroke endpoints\nor corner can appear in the center of the receptive ﬁeld\nof the highest level feature detectors. In LeNet-5, the set\nof centers of the receptive ﬁelds of the last convolutional\nlayer (C3, see below) form a 20 20 area in the center of the\n32 32 input. The values of the input pixels are normalized\nso that the background level (white) corresponds to a value\nof\nand the foreground (black) corresponds to 1.175.\nThis makes the mean input roughly zero and the variance\nroughly one, which accelerates learning [46].\nIn the following, convolutional layers are labeled Cx,\nsubsampling layers are labeled Sx, and fully connected\nlayers are labeled Fx, where x is the layer index.\nLayer C1 is a convolutional layer with six feature maps.\nEach unit in each feature map is connected to a 5 5 neigh-\nborhood in the input. The size of the feature maps is 28 28\nwhich prevents connection from the input from falling off\nthe boundary. C1 contains 156 trainable parameters and\n122 304 connections.\nLayer S2 is a subsampling layer with six feature maps of\nsize 14 14. Each unit in each feature map is connected to a\n2 2 neighborhood in the corresponding feature map in C1.\nThe four inputs to a unit in S2 are added, then multiplied by\n2284\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nTable 1\nEach Column Indicates Which Feature Map in S2 Are\nCombined by the Units in a Particular Feature Map of C3\na trainable coefﬁcient, and then added to a trainable bias.\nThe result is passed through a sigmoidal function. The 2 2\nreceptive ﬁelds are nonoverlapping, therefore feature maps\nin S2 have half the number of rows and column as feature\nmaps in C1. Layer S2 has 12 trainable parameters and 5880\nconnections.\nLayer C3 is a convolutional layer with 16 feature maps.\nEach unit in each feature map is connected to several\n5 5 neighborhoods at identical locations in a subset of\nS2’s feature maps. Table 1 shows the set of S2 feature\nmaps combined by each C3 feature map. Why not connect\nevery S2 feature map to every C3 feature map? The\nreason is twofold. First, a noncomplete connection scheme\nkeeps the number of connections within reasonable bounds.\nMore importantly, it forces a break of symmetry in the\nnetwork. Different feature maps are forced to extract dif-\nferent (hopefully complementary) features because they get\ndifferent sets of inputs. The rationale behind the connection\nscheme in Table 1 is the following. The ﬁrst six C3 feature\nmaps take inputs from every contiguous subsets of three\nfeature maps in S2. The next six take input from every\ncontiguous subset of four. The next three take input from\nsome discontinuous subsets of four. Finally, the last one\ntakes input from all S2 feature maps. Layer C3 has 1516\ntrainable parameters and 156 000 connections.\nLayer S4 is a subsampling layer with 16 feature maps of\nsize 5 5. Each unit in each feature map is connected to a\n2 2 neighborhood in the corresponding feature map in C3,\nin a similar way as C1 and S2. Layer S4 has 32 trainable\nparameters and 2000 connections.\nLayer C5 is a convolutional layer with 120 feature maps.\nEach unit is connected to a 5 5 neighborhood on all 16\nof S4’s feature maps. Here, because the size of S4 is also\n5 5, the size of C5’s feature maps is 1 1; this amounts\nto a full connection between S4 and C5. C5 is labeled as\na convolutional layer, instead of a fully connected layer,\nbecause if LeNet-5 input were made bigger with everything\nelse kept constant, the feature map dimension would be\nlarger than 1 1. This process of dynamically increasing the\nsize of a convolutional network is described in Section VII.\nLayer C5 has 48 120 trainable connections.\nLayer F6 contains 84 units (the reason for this number\ncomes from the design of the output layer, explained\nbelow) and is fully connected to C5. It has 10 164 trainable\nparameters.\nAs in classical NN’s, units in layers up to F6 compute a\ndot product between their input vector and their weight\nvector, to which a bias is added. This weighted sum,\ndenoted\nfor unit\nis then passed through a sigmoid\nsquashing function to produce the state of unit\ndenoted\nby\n(5)\nThe squashing function is a scaled hyperbolic tangent\n(6)\nwhere\nis the amplitude of the function and\ndetermines\nits slope at the origin. The function\nis odd, with horizontal\nasymptotes at\nand\nThe constant\nis chosen to be\n1.7159. The rationale for this choice of a squashing function\nis given in Appendix A.\nFinally, the output layer is composed of Euclidean RBF\nunits, one for each class, with 84 inputs each. The outputs\nof each RBF unit\nis computed as follows:\n(7)\nIn other words, each output RBF unit computes the Eu-\nclidean distance between its input vector and its parameter\nvector. The further away the input is from the parameter\nvector, the larger the RBF output. The output of a particular\nRBF can be interpreted as a penalty term measuring the\nﬁt between the input pattern and a model of the class\nassociated with the RBF. In probabilistic terms, the RBF\noutput can be interpreted as the unnormalized negative\nlog-likelihood of a Gaussian distribution in the space of\nconﬁgurations of layer F6. Given an input pattern, the loss\nfunction should be designed so as to get the conﬁguration\nof F6 as close as possible to the parameter vector of the\nRBF that corresponds to the pattern’s desired class. The\nparameter vectors of these units were chosen by hand and\nkept ﬁxed (at least initially). The components of those\nparameters vectors were set to\n1 or\n1. While they could\nhave been chosen at random with equal probabilities for\n1 and\n1, or even chosen to form an error correcting\ncode as suggested by [47], they were instead designed to\nrepresent a stylized image of the corresponding character\nclass drawn on a 7 12 bitmap (hence the number 84). Such\na representation is not particularly useful for recognizing\nisolated digits, but it is quite useful for recognizing strings\nof characters taken from the fully printable ASCII set. The\nrationale is that characters that are similar, and therefore\nconfusable, such as uppercase “O,” lowercase “o,” and zero,\nlowercase “l” digit one, and square brackets and uppercase\n“I,” will have similar output codes. This is particularly\nuseful if the system is combined with a linguistic post-\nprocessor that can correct such confusions. Because the\ncodes for confusable classes are similar, the output of the\ncorresponding RBF’s for an ambiguous character will be\nsimilar, and the postprocessor will be able to pick the\nappropriate interpretation. Fig. 3 gives the output codes for\nthe full ASCII set.\nAnother reason for using such distributed codes, rather\nthan the more common “1 of N” code (also called place\ncode or grandmother cell code) for the outputs is that\nnondistributed codes tend to behave badly when the number\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2285\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 3.\nInitial parameters of the output RBF’s for recognizing the full ASCII set.\nof classes is larger than a few dozen. The reason is\nthat output units in a nondistributed code must be off\nmost of the time. This is quite difﬁcult to achieve with\nsigmoid units. Yet another reason is that the classiﬁers are\noften used not only to recognize characters, but also to\nreject noncharacters. RBF’s with distributed codes are more\nappropriate for that purpose because unlike sigmoids, they\nare activated within a well-circumscribed region of their\ninput space, outside of which nontypical patterns are more\nlikely to fall.\nThe parameter vectors of the RBF’s play the role of\ntarget vectors for layer F6. It is worth pointing out that\nthe components of those vectors are\n1 or\n1, which is\nwell within the range of the sigmoid of F6, and therefore\nprevents those sigmoids from getting saturated. In fact,\n1 and\n1 are the points of maximum curvature of the\nsigmoids. This forces the F6 units to operate in their\nmaximally nonlinear range. Saturation of the sigmoids must\nbe avoided because it is known to lead to slow convergence\nand ill-conditioning of the loss function.\nC. Loss Function\nThe simplest output loss function that can be used with\nthe above network is the maximum likelihood estimation\ncriterion, which in our case is equivalent to the minimum\nmean squared error (MSE). The criterion for a set of\ntraining samples is simply\n(8)\nwhere\nis the output of the\nth RBF unit, i.e., the\none that corresponds to the correct class of input pattern\nWhile this cost function is appropriate for most cases,\nit lacks three important properties. First, if we allow the\nparameters of the RBF to adapt,\nhas a trivial, but\ntotally unacceptable, solution. In this solution, all the RBF\nparameter vectors are equal and the state of F6 is constant\nand equal to that parameter vector. In this case the network\nhappily ignores the input, and all the RBF outputs are equal\nto zero. This collapsing phenomenon does not occur if the\nRBF weights are not allowed to adapt. The second problem\nis that there is no competition between the classes. Such a\ncompetition can be obtained by using a more discriminative\ntraining criterion, dubbed the maximum a posteriori (MAP)\ncriterion, similar to maximum mutual information criterion\nsometimes used to train HMM’s [48]–[50]. It corresponds\nto maximizing the posterior probability of the correct class\n(or minimizing the logarithm of the probability of the\ncorrect class), given that the input image can come from\none of the classes or from a background “rubbish” class\nlabel. In terms of penalties, it means that in addition to\npushing down the penalty of the correct class like the MSE\ncriterion, this criterion also pulls up the penalties of the\nincorrect classes\n(9)\nThe negative of the second term plays a “competitive”\nrole. It is necessarily smaller than (or equal to) the ﬁrst\nterm, therefore this loss function is positive. The constant\nis positive and prevents the penalties of classes that\nare already very large from being pushed further up. The\nposterior probability of this rubbish class label would be the\nratio of\nand\nThis discriminative\ncriterion prevents the previously mentioned “collapsing\neffect” when the RBF parameters are learned because it\nkeeps the RBF centers apart from each other. In Section VI,\nwe present a generalization of this criterion for systems\nthat learn to classify multiple objects in the input (e.g.,\ncharacters in words or in documents).\nComputing the gradient of the loss function with respect\nto all the weights in all the layers of the convolutional\nnetwork is done with back propagation. The standard al-\ngorithm must be slightly modiﬁed to take account of the\n2286\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nweight sharing. An easy way to implement it is to ﬁrst\ncompute the partial derivatives of the loss function with\nrespect to each connection, as if the network were a\nconventional multilayer network without weight sharing.\nThen the partial derivatives of all the connections that share\na same parameter are added to form the derivative with\nrespect to that parameter.\nSuch a large architecture can be trained very efﬁciently,\nbut doing so requires the use of a few techniques that are\ndescribed in the appendixes. Appendix A describes details\nsuch as the particular sigmoid used and the weight ini-\ntialization. Appendixes B and C describe the minimization\nprocedure used, which is a stochastic version of a diagonal\napproximation to the Levenberg–Marquardt procedure.\nIII.\nRESULTS AND COMPARISON WITH OTHER METHODS\nWhile recognizing individual digits is only one of many\nproblems involved in designing a practical recognition\nsystem, it is an excellent benchmark for comparing shape\nrecognition methods. Though many existing methods com-\nbine a hand-crafted feature extractor and a trainable clas-\nsiﬁer, this study concentrates on adaptive methods that\noperate directly on size-normalized images.\nA. Database: The Modiﬁed NIST Set\nThe database used to train and test the systems described\nin this paper was constructed from the NIST’s Special\nDatabase 3 and Special Database 1 containing binary im-\nages of handwritten digits. NIST originally designated SD-3\nas their training set and SD-1 as their test set. However,\nSD-3 is much cleaner and easier to recognize than SD-1.\nThe reason for this can be found on the fact that SD-\n3 was collected among Census Bureau employees, while\nSD-1 was collected among high-school students. Drawing\nsensible conclusions from learning experiments requires\nthat the result be independent of the choice of training set\nand test among the complete set of samples. Therefore it\nwas necessary to build a new database by mixing NIST’s\ndatasets.\nSD-1 contains 58 527 digit images written by 500 dif-\nferent writers. In contrast to SD-3, where blocks of data\nfrom each writer appeared in sequence, the data in SD-1 is\nscrambled. Writer identities for SD-1 are available and we\nused this information to unscramble the writers. We then\nsplit SD-1 in two: characters written by the ﬁrst 250 writers\nwent into our new training set. The remaining 250 writers\nwere placed in our test set. Thus we had two sets with nearly\n30 000 examples each. The new training set was completed\nwith enough examples from SD-3, starting at pattern #0, to\nmake a full set of 60 000 training patterns. Similarly, the\nnew test set was completed with SD-3 examples starting at\npattern #35 000 to make a full set with 60 000 test patterns.\nIn the experiments described here, we only used a subset of\n10 000 test images (5,000 from SD-1 and 5,000 from SD-3),\nbut we used the full 60 000 training samples. The resulting\ndatabase was called the modiﬁed NIST, or MNIST, dataset.\nFig. 4.\nSize-normalized examples from the MNIST database.\nThe original black and white (bilevel) images were size\nnormalized to ﬁt in a 20 20 pixel box while preserving\ntheir aspect ratio. The resulting images contain grey levels\nas result of the antialiasing (image interpolation) technique\nused by the normalization algorithm. Three versions of the\ndatabase were used. In the ﬁrst version, the images were\ncentered in a 28 28 image by computing the center of mass\nof the pixels and translating the image so as to position this\npoint at the center of the 28 28 ﬁeld. In some instances,\nthis 28 28 ﬁeld was extended to 32 32 with background\npixels. This version of the database will be referred to as\nthe regular database. In the second version of the database,\nthe character images were deslanted and cropped down to\n20 20 pixels images. The deslanting computes the second\nmoments of inertia of the pixels (counting a foreground\npixel as one and a background pixel as zero) and shears the\nimage by horizontally shifting the lines so that the principal\naxis is vertical. This version of the database will be referred\nto as the deslanted database. In the third version of the\ndatabase, used in some early experiments, the images were\nreduced to 16 16 pixels.1 Fig. 4 shows examples randomly\npicked from the test set.\nB. Results\nSeveral versions of LeNet-5 were trained on the regu-\nlar MNIST database. Twenty iterations through the entire\ntraining data were performed for each session. The values\nof the global learning rate\n[see (21) in Appendix C for\na deﬁnition] was decreased using the following schedule:\n0.0005 for the ﬁrst two passes; 0.0002 for the next three;\n0.0001 for the next three; 0.000 05 for the next 4; and\n0.000 01 thereafter. Before each iteration, the diagonal\n1The regular database (60 000 training examples, 10 000 test examples\nsize-normalized to 20\u000220 and centered by center of mass in 28\u000228 ﬁelds)\nis available WWW: http://www.research.att.com/˜yann/ocr/mnist.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2287\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 5.\nTraining and test error of LeNet-5 as a function of the\nnumber of passes through the 60 000 pattern training set (without\ndistortions). The average training error is measured on-the-ﬂy as\ntraining proceeds. This explains why the training error appears to\nbe larger than the test error initially. Convergence is attained after\n10–12 passes through the training set.\nHessian approximation was reevaluated on 500 samples,\nas described in Appendix C, and was kept ﬁxed during\nthe entire iteration. The parameter\nwas set to 0.02.\nThe resulting effective learning rates during the ﬁrst pass\nvaried between approximately 7 10\nand 0.016 over\nthe set of parameters. The test error rate stabilizes after\naround ten passes through the training set at 0.95%. The\nerror rate on the training set reaches 0.35% after 19\npasses. Many authors have reported observing the common\nphenomenon of overtraining when training NN’s or other\nadaptive algorithms on various tasks. When overtraining\noccurs, the training error keeps decreasing over time but\nthe test error goes through a minimum and starts increasing\nafter a certain number of iterations. While this phenomenon\nis very common, it was not observed in our case as the\nlearning curves in Fig. 5 show. A possible reason is that\nthe learning rate was kept relatively large. The effect of\nthis is that the weights never settle down in the local\nminimum but keep oscillating randomly. Because of those\nﬂuctuations, the average cost will be lower in a broader\nminimum. Therefore, stochastic gradient will have a similar\neffect as a regularization term that favors broader minima.\nBroader minima correspond to solutions with large entropy\nof the parameter distribution, which is beneﬁcial to the\ngeneralization error.\nThe inﬂuence of the training set size was measured\nby training the network with 15 000, 30 000, and 60 000\nexamples. The resulting training error and test error are\nshown in Fig. 6. It is clear that, even with specialized\narchitectures such as LeNet-5, more training data would\nimprove the accuracy.\nTo verify this hypothesis, we artiﬁcially generated more\ntraining examples by randomly distorting the original train-\ning images. The increased training set was composed of\nthe 60 000 original patterns plus 540 000 instances of dis-\ntorted patterns with randomly picked distortion parameters.\nThe distortions were combinations of the following planar\nafﬁne transformations: horizontal and vertical translations;\nscaling; squeezing (simultaneous horizontal compression\nand vertical elongation, or the reverse); and horizontal\nshearing. Fig. 7 shows examples of distorted patterns used\nfor training. When distorted data were used for training,\nthe test error rate dropped to 0.8% (from 0.95% without\ndeformation). The same training parameters were used\nas without deformations. The total length of the training\nsession was left unchanged (20 passes of 60 000 patterns\neach). It is interesting to note that the network effectively\nsees each individual sample only twice over the course of\nthese 20 passes.\nFig. 8 shows all 82 misclassiﬁed test examples. some\nof those examples are genuinely ambiguous, but several\nare perfectly identiﬁable by humans, although they are\nwritten in an under-represented style. This shows that\nfurther improvements are to be expected with more training\ndata.\nC. Comparison with Other Classiﬁers\nFor the sake of comparison, a variety of other trainable\nclassiﬁers was trained and tested on the same database. An\nearly subset of these results was presented in [51]. The error\nrates on the test set for the various methods are shown in\nFig. 9.\n1) Linear\nClassiﬁer\nand\nPairwise\nLinear\nClassiﬁer:\nPossibly the simplest classiﬁer that one might consider\nis a linear classiﬁer. Each input pixel value contributes to a\nweighted sum for each output unit. The output unit with the\nhighest sum (including the contribution of a bias constant)\nindicates the class of the input character. On the regular\ndata, the error rate is 12%. The network has 7850 free\nparameters. On the deslanted images, the test error rate is\n8.4%. The network has 4010 free parameters. The deﬁcien-\ncies of the linear classiﬁer are well documented [1], and it is\nincluded here simply to form a basis of comparison for more\nsophisticated classiﬁers. Various combinations of sigmoid\nunits, linear units, gradient descent learning, and learning\nby directly solving linear systems gave similar results.\nA simple improvement of the basic linear classiﬁer was\ntested [52]. The idea is to train each unit of a single-\nlayer network to separate each class from each other\nclass. In our case this layer comprises 45 units labeled\nUnit\nis trained to pro-\nduce\n1 on patterns of class\n1 on patterns of class\n,\nand it is not trained on other patterns. The ﬁnal score for\nclass\nis the sum of the outputs all the units labeled\nminus the sum of the output of all the units labeled\nfor\nall\nand\nThe error rate on the regular test set was 7.6%.\n2) Baseline Nearest Neighbor Classiﬁer: Another simple\nclassiﬁer is a K-NN classiﬁer with a Euclidean distance\nmeasure between input images. This classiﬁer has the\nadvantage that no training time, and no thought on the\npart of the designer, are required. However the memory\nrequirement and recognition time are large: the complete\n60 000 20\n20 pixel training images (about 24 megabytes\nat one byte per pixel) must be available at run time. Much\n2288\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 6.\nTraining and test errors of LeNet-5 achieved using training sets of various sizes. This graph\nsuggests that a larger training set could improve the performance of LeNet-5. The hollow square\nshows the test error when more training patterns are artiﬁcially generated using random distortions.\nThe test patterns are not distorted.\nFig. 7.\nExamples of distortions of ten training patterns.\nmore compact representations could be devised with modest\nincrease in error rate. On the regular test set the error\nrate was 5.0%. On the deslanted data, the error rate was\n2.4%, with\nNaturally, a realistic Euclidean distance\nnearest-neighbor system would operate on feature vectors\nFig. 8.\nThe 82 test patterns misclassiﬁed by LeNet-5. Below\neach image is displayed the correct answers (left) and the net-\nwork answer (right). These errors are mostly caused either by\ngenuinely ambiguous patterns, or by digits written in a style that\nare under-represented in the training set.\nrather than directly on the pixels, but since all of the other\nsystems presented in this study operate directly on the\npixels, this result is useful for a baseline comparison.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2289\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 9.\nError rate on the test set (%) for various classiﬁcation methods. [deslant] indicates that the\nclassiﬁer was trained and tested on the deslanted version of the database. [dist] indicates that the\ntraining set was augmented with artiﬁcially distorted examples. [16\u000216] indicates that the system\nused the 16\u000216 pixel images. The uncertainty in the quoted error rates is about 0.1%.\n3) PCA and Polynomial Classiﬁer: Following [53] and\n[54], a preprocessing stage was constructed which computes\nthe projection of the input pattern on the 40 principal\ncomponents of the set of training vectors. To compute the\nprincipal components, the mean of each input component\nwas ﬁrst computed and subtracted from the training\nvectors. The covariance matrix of the resulting vectors\nwas then computed and diagonalized using singular value\ndecomposition. The 40-dimensional feature vector was used\nas the input of a second degree polynomial classiﬁer. This\nclassiﬁer can be seen as a linear classiﬁer with 821 inputs,\npreceded by a module that computes all products of pairs of\ninput variables. The error on the regular test set was 3.3%.\n4) RBF Network: Following [55], an RBF network was\nconstructed. The ﬁrst layer was composed of 1000 Gaussian\nRBF units with 28 28 inputs, and the second layer was a\nsimple 1000 inputs/ten outputs linear classiﬁer. The RBF\nunits were divided into ten groups of 100. Each group of\nunits was trained on all the training examples of one of\nthe ten classes using the adaptive K-means algorithm. The\nsecond-layer weights were computed using a regularized\npseudoinverse method. The error rate on the regular test\nset was 3.6%.\n5) One-Hidden-Layer Fully Connected Multilayer NN:\nAnother classiﬁer that we tested was a fully connected\nmultilayer NN with two layers of weights (one hidden layer)\ntrained with the version of back-propagation described in\nAppendix C. Error on the regular test set was 4.7% for a\nnetwork with 300 hidden units and 4.5% for a network with\n1000 hidden units. Using artiﬁcial distortions to generate\nmore training data brought only marginal improvement:\n3.6% for 300 hidden units and 3.8% for 1000 hidden units.\nWhen deslanted images were used, the test error jumped\ndown to 1.6% for a network with 300 hidden units.\nIt remains somewhat of a mystery that networks with\nsuch a large number of free parameters manage to achieve\nreasonably low testing errors. We conjecture that the dy-\nnamics of gradient descent learning in multilayer nets\nhas a “self-regularization” effect. Because the origin of\nweight space is a saddle point that is attractive in al-\nmost every direction, the weights invariably shrink during\nthe ﬁrst few epochs (recent theoretical analysis seem to\nconﬁrm this [56]). Small weights cause the sigmoids to\noperate in the quasi-linear region, making the network\nessentially equivalent to a low-capacity, single-layer net-\nwork. As the learning proceeds the weights grow, which\n2290\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nprogressively increases the effective capacity of the net-\nwork. This seems to be an almost perfect, if fortuitous,\nimplementation of Vapnik’s “structural risk minimization”\nprinciple [6]. A better theoretical understanding of these\nphenomena, and more empirical evidence, are deﬁnitely\nneeded.\n6) Two-Hidden-Layer Fully Connected Multilayer NN: To\nsee the effect of the architecture, several two-hidden-layer\nmultilayer NN’s were trained. Theoretical results have\nshown that any function can be approximated by a one-\nhidden-layer NN [57]. However, several authors have ob-\nserved that two-hidden-layer architectures sometimes yield\nbetter performance in practical situations. This phenomenon\nwas also observed here. The test error rate of a 28 28-\n300-100-10 network was 3.05%, a much better result than\nthe one-hidden-layer network, obtained using marginally\nmore weights and connections. Increasing the network size\nto 28 28-1000-150-10 yielded only marginally improved\nerror rates: 2.95%. Training with distorted patterns im-\nproved the performance somewhat: 2.50% error for the\n28 28-300-100-10 network, and 2.45% for the 28 28-\n1000-150-10 network.\n7) A Small Convolutional Network—LeNet-1: Convolu-\ntional networks are an attempt to solve the dilemma\nbetween small networks that cannot learn the training\nset and large networks that seem overparameterized.\nLeNet-1 was an early embodiment of the convolutional\nnetwork architecture which is included here for comparison\npurposes. The images were down-sampled to 16 16\npixels and centered in the 28 28 input layer. Although\nabout 100 000 multiply/add steps are required to evaluate\nLeNet-1, its convolutional nature keeps the number of free\nparameters to only about 2600. The LeNet-1 architecture\nwas developed using our own version of the USPS (U.S.\nPostal Service zip codes) database and its size was tuned to\nmatch the available data [35]. LeNet-1 achieved 1.7% test\nerror. The fact that a network with such a small number of\nparameters can attain such a good error rate is an indication\nthat the architecture is appropriate for the task.\n8) LeNet-4: Experiments with LeNet-1 made it clear that\na larger convolutional network was needed to make optimal\nuse of the large size of the training set. LeNet-4 and later\nLeNet-5 were designed to address this problem. LeNet-\n4 is very similar to LeNet-5, except for the details of\nthe architecture. It contains four ﬁrst-level feature maps,\nfollowed by eight subsampling maps connected in pairs\nto each ﬁrst-layer feature maps, then 16 feature maps,\nfollowed by 16 subsampling maps, followed by a fully\nconnected layer with 120 units, followed by the output layer\n(ten units). LeNet-4 contains about 260 000 connections and\nhas about 17 000 free parameters. Test error was 1.1%. In a\nseries of experiments, we replaced the last layer of LeNet-\n4 with a Euclidean nearest-neighbor classiﬁer, and with\nthe “local learning” method of Bottou and Vapnik [58], in\nwhich a local linear classiﬁer is retrained each time a new\ntest pattern is shown. Neither of those methods improved\nthe raw error rate, although they did improve the rejection\nperformance.\n9) Boosted LeNet-4: Following\ntheoretical\nwork\nby\nSchapire [59], Drucker et al. [60] developed the “boosting”\nmethod for combining multiple classiﬁers. Three LeNet-4’s\nare combined: the ﬁrst one is trained the usual way; the\nsecond one is trained on patterns that are ﬁltered by the\nﬁrst net so that the second machine sees a mix of patterns,\n50% of which the ﬁrst net got right and 50% of which\nit got wrong; the third net is trained on new patterns on\nwhich the ﬁrst and the second nets disagree. During testing,\nthe outputs of the three nets are simply added. Because the\nerror rate of LeNet-4 is very low, it was necessary to\nuse the artiﬁcially distorted images (as with LeNet-5) in\norder to get enough samples to train the second and third\nnets. The test error rate was 0.7%, the best of any of our\nclassiﬁers. At ﬁrst glance, boosting appears to be three\ntimes more expensive as a single net. In fact, when the ﬁrst\nnet produces a high conﬁdence answer, the other nets are\nnot called. The average computational cost is about 1.75\ntimes that of a single net.\n10) Tangent Distance Classiﬁer: The\ntangent\ndistance\nclassiﬁer is a nearest-neighbor method where the distance\nfunction is made insensitive to small distortions and\ntranslations of the input image [61]. If we consider an\nimage as a point in a high-dimensional pixel space (where\nthe dimensionality equals the number of pixels), then an\nevolving distortion of a character traces out a curve in pixel\nspace. Taken together, all these distortions deﬁne a low-\ndimensional manifold in pixel space. For small distortions\nin the vicinity of the original image, this manifold can be\napproximated by a plane, known as the tangent plane. An\nexcellent measure of “closeness” for character images is\nthe distance between their tangent planes, where the set of\ndistortions used to generate the planes includes translations,\nscaling, skewing, squeezing, rotation, and line thickness\nvariations. A test error rate of 1.1% was achieved using\n16 16 pixel images. Preﬁltering techniques using simple\nEuclidean distance at multiple resolutions allowed to reduce\nthe number of necessary tangent distance calculations.\n11) SVM: Polynomial classiﬁers are well studied meth-\nods for generating complex decision surfaces. Unfortu-\nnately, they are impractical for high-dimensional problems\nbecause the number of product terms is prohibitive. The\nsupport vector technique is an extremely economical way of\nrepresenting complex surfaces in high-dimensional spaces,\nincluding polynomials and many other types of surfaces [6].\nA particularly interesting subset of decision surfaces\nis the ones that correspond to hyperplanes that are at a\nmaximum distance from the convex hulls of the two classes\nin the high-dimensional space of the product terms. Boser\net al. [62] realized that any polynomial of degree\nin this\n“maximum margin” set can be computed by ﬁrst computing\nthe dot product of the input image with a subset of the train-\ning samples (called the “support vectors”), elevating the\nresult to the\nth power, and linearly combining the numbers\nthereby obtained. Finding the support vectors and the coef-\nﬁcients amounts to solving a high-dimensional quadratic\nminimization problem with linear inequality constraints.\nFor the sake of comparison, we include here the results\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2291\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 10.\nRejection Performance: percentage of test patterns that must be rejected to achieve 0.5%\nerror for some of the systems.\nFig. 11.\nNumber of multiply–accumulate operations for the recognition of a single character\nstarting with a size-normalized image.\nobtained by Burges and Sch¨olkopf and reported in [63].\nWith a regular SVM, their error rate on the regular test set\nwas 1.4%. Cortes and Vapnik had reported an error rate of\n1.1% with SVM on the same data using a slightly different\ntechnique. The computational cost of this technique is very\nhigh: about 14 million multiply-adds per recognition. Using\nSch¨olkopf’s V-SVM technique, 1.0% error was attained.\nMore recently, Sch¨olkopf (personal communication) has\nreached 0.8% using a modiﬁed version of the V-SVM.\nUnfortunately, V-SVM is extremely expensive: about twice\nas much as regular SVM. To alleviate this problem, Burges\nhas proposed the RS-SVM technique, which attained 1.1%\non the regular test set [63], with a computational cost of\nonly 650 000 multiply–adds per recognition, i.e., only about\n60% more expensive than LeNet-5.\nD. Discussion\nA summary of the performance of the classiﬁers is\nshown in Figs. 9–12. Fig. 9 shows the raw error rate of the\nclassiﬁers on the 10 000 example test set. Boosted LeNet-4\nperformed best, achieving a score of 0.7%, closely followed\nby LeNet-5 at 0.8%.\nFig. 10 shows the number of patterns in the test set\nthat must be rejected to attain a 0.5% error for some of\n2292\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 12.\nMemory requirements, measured in number of variables, for each of the methods. Most\nof the methods only require one byte per variable for adequate performance.\nthe methods. Patterns are rejected when the value of the\ncorresponding output is smaller than a predeﬁned thresh-\nold. In many applications, rejection performance is more\nsigniﬁcant than raw error rate. The score used to decide\nupon the rejection of a pattern was the difference between\nthe scores of the top two classes. Again, Boosted LeNet-4\nhas the best performance. The enhanced versions of LeNet-\n4 did better than the original LeNet-4, even though the raw\naccuracies were identical.\nFig. 11 shows the number of multiply–accumulate op-\nerations necessary for the recognition of a single size-\nnormalized image for each method. Expectedly, NN’s are\nmuch less demanding than memory-based methods. Con-\nvolutional NN’s are particularly well suited to hardware\nimplementations because of their regular structure and\ntheir low memory requirements for the weights. Single\nchip mixed analog–digital implementations of LeNet-5’s\npredecessors have been shown to operate at speeds in\nexcess of 1000 characters per second [64]. However, the\nrapid progress of mainstream computer technology renders\nthose exotic technologies quickly obsolete. Cost-effective\nimplementations of memory-based techniques are more\nelusive due to their enormous memory requirements and\ncomputational requirements.\nTraining time was also measured. K-NN’s and tangent\ndistance classiﬁer have essentially zero training time. While\nthe single-layer net, the pairwise net, and PCA quadratic\nnet could be trained in less than an hour, the multilayer net\ntraining times were expectedly much longer, but only re-\nquired 10–20 passes through the training set. This amounts\nto two–three days of CPU to train LeNet-5 on a Silicon\nGraphics Origin 2000 server using a single 200 MHz\nR10000 processor. It is important to note that while the\ntraining time is somewhat relevant to the designer, it is\nof little interest to the ﬁnal user of the system. Given the\nchoice between an existing technique and a new technique\nthat brings marginal accuracy improvements at the price of\nconsiderable training time, any ﬁnal user would choose the\nlatter.\nFig. 12 shows the memory requirements, and therefore\nthe number of free parameters, of the various classiﬁers\nmeasured in terms of the number of variables that need\nto be stored. Most methods require only about 1 byte\nper variable for adequate performance. However, nearest-\nneighbor methods may get by with 4 bits per pixel for\nstoring the template images. Not surprisingly, NN’s require\nmuch less memory than memory-based methods.\nThe overall performance depends on many factors includ-\ning accuracy, running time, and memory requirements. As\ncomputer technology improves, larger capacity recognizers\nbecome feasible. Larger recognizers in turn require larger\ntraining sets. LeNet-1 was appropriate to the available\ntechnology in 1989, just as LeNet-5 is appropriate now.\nIn 1989 a recognizer as complex as LeNet-5 would have\nrequired several weeks’ training and more data than were\navailable and was therefore not even considered. For quite a\nlong time, LeNet-1 was considered the state of the art. The\nlocal learning classiﬁer, the optimal margin classiﬁer, and\nthe tangent distance classiﬁer were developed to improve\nupon LeNet-1—and they succeeded at that. However, they\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2293\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nin turn motivated a search for improved NN architectures.\nThis search was guided in part by estimates of the capacity\nof various learning machines, derived from measurements\nof the training and test error as a function of the number\nof training examples. We discovered that more capacity\nwas needed. Through a series of experiments in architec-\nture, combined with an analysis of the characteristics of\nrecognition errors, LeNet-4 and LeNet-5 were crafted.\nWe ﬁnd that boosting gives a substantial improvement in\naccuracy, with a relatively modest penalty in memory and\ncomputing expense. Also, distortion models can be used\nto increase the effective size of a data set without actually\nrequiring to collect more data.\nThe SVM has excellent accuracy, which is most remark-\nable because, unlike the other high performance classiﬁers,\nit does not include a priori knowledge about the problem.\nIn fact, this classiﬁer would do just as well if the image\npixels were permuted with a ﬁxed mapping and lost their\npictorial structure. However, reaching levels of performance\ncomparable to the convolutional NN’s can only be done\nat considerable expense in memory and computational re-\nquirements. The RS-SVM requirements are within a factor\nof two of the convolutional networks, and the error rate is\nvery close. Improvements of those results are expected as\nthe technique is relatively new.\nWhen plenty of data are available, many methods can\nattain respectable accuracy. The neural-net methods run\nmuch faster and require much less space than memory-\nbased techniques. The NN’s advantage will become more\nstriking as training databases continue to increase in size.\nE. Invariance and Noise Resistance\nConvolutional networks are particularly well suited for\nrecognizing or rejecting shapes with widely varying size,\nposition, and orientation, such as the ones typically pro-\nduced by heuristic segmenters in real-world string recog-\nnition systems.\nIn an experiment like the one described above, the\nimportance of noise resistance and distortion invariance is\nnot obvious. The situation in most real applications is quite\ndifferent. Characters generally must be segmented out of\ntheir context prior to recognition. Segmentation algorithms\nare rarely perfect and often leave extraneous marks in char-\nacter images (noise, underlines, neighboring characters), or\nsometimes cut characters too much and produce incomplete\ncharacters. Those images cannot be reliably size-normalized\nand centered. Normalizing incomplete characters can be\nvery dangerous. For example, an enlarged stray mark can\nlook like a genuine “1.” Therefore, many systems have\nresorted to normalizing the images at the level of ﬁelds or\nwords. In our case, the upper and lower proﬁles of entire\nﬁelds (i.e., amounts in a check) are detected and used to\nnormalize the image to a ﬁxed height. While this guarantees\nthat stray marks will not be blown up into character-\nlooking images, this also creates wide variations of the\nsize and vertical position of characters after segmentation.\nTherefore it is preferable to use a recognizer that is robust\nto such variations. Fig. 13 shows several examples of\ndistorted characters that are correctly recognized by LeNet-\n5. It is estimated that accurate recognition occurs for\nscale variations up to about a factor of two, vertical shift\nvariations of plus or minus about half the height of the\ncharacter, and rotations up to plus or minus 30 degrees.\nWhile fully invariant recognition of complex shapes is still\nan elusive goal, it seems that convolutional networks offer\na partial answer to the problem of invariance or robustness\nwith respect to geometrical distortions.\nFig. 13 includes examples of the robustness of LeNet-5\nunder extremely noisy conditions. Processing those images\nwould pose insurmountable problems of segmentation and\nfeature extraction to many methods, but LeNet-5 seems\nable to robustly extract salient features from these cluttered\nimages. The training set used for the network shown here\nwas the MNIST training set with salt and pepper noise\nadded. Each pixel was randomly inverted with probability\n0.1.2\nIV.\nMULTIMODULE SYSTEMS AND GRAPH\nTRANSFORMER NETWORKS\nThe classical back-propagation algorithm, as described\nand used in the previous sections, is a simple form of\ngradient-based learning. However, it is clear that the gra-\ndient back-propagation algorithm given by (4) describes a\nmore general situation than simple multilayer feedforward\nnetworks composed of alternated linear transformations and\nsigmoidal functions. In principle, derivatives can be back-\npropagated through any arrangement of functional modules,\nas long as we can compute the product of the Jacobians of\nthose modules by any vector. Why would we want to train\nsystems composed of multiple heterogeneous modules? The\nanswer is that large and complex trainable systems need to\nbe built out of simple, specialized modules. The simplest\nexample is LeNet-5, which mixes convolutional layers,\nsubsampling layers, fully connected layers, and RBF layers.\nAnother less trivial example, described in Sections IV-A\nand IV-B, is a system for recognizing words, that can\nbe trained to simultaneously segment and recognize words\nwithout ever being given the correct segmentation.\nFig. 14 shows an example of a trainable multimodular\nsystem. A multimodule system is deﬁned by the function\nimplemented by each of the modules and by the graph of\ninterconnection of the modules to each other. The graph\nimplicitly deﬁnes a partial order according to which the\nmodules must be updated in the forward pass. For example\nin Fig. 14, module 0 is ﬁrst updated, then modules 1 and\n2 are updated (possibly in parallel), followed by module\n3. Modules may or may not have trainable parameters.\nLoss functions, which measure the performance of the\nsystem, are implemented as module 4. In the simplest case,\nthe loss function module receives an external input that\ncarries the desired output. In this framework, there is no\nqualitative difference between trainable parameters (W1,\n2More\nexamples\nof\nLeNet-5\nin\naction\nare\navailable\nWWW:\nhttp://www.research.att.com/˜yann/ocr.\n2294\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 13.\nExamples of unusual, distorted, and noisy characters correctly recognized by LeNet-5.\nThe grey level of the output label represents the penalty (lighter for higher penalties).\nFig. 14.\nA trainable system composed of heterogeneous modules.\nW2 in the ﬁgure), external inputs and outputs (Z,D,E), and\nintermediate state variables (X1, X2, X3, X4, X5).\nA. An Object-Oriented Approach\nObject-oriented programming offers a particularly con-\nvenient way of implementing multimodule systems. Each\nmodule is an instance of a class. Module classes have\na “forward propagation” method (or member function)\ncalled fprop whose arguments are the inputs and outputs\nof the module. For example, computing the output of\nmodule 3 in Fig. 14 can be done by calling the method\nfprop on module 3 with the arguments X3, X4, X5.\nComplex modules can be constructed from simpler modules\nby simply deﬁning a new class whose slots will contain\nthe member modules and the intermediate state variables\nbetween those modules. The fprop method for the class\nsimply calls the fprop methods of the member modules,\nwith the appropriate intermediate state variables or external\ninput and outputs as arguments. Although the algorithms\nare easily generalizable to any network of such modules,\nincluding those whose inﬂuence graph has cycles, we will\nlimit the discussion to the case of directed acyclic graphs\n(feed-forward networks).\nComputing derivatives in a multimodule system is just as\nsimple. A “backward propagation” method, called bprop,\nfor each module class can be deﬁned for that purpose. The\nbprop method of a module takes the same arguments as\nthe fprop method. All the derivatives in the system can be\ncomputed by calling the bprop method on all the modules\nin reverse order compared to the forward propagation\nphase. The state variables are assumed to contain slots\nfor storing the gradients computed during the backward\npass, in addition to storage for the states computed in the\nforward pass. The backward pass effectively computes the\npartial derivatives of the loss\nwith respect to all the state\nvariables and all the parameters in the system. There is\nan interesting duality property between the forward and\nbackward functions of certain modules. For example, a\nsum of several variables in the forward direction is trans-\nformed into a simple fan-out (replication) in the backward\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2295\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\ndirection. Conversely, a fan-out in the forward direction\nis transformed into a sum in the backward direction. The\nsoftware environment used to obtain the results described\nin this paper, called SN3.1, uses the above concepts. It\nis based on a home-grown object-oriented dialect of Lisp\nwith a compiler to C.\nThe fact that derivatives can be computed by propagation\nin the reverse graph is easy to understand intuitively. The\nbest way to justify it theoretically is through the use of\nLagrange functions [21], [22]. The same formalism can be\nused to extend the procedures to networks with recurrent\nconnections.\nB. Special Modules\nNN’s and many other standard pattern recognition tech-\nniques can be formulated in terms of multimodular systems\ntrained with gradient-based learning. Commonly used mod-\nules include matrix multiplications and sigmoidal modules,\nthe combination of which can be used to build conven-\ntional NN’s. Other modules include convolutional layers,\nsubsampling layers, RBF layers, and “softmax” layers [65].\nLoss functions are also represented as modules whose\nsingle output produces the value of the loss. Commonly\nused modules have simple bprop methods. In general, the\nbprop method of a function\nis a multiplication by the\nJacobian of\nHere are a few commonly used examples.\nThe bprop method of a fanout (a “Y” connection) is a\nsum, and vice versa. The bprop method of a multipli-\ncation by a coefﬁcient is a multiplication by the same\ncoefﬁcient. The bprop method of a multiplication by a\nmatrix is a multiplication by the transpose of that matrix.\nThe bprop method of an addition with a constant is the\nidentity.\nInterestingly, certain nondifferentiable modules can be\ninserted in a multimodule system without adverse effect.\nAn interesting example of that is the multiplexer module.\nIt has two (or more) regular inputs, one switching input, and\none output. The module selects one of its inputs, depending\nupon the (discrete) value of the switching input, and copies\nit on its output. While this module is not differentiable\nwith respect to the switching input, it is differentiable with\nrespect to the regular inputs. Therefore the overall function\nof a system that includes such modules will be differentiable\nwith respect to its parameters as long as the switching input\ndoes not depend upon the parameters. For example, the\nswitching input can be an external input.\nAnother interesting case is the min module. This module\nhas two (or more) inputs and one output. The output of\nthe module is the minimum of the inputs. The function\nof this module is differentiable everywhere, except on\nthe switching surface which is a set of measure zero.\nInterestingly, this function is continuous and reasonably\nregular, and that is sufﬁcient to ensure the convergence\nof a gradient-based learning algorithm.\nThe object-oriented implementation of the multimodule\nidea can easily be extended to include a bbprop method\nthat propagates Gauss–Newton approximations of the sec-\nond derivatives. This leads to a direct generalization for\nmodular systems of the second-derivative back propagation\n(22) given in Appendix C.\nThe multiplexer module is a special case of a much more\ngeneral situation, described at length in Section IX, where\nthe architecture of the system changes dynamically with the\ninput data. Multiplexer modules can be used to dynamically\nrewire (or reconﬁgure) the architecture of the system for\neach new input pattern.\nC. GTN’s\nMultimodule systems are very ﬂexible tools for build-\ning a large trainable system. However, the descriptions\nin the previous sections implicitly assumed that the set\nof parameters, and the state information communicated\nbetween the modules, are all ﬁxed-size vectors. The limited\nﬂexibility of ﬁxed-size vectors for data representation is\na serious deﬁciency for many applications, notably for\ntasks that deal with variable length inputs (e.g., continuous\nspeech recognition and handwritten word recognition) or for\ntasks that require encoding relationships between objects or\nfeatures whose number and nature can vary (invariant per-\nception, scene analysis, recognition of composite objects).\nAn important special case is the recognition of strings of\ncharacters or words.\nMore generally, ﬁxed-size vectors lack ﬂexibility for\ntasks in which the state must encode probability distribu-\ntions over sequences of vectors or symbols, as is the case in\nlinguistic processing. Such distributions over sequences are\nbest represented by stochastic grammars, or, in the more\ngeneral case, directed graphs in which each arc contains\na vector (stochastic grammars are special cases in which\nthe vector contains probabilities and symbolic information).\nEach path in the graph represents a different sequence of\nvectors. Distributions over sequences can be represented\nby interpreting elements of the data associated with each\narc as parameters of a probability distribution or simply\nas a penalty. Distributions over sequences are particularly\nhandy for modeling linguistic knowledge in speech or\nhandwriting recognition systems: each sequence, i.e., each\npath in the graph, represents an alternative interpretation\nof the input. Successive processing modules progressively\nreﬁne the interpretation. For example, a speech recognition\nsystem might start with a single sequence of acoustic\nvectors, transform it into a lattice of phonemes (distribution\nover phoneme sequences), then into a lattice of words\n(distribution over word sequences), and then into a single\nsequence of words representing the best interpretation.\nIn our work on building large-scale handwriting recog-\nnition systems, we have found that these systems could be\ndeveloped and designed much more easily and quickly by\nviewing the system as a networks of modules that take one\nor several graphs as input and produce graphs as output.\nSuch modules are called GT’s, and the complete systems\nare called GTN’s. Modules in a GTN communicate their\nstates and gradients in the form of directed graphs whose\narcs carry numerical information (scalars or vectors) [66].\nFrom the statistical point of view, the ﬁxed-size state vec-\ntors of conventional networks can be seen as representing\n2296\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\n(a)\n(b)\nFig. 15.\nTraditional NN’s and multimodule systems communi-\ncate ﬁxed-size vectors between layers. Multilayer GTN’s are\ncomposed of trainable modules that operate on and produce graphs\nwhose arcs carry numerical information.\nthe means of distributions in state space. In variable-size\nnetworks such as the space-displacement NN’s described\nin Section VII, the states are variable-length sequences\nof ﬁxed size vectors. They can be seen as representing\nthe mean of a probability distribution over variable-length\nsequences of ﬁxed-size vectors. In GTN’s the states are\nrepresented as graphs, which can be seen as represent-\ning mixtures of probability distributions over structured\ncollections (possibly sequences) of vectors (Fig. 15).\nOne of the main points of the next several sections is\nto show that gradient-based learning procedures are not\nlimited to networks of simple modules that communicate\nthrough ﬁxed-size vectors but can be generalized to\nGTN’s. Gradient back propagation through a GT takes\ngradients with respect to the numerical information in\nthe output graph and computes gradients with respect to\nthe numerical information attached to the input graphs,\nand with respect to the module’s internal parameters.\nGradient-based\nlearning\ncan\nbe\napplied\nas\nlong\nas\ndifferentiable functions are used to produce the numerical\ndata in the output graph from the numerical data in the\ninput graph and the functions parameters.\nThe second point of the next several sections is to show\nthat the functions implemented by many of the modules\nused in typical document processing systems (and other\nimage recognition systems), though commonly thought to\nbe combinatorial in nature, are indeed differentiable with\nrespect to their internal parameters as well as with respect\nto their inputs, and are therefore usable as part of a globally\ntrainable system.\nIn most of the following, we will purposely avoid making\nreferences to probability theory. All the quantities manipu-\nlated are viewed as penalties, or costs, which if necessary\ncan be transformed into probabilities by taking exponentials\nand normalizing.\nV.\nMULTIPLE OBJECT RECOGNITION: HOS\nOne of the most difﬁcult problems of handwriting recog-\nnition is to recognize not just isolated characters, but\nFig. 16.\nBuilding a segmentation graph with HOS.\nstrings of characters such as zip codes, check amounts,\nor words. Since most recognizers can only deal with one\ncharacter at a time, we must ﬁrst segment the string\ninto individual character images. However, it is almost\nimpossible to devise image analysis techniques that will\ninfallibly segment naturally written sequences of characters\ninto well formed characters.\nThe recent history of automatic speech recognition [28],\n[67] is here to remind us that training a recognizer by\noptimizing a global criterion (at the word or sentence level)\nis much preferable to merely training it on hand-segmented\nphonemes or other units. Several recent works have shown\nthat the same is true for handwriting recognition [38]:\noptimizing a word-level criterion is preferable to solely\ntraining a recognizer on presegmented characters because\nthe recognizer can learn not only to recognize individual\ncharacters, but also to reject missegmented characters,\nthereby minimizing the overall word error.\nThis section and Section VI describe in detail a simple\nexample of GTN to address the problem of reading strings\nof characters, such as words or check amounts. The method\navoids the expensive and unreliable task of hand-truthing\nthe result of the segmentation often required in more\ntraditional systems trained on individually labeled character\nimages.\nA. Segmentation Graph\nA now classical method for segmentation and recognition\nis called HOS [68], [69]. Its main advantages over other\napproaches to segmentation are that it avoids making hard\ndecisions about the segmentation by taking a large number\nof different segmentations into consideration. The idea is to\nuse heuristic image processing techniques to ﬁnd candidate\ncuts of the word or string, and then to use the recognizer to\nscore the alternative segmentations thereby generated. The\nprocess is depicted in Fig. 16. First, a number of candidate\ncuts are generated. Good candidate locations for cuts can be\nfound by locating minima in the vertical projection proﬁle,\nor minima of the distance between the upper and lower\ncontours of the word. Better segmentation heuristics are\ndescribed in Section XI. The cut generation heuristic is\ndesigned so as to generate more cuts than necessary in the\nhope that the “correct” set of cuts will be included. Once the\ncuts have been generated, alternative segmentations are best\nrepresented by a graph, called the segmentation graph. The\nsegmentation graph is a directed acyclic graph with a start\nnode and an end node. Each internal node is associated with\na candidate cut produced by the segmentation algorithm.\nEach arc between a source node and a destination node\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2297\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 17.\nRecognizing a character string with a GTN. For read-\nability, only the arcs with low penalties are shown.\nis associated with an image that contains all the ink\nbetween the cut associated with the source node and the\ncut associated with the destination node. An arc is created\nbetween two nodes if the segmentor decided that the ink\nbetween the corresponding cuts could form a candidate\ncharacter. Typically, each individual piece of ink would\nbe associated with an arc. Pairs of successive pieces of\nink would also be included, unless they are separated by a\nwide gap, which is a clear indication that they belong to\ndifferent characters. Each complete path through the graph\ncontains each piece of ink once and only once. Each path\ncorresponds to a different way of associating pieces of ink\ntogether so as to form characters.\nB. Recognition Transformer and Viterbi Transformer\nA simple GTN to recognize character strings is shown in\nFig. 17. It is composed of two GT’s called the recognition\ntransformer\nand the Viterbi transformer\nThe goal\nof the recognition transformer is to generate a graph, called\nthe interpretation graph or recognition graph\nthat\ncontains all the possible interpretations for all the possible\nsegmentations of the input. Each path in\nrepresents\none possible interpretation of one particular segmentation\nFig. 18.\nThe recognition transformer reﬁnes each arc of the\nsegmentation arc into a set of arcs in the interpretation graph, one\nper character class, with attached penalties and labels.\nof the input. The role of the Viterbi transformer is to extract\nthe best interpretation from the interpretation graph.\nThe recognition transformer\ntakes the segmentation\ngraph\nas input, and applies the recognizer for single\ncharacters to the images associated with each of the arcs in\nthe segmentation graph. The interpretation graph\nhas\nalmost the same structure as the segmentation graph, except\nthat each arc is replaced by a set of arcs from and to the\nsame node. In this set of arcs, there is one arc for each pos-\nsible class for the image associated with the corresponding\narc in\nAs shown in Fig. 18, to each arc is attached\na class label, and the penalty that the image belongs to\nthis class as produced by the recognizer. If the segmentor\nhas computed penalties for the candidate segments, these\npenalties are combined with the penalties computed by the\ncharacter recognizer to obtain the penalties on the arcs of\nthe interpretation graph. Although combining penalties of\ndifferent nature seems highly heuristic, the GTN training\nprocedure will tune the penalties and take advantage of this\ncombination anyway. Each path in the interpretation graph\ncorresponds to a possible interpretation of the input word.\nThe penalty of a particular interpretation for a particular\nsegmentation is given by the sum of the arc penalties\nalong the corresponding path in the interpretation graph.\nComputing the penalty of an interpretation independently\nof the segmentation requires to combine the penalties of\nall the paths with that interpretation. An appropriate rule\nfor combining the penalties of parallel paths is given in\nSection VI-C.\n2298\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nThe Viterbi transformer produces a graph\nwith a\nsingle path. This path is the path of least cumulated penalty\nin the Interpretation graph. The result of the recognition\ncan be produced by reading off the labels of the arcs along\nthe graph\nextracted by the Viterbi transformer. The\nViterbi transformer owes its name to the famous Viterbi\nalgorithm [70], an application of the principle of dynamic\nprogramming to ﬁnd the shortest path in a graph efﬁciently.\nLet\nbe the penalty associated to arc\nwith source\nnode\nand destination node\n(note that there can be\nmultiple arcs between two nodes). In the interpretation\ngraph, arcs also have a label\nThe Viterbi algorithm\nproceeds as follows. Each node\nis associated with a\ncumulated Viterbi penalty\nThose cumulated penalties\nare computed in any order that satisﬁes the partial order\ndeﬁned by the interpretation graph (which is directed and\nacyclic). The start node is initialized with the cumulated\npenalty\nThe other nodes cumulated penalties\nare computed recursively from the\nvalues of their\nparent nodes, through the upstream arcs\nwith\ndestination\n(10)\nFurthermore, the value of\nfor each node\nwhich min-\nimizes the right-hand side is noted\nthe minimizing\nentering arc. When the end node is reached we obtain in\nthe total penalty of the path with the smallest total\npenalty. We call this penalty the Viterbi penalty, and this\nsequence of arcs and nodes the Viterbi path. To obtain the\nViterbi path with nodes\nand arcs\nwe\ntrace back these nodes and arcs as follows, starting with\nthe end node, and recursively using the minimizing\nentering arc:\nand\nuntil the start node\nis reached. The label sequence can then be read off the arcs\nof the Viterbi path.\nVI.\nGLOBAL TRAINING FOR GRAPH\nTRANSFORMER NETWORKS\nSection V described the process of recognizing a string\nusing HOS, assuming that the recognizer is trained so\nas to give low penalties for the correct class label of\ncorrectly segmented characters, high penalties for erroneous\ncategories of correctly segmented characters, and high\npenalties for all categories for poorly formed characters.\nThis section explains how to train the system at the string\nlevel to do the above without requiring manual labeling of\ncharacter segments. This training will be performed with\na GTN whose architecture is slightly different from the\nrecognition architecture described in Section V.\nIn many applications, there is enough a priori knowledge\nabout what is expected from each of the modules in order\nto train them separately. For example, with HOS one\ncould individually label single-character images and train\na character recognizer on them, but it might be difﬁcult\nto obtain an appropriate set of noncharacter images to\ntrain the model to reject wrongly segmented candidates.\nAlthough separate training is simple, it requires additional\nsupervision information that is often lacking or incomplete\n(the correct segmentation and the labels of incorrect candi-\ndate segments). Furthermore, it can be shown that separate\ntraining is suboptimal [67].\nThe following section describes four different gradient-\nbased methods for training GTN-based handwriting recog-\nnizers at the string level: Viterbi training, discriminative\nViterbi training, forward training, and discriminative for-\nward training. The last one is a generalization to graph-\nbased systems of the maximum a posteriori criterion in-\ntroduced in Section II-C. Discriminative forward training\nis somewhat similar to the so-called maximum mutual\ninformation criterion used to train HMM in speech recog-\nnition. However, our rationale differs from the classical\none. We make no recourse to a probabilistic interpretation\nbut show that, within the gradient-based learning approach,\ndiscriminative training is a simple instance of the pervasive\nprinciple of error correcting learning.\nTraining methods for graph-based sequence recognition\nsystems such as HMM’s have been extensively studied\nin the context of speech recognition [28]. Those meth-\nods require that the system be based on probabilistic\ngenerative models of the data, which provide normalized\nlikelihoods over the space of possible input sequences.\nPopular HMM learning methods, such as the Baum–Welsh\nalgorithm, rely on this normalization. The normalization\ncannot be preserved when nongenerative models such as\nNN’s are integrated into the system. Other techniques, such\nas discriminative training methods, must be used in this\ncase. Several authors have proposed such methods to train\nNN/HMM speech recognizers at the word or sentence level\n[29], [67], [71]–[78].\nOther globally trainable sequence recognition systems\navoid the difﬁculties of statistical modeling by not resorting\nto graph-based techniques. The best example is recurrent\nNN’s (RNN’s). Unfortunately, despite early enthusiasm,\nthe training of RNN’s with gradient-based techniques has\nproven very difﬁcult in practice [79].\nThe GTN techniques presented below simplify and gen-\neralize the global training methods developed for speech\nrecognition.\nA. Viterbi Training\nDuring recognition, we select the path in the interpre-\ntation graph that has the lowest penalty with the Viterbi\nalgorithm. Ideally, we would like this path of lowest penalty\nto be associated with the correct label sequence as often as\npossible. An obvious loss function to minimize is therefore\nthe average over the training set of the penalty of the\npath associated with the correct label sequence that has the\nlowest penalty. The goal of training will be to ﬁnd the set of\nrecognizer parameters (the weights, if the recognizer is an\nNN) that minimize the average penalty of this “correct”\nlowest penalty path. The gradient of this loss function\ncan be computed by back propagation through the GTN\narchitecture shown in Fig. 19. This training architecture is\nalmost identical to the recognition architecture described\nin the previous section, except that an extra GT called a\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2299\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 19.\nViterbi training GTN architecture for a character string\nrecognizer based on HOS.\npath selector is inserted between the interpretation graph\nand the Viterbi transformer. This transformer takes the\ninterpretation graph and the desired label sequence as input.\nIt extracts from the interpretation graph those paths that\ncontain the correct (desired) label sequence. Its output\ngraph\nis called the constrained interpretation graph (also\nknown as forced alignment in the HMM literature) and\ncontains all the paths that correspond to the correct label\nsequence. The constrained interpretation graph is then sent\nto the Viterbi transformer which produces a graph\nwith a single path. This path is the “correct” path with\nthe lowest penalty. Finally, a path scorer transformer takes\nand simply computes its cumulated penalty\nby\nadding up the penalties along the path. The output of this\nGTN is the loss function for the current pattern\n(11)\nThe only label information that is required by the above\nsystem is the sequence of desired character labels. No\nknowledge of the correct segmentation is required on\nthe part of the supervisor, since it chooses among the\nsegmentations in the interpretation graph the one that yields\nthe lowest penalty.\nThe process of back propagating gradients through the\nViterbi training GTN is now described. As explained in\nSection IV, the gradients must be propagated backward\nthrough all modules of the GTN in order to compute\ngradients in preceding modules and thereafter tune their\nparameters. Back propagating gradients through the path\nscorer is quite straightforward. The partial derivatives of\nthe loss function with respect to the individual penalties on\nthe constrained Viterbi path\nare equal to one, since\nthe loss function is simply the sum of those penalties. Back\npropagating through the Viterbi Transformer is equally\nsimple. The partial derivatives of\nwith respect to the\npenalties on the arcs of the constrained graph\nare one for\nthose arcs that appear in the constrained Viterbi path\nand zero for those that do not. Why is it legitimate to back\npropagate through an essentially discrete function such as\nthe Viterbi transformer? The answer is that the Viterbi trans-\nformer is nothing more than a collection of min functions\nand adders put together. It was shown in Section IV that\ngradients can be back propagated through min functions\nwithout adverse effects. Back propagation through the path\nselector transformer is similar to back propagation through\nthe Viterbi transformer. Arcs in\nthat appear in\nhave the same gradient as the corresponding arc in\ni.e., one or zero, depending on whether the arc appear\nin\nThe other arcs, i.e., those that do not have an\nalter ego in\nbecause they do not contain the right label\nhave a gradient of zero. During the forward propagation\nthrough the recognition transformer, one instance of the\nrecognizer for single character was created for each arc in\nthe segmentation graph. The state of recognizer instances\nwas stored. Since each arc penalty in\nis produced by\nan individual output of a recognizer instance, we now have\na gradient (one or zero) for each output of each instance\nof the recognizer. Recognizer outputs that have a nonzero\ngradient are part of the correct answer and will therefore\nhave their value pushed down. The gradients present on\nthe recognizer outputs can be back propagated through\neach recognizer instance. For each recognizer instance, we\nobtain a vector of partial derivatives of the loss function\nwith respect to the recognizer instance parameters. All the\nrecognizer instances share the same parameter vector, since\nthey are merely clones of each other, therefore the full\ngradient of the loss function with respect to the recognizer’s\nparameter vector is simply the sum of the gradient vectors\nproduced by each recognizer instance. Viterbi training,\nthough formulated differently, is often use in HMM-based\nspeech recognition systems [28]. Similar algorithms have\nbeen applied to speech recognition systems that integrate\nNN’s with time alignment [71], [72], [76] or hybrid neural-\nnetwork/HMM systems [29], [74], [75].\nWhile it seems simple and satisfying, this training archi-\ntecture has a ﬂaw that can potentially be fatal. The problem\nwas already mentioned in Section II-C. If the recognizer\nis a simple NN with sigmoid output units, the minimum\nof the loss function is attained, not when the recognizer\nalways gives the right answer, but when it ignores the\ninput and sets its output to a constant vector with small\nvalues for all the components. This is known as the collapse\nproblem. The collapse only occurs if the recognizer outputs\ncan simultaneously take their minimum value. If, on the\nother hand, the recognizer’s output layer contains RBF\nunits with ﬁxed parameters, then there is no such trivial\nsolution. This is due to the fact that a set of RBF with\nﬁxed distinct parameter vectors cannot simultaneously take\ntheir minimum value. In this case, the complete collapse\ndescribed above does not occur. However, this does not\ntotally prevent the occurrence of a milder collapse because\nthe loss function still has a “ﬂat spot” for a trivial solution\nwith constant recognizer output. This ﬂat spot is a saddle\npoint, but it is attractive in almost all directions and is very\ndifﬁcult to get out of using gradient-based minimization\nprocedures. If the parameters of the RBF’s are allowed\n2300\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nto adapt, then the collapse problems reappear because the\nRBF centers can all converge to a single vector, and the\nunderlying NN can learn to produce that vector and ignore\nthe input. A different kind of collapse occurs if the width\nof the RBF’s are also allowed to adapt. The collapse only\noccurs if a trainable module such as an NN feeds the\nRBF’s. The collapse does not occur in HMM-based speech\nrecognition systems because they are generative systems\nthat produce normalized likelihoods for the input data (more\non this later). Another way to avoid the collapse is to train\nthe whole system with respect to a discriminative training\ncriterion, such as maximizing the conditional probability of\nthe correct interpretations (correct sequence of class labels)\ngiven the input image.\nAnother problem with Viterbi training is that the penalty\nof the answer cannot be used reliably as a measure of\nconﬁdence because it does not take low-penalty (or high-\nscoring) competing answers into account.\nB. Discriminative Viterbi Training\nA modiﬁcation of the training criterion can circumvent\nthe collapse problem described above and at the same time\nproduce more reliable conﬁdence values. The idea is to\nnot only minimize the cumulated penalty of the lowest\npenalty path with the correct interpretation, but also to\nsomehow increase the penalty of competing and possibly\nincorrect paths that have a dangerously low penalty. This\ntype of criterion is called discriminative because it plays the\ngood answers against the bad ones. Discriminative training\nprocedures can be seen as attempting to build appropriate\nseparating surfaces between classes rather than to model in-\ndividual classes independently of each other. For example,\nmodeling the conditional distribution of the classes given\nthe input image is more discriminative (focusing more on\nthe classiﬁcation surface) than having a separate generative\nmodel of the input data associated to each class (which, with\nclass priors, yields the whole joint distribution of classes\nand inputs). This is because the conditional approach does\nnot need to assume a particular form for the distribution of\nthe input data.\nOne example of discriminative criterion is the difference\nbetween the penalty of the Viterbi path in the constrained\ngraph, and the penalty of the Viterbi path in the (uncon-\nstrained) interpretation graph, i.e., the difference between\nthe penalty of the best correct path and the penalty of\nthe best path (correct or incorrect). The corresponding\nGTN training architecture is shown in Fig. 20. The left\nside of the diagram is identical to the GTN used for\nnondiscriminative Viterbi training. This loss function re-\nduces the risk of collapse because it forces the recognizer\nto increases the penalty of wrongly recognized objects.\nDiscriminative training can also be seen as another example\nof error correction procedure, which tends to minimize the\ndifference between the desired output computed in the left\nhalf of the GTN in Fig. 20 and the actual output computed\nin the right half of Fig. 20.\nLet the discriminative Viterbi loss function be denoted\nand let us call\nthe penalty of the Viterbi path\nin the constrained graph and\nthe penalty of the Viterbi\npath in the unconstrained interpretation graph\n(12)\nis always positive since the constrained graph is a\nsubset of the paths in the interpretation graph, and the\nViterbi algorithm selects the path with the lowest total\npenalty. In the ideal case, the two paths\nand\ncoincide, and\nis zero.\nBack-propagating gradients through the discriminative\nViterbi GTN adds some “negative” training to the previ-\nously described nondiscriminative training. Fig. 20 shows\nhow the gradients are back propagated. The left half is\nidentical to the nondiscriminative Viterbi training GTN,\ntherefore the back propagation is identical. The gradients\nback propagated through the right half of the GTN are\nmultiplied by\n1, since\ncontributes to the loss with\na negative sign. Otherwise the process is similar to the left\nhalf. The gradients on arcs of\nget positive contributions\nfrom the left half and negative contributions from the\nright half. The two contributions must be added since the\npenalties on\narcs are sent to the two halves through\na “Y” connection in the forward pass. Arcs in\nthat\nappear neither in\nnor in\nhave a gradient of zero.\nThey do not contribute to the cost. Arcs that appear in both\nand\nalso have zero gradient. The\n1 contribution\nfrom the right half cancels the\n1 contribution from the left\nhalf. In other words, when an arc is rightfully part of the\nanswer there is no gradient. If an arc appears in\nbut\nnot in\nthe gradient is\n1. The arc should have had a\nlower penalty to make it to\nIf an arc is in\nbut\nnot in\nthe gradient is\nThe arc had a low penalty,\nbut it should have had a higher penalty since it is not part\nof the desired answer.\nVariations of this technique have been used for the speech\nrecognition. Driancourt and Bottou [76] used a version of\nit where the loss function is saturated to a ﬁxed value.\nThis can be seen as a generalization of the Learning Vector\nQuantization 2 (LVQ-2) loss function [80]. Other variations\nof this method use not only the Viterbi path but the K-\nbest paths. The discriminative Viterbi algorithm does not\nhave the ﬂaws of the nondiscriminative version, but there\nare problems nonetheless. The main problem is that the\ncriterion does not build a margin between the classes. The\ngradient is zero as soon as the penalty of the constrained\nViterbi path is equal to that of the Viterbi path. It would be\ndesirable to push up the penalties of the wrong paths when\nthey are dangerously close to the good one. The following\nsection presents a solution to this problem.\nC. Forward Scoring and Forward Training\nWhile the penalty of the Viterbi path is perfectly appro-\npriate for the purpose of recognition it gives only a partial\npicture of the situation. Imagine the lowest penalty paths\ncorresponding to several different segmentations produced\nthe same answer (the same label sequence). Then it could be\nargued that the overall penalty for the interpretation should\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2301\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 20.\nDiscriminative Viterbi training GTN architecture for a character string recognizer based\non HOS. Quantities in square brackets are penalties computed during the forward propagation.\nQuantities in parentheses are partial derivatives computed during the backward propagation.\nbe smaller than the penalty obtained when only one path\nproduced that interpretation, because multiple paths with\nidentical label sequences are more evidence that the label\nsequence is correct. Several rules can be used compute\nthe penalty associated to a graph that contains several\nparallel paths. We use a combination rule borrowed from\na probabilistic interpretation of the penalties as negative\nlog posteriors. In a probabilistic framework, the posterior\nprobability for the interpretation should be the sum of the\nposteriors for all the paths that produce that interpretation.\nTranslated in terms of penalties, the penalty of an inter-\npretation should be the negative logarithm of the sum of\nthe negative exponentials of the penalties of the individual\npaths. The overall penalty will be smaller than all the\npenalties of the individual paths.\nGiven an interpretation, there is a well-known method,\ncalled the forward algorithm for computing the above\nquantity efﬁciently [28]. The penalty computed with this\nprocedure for a particular interpretation is called the for-\nward penalty. Consider again the concept of constrained\n2302\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\ngraph, the subgraph of the interpretation graph which\ncontains only the paths that are consistent with a particular\nlabel sequence. There is one constrained graph for each\npossible label sequence (some may be empty graphs, which\nhave inﬁnite penalties). Given an interpretation, running\nthe forward algorithm on the corresponding constrained\ngraph gives the forward penalty for that interpretation.\nThe forward algorithm proceeds in a way very similar to\nthe Viterbi algorithm, except that the operation used at\neach node to combine the incoming cumulated penalties,\ninstead of being the min function, is the so-called logadd\noperation, which can be seen as a “soft” version of the min\nfunction\n(13)\nwhere\nis the set of upstream arcs of node\nis the penalty on arc\nand\n(14)\nNote that because of numerical inaccuracies, it is better\nto factorize the largest\n(corresponding to the smallest\npenalty) out of the logarithm.\nAn interesting analogy can be drawn if we consider\nthat a graph on which we apply the forward algorithm is\nequivalent to an NN on which we run a forward propaga-\ntion, except that multiplications are replaced by additions,\nthe additions are replaced by log-adds, and there are no\nsigmoids.\nOne way to understand the forward algorithm is to think\nabout multiplicative scores (e.g., probabilities) instead of\nadditive penalties on the arcs: score\nIn that case the Viterbi algorithm selects the path with\nthe largest cumulative score (with scores multiplied along\nthe path), whereas the forward score is the sum of the\ncumulative scores associated to each of the possible paths\nfrom the start to the end node. The forward penalty is\nalways lower than the cumulated penalty on any of the\npaths, but if one path “dominates” (with a much lower\npenalty), its penalty is almost equal to the forward penalty.\nThe forward algorithm gets its name from the forward\npass of the well-known Baum–Welsh algorithm for training\nHMM’s [28]. Section VIII-E gives more details on the\nrelation between this work and HMM’s.\nThe advantage of the forward penalty with respect to the\nViterbi penalty is that it takes into account all the different\nways to produce an answer, not just the one with the lowest\npenalty. This is important if there is some ambiguity in the\nsegmentation, since the combined forward penalty of two\npaths\nand\nassociated with the same label sequence\nmay be less than the penalty of a path\nassociated with\nanother label sequence, even though the penalty of\nmight be less than any one of\nor\nThe forward-training GTN is only a slight modiﬁcation of\nthe previously introduced Viterbi-training GTN. It sufﬁces\nto turn the Viterbi transformers in Fig. 19 into forward\nscorers that take an interpretation graph as input an produce\nthe forward penalty of that graph on output. Then the\npenalties of all the paths that contain the correct answer\nare lowered, instead of just that of the best one.\nBack propagating through the forward penalty computa-\ntion (the forward transformer) is quite different from back\npropagating through a Viterbi transformer. All the penalties\nof the input graph have an inﬂuence on the forward penalty,\nbut penalties that belong to low-penalty paths have a\nstronger inﬂuence. Computing derivatives with respect to\nthe forward penalties\ncomputed at each\nnode of a\ngraph is done by back-propagation through the graph\n(15)\nwhere\nwith source\nis the set of\ndownstream arcs from node\nFrom the above derivatives,\nthe derivatives with respect to the arc penalties are obtained\n(16)\nThis can be seen as a “soft” version of the back propagation\nthrough a Viterbi scorer and transformer. All the arcs in\nhave an inﬂuence on the loss function. The arcs that\nbelong to low penalty paths have a larger inﬂuence. Back\npropagation through the path selector is the same as before.\nThe derivative with respect to\narcs that have an alter\nego in\nare simply copied from the corresponding arc in\nThe derivatives with respect to the other arcs are zero.\nSeveral authors have applied the idea of back-propagating\ngradients through a forward scorer to train speech recogni-\ntion systems, including Bridle and his\n-net model [73] and\nHaffner and his\n-TDNN model [81], but these authors\nrecommended discriminative training as described in the\nnext section.\nD. Discriminative Forward Training\nThe information contained in the forward penalty can be\nused in another discriminative training criterion which we\nwill call the discriminative forward criterion. This criterion\ncorresponds to maximization of the posterior probability of\nchoosing the paths associated with the correct interpreta-\ntion. This posterior probability is deﬁned as the exponential\nof minus the constrained forward penalty, normalized by the\nexponential of minus the unconstrained forward penalty.\nNote that the forward penalty of the constrained graph\nis always larger or equal to the forward penalty of the\nunconstrained interpretation graph. Ideally, we would like\nthe forward penalty of the constrained graph to be equal\nto the forward penalty of the complete interpretation graph.\nEquality between those two quantities is achieved when\nthe combined penalties of the paths with the correct label\nsequence is negligibly small compared to the penalties of all\nthe other paths, or that the posterior probability associated\nto the paths with the correct interpretation is almost one,\nwhich is precisely what we want. The corresponding GTN\ntraining architecture is shown in Fig. 21.\nLet the difference be denoted\nand let us call\nthe forward penalty of the constrained graph and\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2303\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 21.\nDiscriminative forward training GTN architecture for a\ncharacter string recognizer based on HOS.\nthe forward penalty of the complete interpretation\ngraph\n(17)\nis always positive since the constrained graph is\na subset of the paths in the interpretation graph, and the\nforward penalty of a graph is always larger than the forward\npenalty of a subgraph of this graph. In the ideal case, the\npenalties of incorrect paths are inﬁnitely large, therefore\nthe two penalties coincide and\nis zero. Readers\nfamiliar with the Boltzmann machine connectionist model\nmight recognize the constrained and unconstrained graphs\nas analogous to the “clamped” (constrained by the observed\nvalues of the output variable) and “free” (unconstrained)\nphases of the Boltzmann machine algorithm [13].\nBack propagating derivatives through the discriminative\nforward GTN distributes gradients more evenly than in the\nViterbi case. Derivatives are back propagated through the\nleft half of the GTN in Fig. 21 down to the interpretation\ngraph. Derivatives are negated and back propagated through\nthe right-half, and the result for each arc is added to the\ncontribution from the left half. Each arc in\nnow has\na derivative. Arcs that are part of a correct path have\na positive derivative. This derivative is very large if an\nincorrect path has a lower penalty than all the correct\npaths. Similarly, the derivatives with respect to arcs that are\npart of a low-penalty incorrect path have a large negative\nderivative. On the other hand, if the penalty of a path\nassociated with the correct interpretation is much smaller\nthan all other paths, the loss function is very close to zero\nand almost no gradient is back propagated. The training\ntherefore concentrates on examples of images which yield\na classiﬁcation error, and furthermore, it concentrates on the\npieces of the image which cause that error. Discriminative\nforward training is an elegant and efﬁcient way of solving\nthe infamous credit assignment problem for learning ma-\nchines that manipulate “dynamic” data structures such as\ngraphs. More generally, the same idea can be used in all\nsituations where a learning machine must choose between\ndiscrete alternative interpretations.\nAs previously, the derivatives on the interpretation graph\npenalties can then be back propagated into the character\nrecognizer instances. Back propagation through the charac-\nter recognizer gives derivatives on its parameters. All the\ngradient contributions for the different candidate segments\nare added up to obtain the total gradient associated to\none pair (input image, correct label sequence), that is, one\nexample in the training set. A step of stochastic gradient\ndescent can then be applied to update the parameters.\nE. Remarks on Discriminative Training\nIn the above discussion, the global training criterion\nwas given a probabilistic interpretation, but the individual\npenalties on the arcs of the graphs were not. There are\ngood reasons for that. For example, if some penalties are\nassociated to the different class labels, they would: 1) have\nto sum to one (class posteriors) or 2) integrate to one over\nthe input domain (likelihoods).\nLet us ﬁrst discuss the ﬁrst case (class posteriors nor-\nmalization). This local normalization of penalties may\neliminate information that is important for locally rejecting\nall the classes [82], e.g., when a piece of image does\nnot correspond to a valid character class because some of\nthe segmentation candidates may be wrong. Although an\nexplicit “garbage class” can be introduced in a probabilistic\nframework to address that question, some problems remain\nbecause it is difﬁcult to characterize such a class probabilis-\ntically and to train a system in this way (it would require\na density model of unseen or unlabeled samples).\nThe probabilistic interpretation of individual variables\nplays an important role in the Baum–Welsh algorithm\nin combination with the expectation-maximization (EM)\nprocedure. Unfortunately, those methods cannot be applied\nto discriminative training criteria, and one is reduced to\nusing gradient-based methods. Enforcing the normalization\nof the probabilistic quantities while performing gradient-\nbased learning is complex, inefﬁcient, time consuming, and\ncreates ill-conditioning of the loss-function.\nFollowing [82], we therefore prefer to postpone normal-\nization as far as possible (in fact, until the ﬁnal decision\nstage of the system). Without normalization, the quantities\nmanipulated in the system do not have a direct probabilistic\ninterpretation.\nLet us now discuss the second case (using a generative\nmodel of the input). Generative models build the boundary\nindirectly by ﬁrst building an independent density model\nfor each class and then performing classiﬁcation decisions\non the basis of these models. This is not a discriminative\napproach in that it does not focus on the ultimate goal of\nlearning, which in this case is to learn the classiﬁcation\ndecision surface. Theoretical arguments [6], [7] suggest that\nestimating input densities when the real goal is to obtain\na discriminant function for classiﬁcation is a suboptimal\nstrategy. In theory, the problem of estimating densities\nin high-dimensional spaces is much more ill posed than\nﬁnding decision boundaries.\n2304\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 22.\nExplicit segmentation can be avoided by sweeping a\nrecognizer at every possible location in the input ﬁeld.\nEven though the internal variables of the system do not\nhave a direct probabilistic interpretation, the overall system\ncan still be viewed as producing posterior probabilities\nfor the classes. In fact, assuming that a particular label\nsequence is given as the “desired sequence” to the GTN in\nFig. 21, the exponential of minus\ncan be interpreted\nas an estimate of the posterior probability of that label\nsequence given the input. The sum of those posteriors for\nall the possible label sequences is one. Another approach\nwould consists of directly minimizing an approximation\nof the number of misclassiﬁcations [83], [76]. We prefer\nto use the discriminative forward loss function because it\ncauses less numerical problems during the optimization. We\nwill see in Section X-C that this is a good way to obtain\nscores on which to base a rejection strategy. The important\npoint being made here is that one is free to choose any\nparameterization deemed appropriate for a classiﬁcation\nmodel. The fact that a particular parameterization uses\ninternal variables with no clear probabilistic interpretation\ndoes not make the model any less legitimate than models\nthat manipulate normalized quantities.\nAn important advantage of global and discriminative\ntraining is that learning focuses on the most important\nerrors, and the system learns to integrate the ambiguities\nfrom the segmentation algorithm with the ambiguities of\nthe character recognizer. In Section IX we present ex-\nperimental results with an online handwriting recognition\nsystem that conﬁrm the advantages of using global training\nversus separate training. Experiments in speech recognition\nwith hybrids of NN’s and HMM’s also showed marked\nimprovements brought by global training [29], [67], [77],\n[84].\nVII.\nMULTIPLE OBJECT RECOGNITION: SPACE\nDISPLACEMENT NEURAL NETWORK\nThere is a simple alternative to explicitly segmenting\nimages of character strings using heuristics. The idea is\nto sweep a recognizer at all possible locations across a\nnormalized image of the entire word or string as shown\nin Fig. 22. With this technique, no segmentation heuristics\nare required since the system essentially examines all the\npossible segmentations of the input. However, there are\nproblems with this approach. First, the method is in general\nFig. 23.\nAn SDNN is a convolutional network that has been\nreplicated over a wide input ﬁeld.\nquite expensive. The recognizer must be applied at every\npossible location on the input, or at least at a large enough\nsubset of locations so that misalignments of characters\nin the ﬁeld of view of the recognizers are small enough\nto have no effect on the error rate. Second, when the\nrecognizer is centered on a character to be recognized,\nthe neighbors of the center character will be present in the\nﬁeld of view of the recognizer, possibly touching the center\ncharacter. Therefore the recognizer must be able to correctly\nrecognize the character in the center of its input ﬁeld, even\nif neighboring characters are very close to or touching the\ncentral character. Third, a word or character string cannot\nbe perfectly size-normalized. Individual characters within a\nstring may have widely varying sizes and baseline positions.\nTherefore the recognizer must be very robust to shifts and\nsize variations.\nThese three problems are elegantly circumvented if a\nconvolutional network is replicated over the input ﬁeld.\nFirst of all, as shown in Section III, convolutional NN’s are\nvery robust to shifts and scale variations of the input image,\nas well as to noise and extraneous marks in the input. These\nproperties take care of the latter two problems mentioned\nin the previous paragraph. Second, convolutional networks\nprovide a drastic saving in computational requirement when\nreplicated over large input ﬁelds. A replicated convolutional\nnetwork, also called an SDNN [27], is shown in Fig. 23.\nWhile scanning a recognizer can be prohibitively expen-\nsive in general, convolutional networks can be scanned or\nreplicated very efﬁciently over large, variable-size input\nﬁelds. Consider one instance of a convolutional net and its\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2305\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nalter ego at a nearby location. Because of the convolutional\nnature of the network, units in the two instances that look\nat identical locations on the input have identical outputs,\ntherefore their states do not need to be computed twice.\nOnly a thin “slice” of new states that are not shared by\nthe two network instances needs to be recomputed. When\nall the slices are put together, the result is simply a larger\nconvolutional network whose structure is identical to the\noriginal network, except that the feature maps are larger\nin the horizontal dimension. In other words, replicating a\nconvolutional network can be done simply by increasing the\nsize of the ﬁelds over which the convolutions are performed\nand by replicating the output layer accordingly. The output\nlayer effectively becomes a convolutional layer. An output\nwhose receptive ﬁeld is centered on an elementary object\nwill produce the class of this object, while an in-between\noutput may indicate no character or contain rubbish. The\noutputs can be interpreted as evidences for the presence of\nobjects at all possible positions in the input ﬁeld.\nThe SDNN architecture seems particularly attractive for\nrecognizing cursive handwriting where no reliable segmen-\ntation heuristic exists. Although the idea of SDNN is quite\nold and very attractive in its simplicity, it has not generated\nwide interest until recently because, as stated above, it puts\nenormous demands on the recognizer [26], [27]. In speech\nrecognition, where the recognizer is at least one order of\nmagnitude smaller, replicated convolutional networks are\neasier to implement, for instance in Haffner’s multistate\nTDNN model [78], [85].\nA. Interpreting the Output of an SDNN with a GTN\nThe output of an SDNN is a sequence of vectors which\nencode the likelihoods, penalties, or scores of ﬁnding char-\nacter of a particular class label at the corresponding location\nin the input. A postprocessor is required to pull out the\nbest possible label sequence from this vector sequence. An\nexample of SDNN output is shown in Fig. 25. Very often,\nindividual characters are spotted by several neighboring\ninstances of the recognizer, a consequence of the robustness\nof the recognizer to horizontal translations. Also quite\noften, characters are erroneously detected by recognizer\ninstances that see only a piece of a character. For example\na recognizer instance that only sees the right third of a\n“4” might output the label 1. How can we eliminate those\nextraneous characters from the output sequence and pull\nout the best interpretation? This can be done using a new\ntype of GT with two input graphs as shown in Fig. 24.\nThe sequence of vectors produced by the SDNN is ﬁrst\ncoded into a linear graph with multiple arcs between pairs\nof successive nodes. Each arc between a particular pair of\nnodes contains the label of one of the possible categories,\ntogether with the penalty produced by the SDNN for that\nclass label at that location. This graph is called the SDNN\noutput graph. The second input graph to the transformer\nis a grammar transducer, more speciﬁcally a ﬁnite-state\ntransducer [86], that encodes the relationship between input\nstrings of class labels and corresponding output strings\nof recognized characters. The transducer is a weighted\nFig. 24.\nA GT pulls out the best interpretation from the output\nof the SDNN.\nFig. 25.\nAn example of multiple character recognition with\nSDNN. With SDNN, no explicit segmentation is performed.\nﬁnite state machine (a graph) where each arc contains a\npair of labels and possibly a penalty. Like a ﬁnite-state\nmachine, a transducer is in a state and follows an arc\nto a new state when an observed input symbol matches\nthe ﬁrst symbol in the symbol pair attached to the arc.\nAt this point the transducer emits the second symbol in\nthe pair together with a penalty that combines the penalty\nof the input symbol and the penalty of the arc. A trans-\nducer therefore transforms a weighted symbol sequence\ninto another weighted symbol sequence. The GT shown\nin Fig. 24 performs a composition between the recognition\ngraph and the grammar transducer. This operation takes\nevery possible sequence corresponding to every possible\npath in the recognition graph and matches them with the\npaths in the grammar transducer. The composition produces\nthe interpretation graph, which contains a path for each\ncorresponding output label sequence. This composition\noperation may seem combinatorially intractable, but it turns\nout there exists an efﬁcient algorithm for it described in\nmore details in Section VIII.\nB. Experiments with SDNN\nIn a series of experiments, LeNet-5 was trained with the\ngoal of being replicated so as to recognize multiple charac-\nters without segmentations. The data were generated from\n2306\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 26.\nAN SDNN applied to a noisy image of digit string.\nThe digits shown in the SDNN output represent the winning class\nlabels, with a lighter grey level for high-penalty answers.\nthe previously described MNIST set as follows. Training\nimages were composed of a central character, ﬂanked by\ntwo side characters picked at random in the training set. The\nseparation between the bounding boxes of the characters\nwere chosen at random between\n1 and 4 pixels. In other\ninstances, no central character was present, in which case\nthe desired output of the network was the blank space class.\nIn addition, training images were degraded with 10% salt\nand pepper noise (random pixel inversions).\nFigs. 25 and 26 show a few examples of successful\nrecognitions of multiple characters by the LeNet-5 SDNN.\nStandard techniques based on HOS would fail miserably on\nmany of those examples. As can be seen on these examples,\nthe network exhibits striking invariance and noise resistance\nproperties. While some authors have argued that invariance\nrequires more sophisticated models than feedforward NN’s\n[87], LeNet-5 exhibits these properties to a large extent.\nSimilarly, it has been suggested that accurate recognition\nof multiple overlapping objects require explicit mechanisms\nthat would solve the so-called feature binding problem [87].\nAs can be seen on Figs. 25 and 26, the network is able\nto tell the characters apart even when they are closely\nintertwined, a task that would be impossible to achieve\nwith the more classical HOS technique. The SDNN is also\nable to correctly group disconnected pieces of ink that form\ncharacters. Good examples of that are shown in the upper\nhalf of Fig. 26. In the top left example, the 4 and the 0 are\nmore connected to each other than they are connected with\nthemselves, yet the system correctly identiﬁes the 4 and the\n0 as separate objects. The top right example is interesting\nfor several reasons. First the system correctly identiﬁes the\nthree individual ones. Second, the left half and right half\nof disconnected 4 are correctly grouped, even though no\ngeometrical information could decide to associate the left\nhalf to the vertical bar on its left or on its right. The right\nhalf of the 4 does cause the appearance of an erroneous\none on the SDNN output, but this one is removed by the\ncharacter model transducer which prevents characters from\nappearing on contiguous outputs.\nAnother important advantage of SDNN is the ease with\nwhich they can be implemented on parallel hardware.\nSpecialized analog/digital chips have been designed and\nused in character recognition, and in image preprocessing\napplications [88]. However the rapid progress of conven-\ntional processor technology with reduced-precision vector\narithmetic instructions (such as Intel’s MMX) make the\nsuccess of specialized hardware hypothetical at best.3\nC. Global Training of SDNN\nIn the above experiments, the string images were artiﬁ-\ncially generated from individual character. The advantage\nis that we know in advance the location and the label of\nthe important character. With real training data, the correct\nsequence of labels for a string is generally available, but\nthe precise locations of each corresponding character in the\ninput image are unknown.\nIn the experiments described in the previous section, the\nbest interpretation was extracted from the SDNN output\nusing a very simple GT. Global training of an SDNN can\nbe performed by back propagating gradients through such\nGT’s arranged in architectures similar to the ones described\nin Section VI.\nThis is somewhat equivalent to modeling the output\nof an SDNN with an HMM. Globally trained, variable-\nsize TDNN/HMM hybrids have been used for speech\nrecognition and online handwriting recognition [67], [77],\n[89], [90]. SDNN’s have been used in combination with\nHMM’s or other elastic matching methods for handwritten\nword recognition [91], [92].\nFig. 27 shows the GT architecture for training an\nSDNN/HMM hybrid with\nthe discriminative forward\ncriterion. The top part is comparable to the top part of\nFig. 21. On the right side the composition of the recognition\ngraph with the grammar gives the interpretation graph\nwith all the possible legal interpretations. On the left side\nthe composition is performed with a grammar that only\ncontains paths with the desired sequence of labels. This has\na somewhat similar function to the path selector used in the\nprevious section. Like in Section VI-D, the loss function is\nthe difference between the forward score obtained from the\nleft half and the forward score obtained from the right half.\nTo back propagate through the composition transformer,\nwe need to keep a record of which arc in the recognition\ngraph originated which arcs in the interpretation graph.\nThe derivative with respect to an arc in the recognition\ngraph is equal to the sum of the derivatives with respect\nto all the arcs in the interpretation graph that originated\nfrom it. Derivative can also be computed for the penalties\non the grammar graph, allowing to learn them as well. As\nin the previous example, a discriminative criterion must\n3Short video clips of the LeNet-5 SDNN are available WWW:\nhttp://www.research.att.com/˜yann/ocr.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2307\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 27.\nA globally trainable SDNN/HMM hybrid system ex-\npressed as a GTN.\nbe used, because using a nondiscriminative criterion could\nresult in a collapse effect if the network’s output RBF are\nadaptive. The above training procedure can be equivalently\nformulated in term of HMM. Early experiments in zip\ncode recognition [91], and more recent experiments in\nonline handwriting recognition [38] have demonstrated the\nidea of globally trained SDNN/HMM hybrids. SDNN is\nan extremely promising and attractive technique for OCR,\nbut so far it has not yielded better results than HOS. We\nhope that these results will improve as more experience is\ngained with these models.\nD. Object Detection and Spotting with SDNN\nAn interesting application of SDNN’s is object detection\nand spotting. The invariance properties of convolutional\nnetworks, combined with the efﬁciency with which they\ncan be replicated over large ﬁelds, suggests that they can be\nused for “brute force” object spotting and detection in large\nimages. The main idea is to train a single convolutional\nnetwork to distinguish images of the object of interest from\nimages present in the background. In utilization mode, the\nnetwork is replicated so as to cover the entire image to\nbe analyzed, thereby forming a 2-D SDNN. The output of\nthe SDNN is a 2-D plane in which activated units indicate\nthe presence of the object of interest in the corresponding\nreceptive ﬁeld. Since the sizes of the objects to be detected\nwithin the image are unknown, the image can be presented\nto the network at multiple resolutions, and the results at\nmultiple resolutions combined. The idea has been applied\nto face location [93], address block location on envelopes\n[94], and hand tracking in video [95].\nTo illustrate the method, we will consider the case\nof face detection in images as described in [93]. First,\nimages containing faces at various scales are collected.\nThose images are ﬁltered through a zero-mean Laplacian\nﬁlter so as to remove variations in global illumination and\nlow spatial frequency illumination gradients. Then, training\nsamples of faces and nonfaces are manually extracted from\nthose images. The face subimages are then size normalized\nso that the height of the entire face is approximately 20\npixels while keeping fairly large variations (within a factor\nof two). The scale of background subimages are picked\nat random. A single convolutional network is trained on\nthose samples to classify face subimages from nonface\nsubimages.\nWhen a scene image is to be analyzed, it is ﬁrst ﬁltered\nthrough the Laplacian ﬁlter and subsampled at powers-of-\ntwo resolutions. The network is replicated over each of\nmultiple resolution images. A simple voting technique is\nused to combine the results from multiple resolutions.\nA 2-D version of the global training method described\nin the previous section can be used to alleviate the need\nto manually locate faces when building the training sample\n[93]. Each possible location is seen as an alternative inter-\npretation, i.e., one of several parallel arcs in a simple graph\nthat only contains a start node and an end node.\nOther authors have used NN’s or other classiﬁers such\nas SVM’s for face detection with great success [96], [97].\nTheir systems are very similar to the one described above,\nincluding the idea of presenting the image to the network\nat multiple scales. But since those systems do not use\nconvolutional networks, they cannot take advantage of the\nspeedup described here, and they have to rely on other\ntechniques, such as preﬁltering and real-time tracking,\nto keep the computational requirement within reasonable\nlimits. In addition, because those classiﬁers are much less\ninvariant to scale variations than convolutional networks, it\nis necessary to multiply the number of scales at which the\nimages are presented to the classiﬁer.\nVIII.\nGRAPH TRANSFORMER NETWORKS\nAND TRANSDUCERS\nIn Section IV, GTN’s were introduced as a general-\nization of multilayer, multimodule networks where the\nstate information is represented as graphs instead of ﬁxed-\nsize vectors. This section reinterprets the GTN’s in the\nframework of generalized transduction and proposes a\npowerful graph composition algorithm.\nA. Previous Work\nNumerous authors in speech recognition have used\ngradient-based learning methods that integrate graph-\nbased statistical models (notably HMM’s) with acoustic\nrecognition modules, mainly Gaussian mixture models,\nbut also NN’s [67], [78], [98], [99]. Similar ideas have\nbeen applied to handwriting recognition (see [38] for\na review). However, there has been no proposal for a\nsystematic approach to multilayer graph-based trainable\nsystems. The idea of transforming graphs into other graphs\nhas received considerable attention in computer science\n2308\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nthrough the concept of weighted ﬁnite-state transducers\n[86]. Transducers have been applied to speech recognition\n[100] and language translation [101], and proposals have\nbeen made for handwriting recognition [102]. This line\nof work has been mainly focused on efﬁcient search\nalgorithms [103] and on the algebraic aspects of combining\ntransducers and graphs (called acceptors in this context),\nbut very little effort has been devoted to building globally\ntrainable systems out of transducers. What is proposed\nin the following sections is a systematic approach to\nautomatic\ntraining\nin\ngraph-manipulating\nsystems.\nA\ndifferent approach to graph-based trainable systems, called\ninput–output HMM, was proposed in [104] and [105].\nB. Standard Transduction\nIn the established framework of ﬁnite-state transducers\n[86], discrete symbols are attached to arcs in the graphs.\nAcceptor graphs have a single symbol attached to each\narc whereas transducer graphs have two symbols (an input\nsymbol and an output symbol). A special null symbol is\nabsorbed by any other symbol (when concatenating symbols\nto build a symbol sequence). Weighted transducers and\nacceptors also have a scalar quantity attached to each\narc. In this framework, the composition operation takes\nas input an acceptor graph and a transducer graph and\nbuilds an output acceptor graph. Each path in this output\ngraph (with symbol sequence\n) corresponds to one path\n(with symbol sequence\n) in the input acceptor graph\nand one path and a corresponding pair of input–output\nsequences\nin the transducer graph. The weights\non the arcs of the output graph are obtained by adding\nthe weights from the matching arcs in the input acceptor\nand transducer graphs. In the rest of the paper, we will\ncall this graph composition operation using transducers the\n(standard) transduction operation.\nA simple example of transduction is shown in Fig. 28.\nIn this simple example, the input and output symbols\non the transducer arcs are always identical. This type of\ntransducer graph is called a grammar graph. To better\nunderstand the transduction operation, imagine two tokens\nsitting each on the start nodes of the input acceptor graph\nand the transducer graph. The tokens can freely follow\nany arc labeled with a null input symbol. A token can\nfollow an arc labeled with a nonnull input symbol if the\nother token also follows an arc labeled with the same\ninput symbol. We have an acceptable trajectory when\nboth tokens reach the end nodes of their graphs (i.e.,\nthe tokens have reached the terminal conﬁguration). This\ntrajectory represents a sequence of input symbols that\ncomplies with both the acceptor and the transducer. We can\nthen collect the corresponding sequence of output symbols\nalong the trajectory of the transducer token. The above\nprocedure produces a tree, but a simple technique described\nin Section VIII-C can be used to avoid generating multiple\ncopies of certain subgraphs by detecting when a particular\noutput state has already been seen.\nThe transduction operation can be performed very ef-\nﬁciently [106], but presents complex bookkeeping prob-\nFig. 28.\nExample of composition of the recognition graph with\nthe grammar graph in order to build an interpretation that is\nconsistent with both of them. During the forward propagation\n(dark arrows), the methods check and fprop are used. Gradients\n(dashed arrows) are back propagated with the adaptation of the\nmethod group.\nlems concerning the handling of all combinations of null\nand nonnull symbols. If the weights are interpreted as\nprobabilities (normalized appropriately) then an acceptor\ngraph represents a probability distribution over the language\ndeﬁned by the set of label sequences associated to all\npossible paths (from the start to the end node) in the graph.\nAn example of application of the transduction operation\nis the incorporation of linguistic constraints (a lexicon or\na grammar) when recognizing words or other character\nstrings. The recognition transformer produces the recog-\nnition graph (an acceptor graph) by applying the NN\nrecognizer to each candidate segment. This acceptor graph\nis composed with a transducer graph for the grammar. The\ngrammar transducer contains a path for each legal sequence\nof symbol, possibly augmented with penalties to indicate\nthe relative likelihoods of the possible sequences. The arcs\ncontain identical input and output symbols. Another exam-\nple of transduction was mentioned in Section V: the path\nselector used in the HOS training GTN is implementable by\na composition. The transducer graph is linear graph which\ncontains the correct label sequence. The composition of\nthe interpretation graph with this linear graph yields the\nconstrained graph.\nC. Generalized Transduction\nIf the data structures associated to each arc took only\na ﬁnite number of values, composing the input graph and\nan appropriate transducer would be a sound solution. For\nour applications however, the data structures attached to\nthe arcs of the graphs may be vectors, images or other\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2309\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nhigh-dimensional objects that are not readily enumerated.\nWe present a new composition operation that solves this\nproblem.\nInstead of only handling graphs with discrete symbols\nand penalties on the arcs, we are interested in considering\ngraphs whose arcs may carry complex data structures,\nincluding continuous-valued data structures such as vectors\nand images. Composing such graphs requires additional\ninformation.\n1) When examining a pair of arcs (one from each input\ngraph), we need a criterion to decide whether to create\ncorresponding arc(s) and node(s) in the output graph,\nbased on the information attached to the input arcs.\nWe can decide to build an arc, several arcs, or an\nentire subgraph with several nodes and arcs.\n2) When that criterion is met, we must build the corre-\nsponding arc(s) and node(s) in the output graph and\ncompute the information attached to the newly created\narc(s) as a function that the information attached to\nthe input arcs.\nThese functions are encapsulated in an object called\na composition transformer. An instance of composition\ntransformer implements the following three methods:\n1) check(arc1,\narc2) compares the data struc-\ntures pointed to by arcs arc1 (from the ﬁrst graph)\nand arc2 (from the second graph) and returns\na boolean indicating whether corresponding arc(s)\nshould be created in the output graph;\n2) fprop(ngraph, upnode,downnode, arc1,\narc2) is called when check(arc1,arc2) re-\nturns true; this method creates new arcs and nodes\nbetween nodes upnode and downnode in the out-\nput graph ngraph, and computes the information\nattached to these newly created arcs as a function of\nthe attached information of the input arcs arc1 and\narc2;\n3) bprop(ngraph, upnode, downnode, arc1,\narc2) is called during training in order to prop-\nagate gradient information from the output subgraph\nbetween upnode and downnode into the data struc-\ntures on the arc1 and arc2, as well as with respect\nto the parameters that were used in the fprop call\nwith the same arguments; this method assumes that\nthe function used by fprop to compute the values\nattached to its output arcs is differentiable.\nThe check method can be seen as constructing a dy-\nnamic architecture of functional dependencies, while the\nfprop method performs a forward propagation through\nthat architecture to compute the numerical information at-\ntached to the arcs. The bprop method performs a backward\npropagation through the same architecture to compute the\npartial derivatives of the loss function with respect to\nthe information attached to the arcs. This is illustrated in\nFig. 28.\nFig. 29 shows a simpliﬁed generalized graph composition\nalgorithm. This simpliﬁed algorithm does not handle null\ntransitions, and it does not check whether the tokens\nFig. 29.\nPseudocode for a simpliﬁed generalized composition\nalgorithm. For simplifying the presentation, we do not handle\nnull transitions nor implement dead end avoidance. The two main\ncomponents of the composition appear clearly here: 1) the recursive\nfunction simtoken() enumerating the token trajectories and 2)\nthe associative array map used for remembering which nodes of\nthe composed graph have been visited.\ntrajectory is acceptable (i.e., both tokens simultaneously\nreach the end nodes of their graphs). The management\nof null transitions is a straightforward modiﬁcation of the\ntoken simulation function. Before enumerating the possible\nnonnull joint token transitions, we loop on the possible\nnull transitions of each token, recursively call the token\nsimulation function, and ﬁnally call the method fprop.\nThe safest way for identifying acceptable trajectories con-\nsists of running a preliminary pass for identifying the\ntoken conﬁgurations from which we can reach the terminal\nconﬁguration (i.e., both tokens on the end nodes). This\n2310\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nis easily achieved by enumerating the trajectories in the\nopposite direction. We start on the end nodes and follow\nthe arcs upstream. During the main pass, we only build\nthe nodes that allow the tokens to reach the terminal\nconﬁguration.\nGraph composition using transducers (i.e., standard trans-\nduction) is easily and efﬁciently implemented as a gener-\nalized transduction. The method check simply tests the\nequality of the input symbols on the two arcs, and the\nmethod fprop creates a single arc whose symbol is the\noutput symbol on the transducer’s arc.\nThe composition between pairs of graphs is particularly\nuseful for incorporating linguistic constraints in a handwrit-\ning recognizer. Examples of its use are given in the online\nhandwriting recognition system described in Section IX\n(and in the check reading system described in Section X).\nIn the rest of the paper, the term composition transformer\nwill denote a GT based on the generalized transductions\nof multiple graphs. The concept of generalized transduc-\ntion is a very general one. In fact, many of the GT’s\ndescribed earlier in this paper, such as the segmenter and\nthe recognizer, can be formulated in terms of generalized\ntransduction. In this case, the generalized transduction does\nnot take two input graphs but a single input graph. The\nmethod fprop of the transformer may create several arcs\nor even a complete subgraph for each arc of the initial\ngraph. In fact the pair check,fprop itself can be seen\nas procedurally deﬁning a transducer.\nIn addition, it can be shown that the generalized trans-\nduction of a single graph is theoretically equivalent to\nthe standard composition of this graph with a particular\ntransducer graph. However, implementing the operation this\nway may be very inefﬁcient since the transducer can be\nvery complicated.\nIn practice, the graph produced by a generalized transduc-\ntion is represented procedurally in order to avoid building\nthe whole output graph (which may be huge when for\nexample the interpretation graph is composed with the\ngrammar graph). We only instantiate the nodes which are\nvisited by the search algorithm during recognition (e.g.,\nViterbi). This strategy propagates the beneﬁts of pruning\nalgorithms (e.g., beam search) in all the GTN’s.\nD. Notes on the Graph Structures\nSection VI discussed the idea of global training by back-\npropagating gradient through simple GT’s. The bprop\nmethod is the basis of the back-propagation algorithm for\ngeneric GT’s. A generalized composition transformer can\nbe seen as dynamically establishing functional relation-\nships between the numerical quantities on the input and\noutput arcs. Once the check function has decided that a\nrelationship should be established, the fprop function im-\nplements the numerical relationship. The check function\nestablishes the structure of the ephemeral network inside\nthe composition transformer.\nSince fprop is assumed to be differentiable, gradients\ncan be back propagated through that structure. Most param-\neters affect the scores stored on the arcs of the successive\ngraphs of the system. A few threshold parameters may\ndetermine whether an arc appears or not in the graph.\nSince nonexisting arcs are equivalent to arcs with very large\npenalties, we only consider the case of parameters affecting\nthe penalties.\nIn the kind of systems we have discussed until now\n(and the application described in Section X), much of the\nknowledge about the structure of the graph that is produced\nby a GT is determined by the nature of the GT, but it may\nalso depend on the value of the parameters and on the input.\nIt may also be interesting to consider GT modules which\nattempt to learn the structure of the output graph. This might\nbe considered a combinatorial problem and not amenable\nto gradient-based learning, but a solution to this problem is\nto generate a large graph that contains the graph candidates\nas subgraphs, and then select the appropriate subgraph.\nE. GTN and HMM’s\nGTN’s can be seen as a generalization and an extension\nof HMM’s. On the one hand, the probabilistic interpretation\ncan be either kept (with penalties being log-probabilities),\npushed to the ﬁnal decision stage (with the difference of\nthe constrained forward penalty and the unconstrained for-\nward penalty being interpreted as negative log-probabilities\nof label sequences), or dropped altogether (the network\njust represents a decision surface for label sequences in\ninput space). On the other hand, GTN’s extend HMM’s\nby allowing to combine in a well-principled framework\nmultiple levels of processing, or multiple models (e.g.,\nPereira et al. have been using the transducer framework for\nstacking HMM’s representing different levels of processing\nin automatic speech recognition [86]).\nUnfolding an HMM in time yields a graph that is very\nsimilar to our interpretation graph (at the ﬁnal stage of\nprocessing of the GTN, before Viterbi recognition). It has\nnodes\nassociated to each time step\nand state\nin the\nmodel. The penalty\nfor an arc from\nto\nthen corresponds to the negative log-probability of emitting\nobserved data\nat position\nand going from state\nto\nstate\nin the time interval\nWith this probabilistic\ninterpretation, the forward penalty is the negative logarithm\nof the likelihood of whole observed data sequence (given\nthe model).\nIn Section VI we mentioned that the collapsing phe-\nnomenon can occur when nondiscriminative loss functions\nare used to train NN’s/HMM hybrid systems. With classi-\ncal HMM’s with ﬁxed preprocessing, this problem does\nnot occur because the parameters of the emission and\ntransition probability models are forced to satisfy certain\nprobabilistic constraints: the sum or the integral of the\nprobabilities of a random variable over its possible values\nmust be one. Therefore, when the probability of certain\nevents is increased, the probability of other events must\nautomatically be decreased. On the other hand, if the\nprobabilistic assumptions in an HMM (or other probabilistic\nmodel) are not realistic, discriminative training, discussed\nin Section VI, can improve performance as this has been\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2311\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nclearly shown for speech recognition systems [48]–[50],\n[107], [108].\nThe input–output HMM (IOHMM) [105], [109] is\nstrongly related to GT’s. Viewed as a probabilistic model,\nan IOHMM represents the conditional distribution of\noutput sequences given input sequences (of the same or\na different length). It is parameterized from an emission\nprobability module and a transition probability module.\nThe emission probability module computes the conditional\nemission probability of an output variable (given an\ninput value and the value of discrete “state” variable).\nThe transition probability module computes conditional\ntransition probabilities of a change in the value of the\n“state” variable, given the input value. Viewed as a GT,\nit assigns an output graph (representing a probability\ndistribution over the sequences of the output variable)\nto each path in the input graph. All these output graphs\nhave the same structure, and the penalties on their arcs are\nsimply added in order to obtain the complete output graph.\nThe input values of the emission and transition modules are\nread off the data structure on the input arcs of the IOHMM\nGT. In practice, the output graph may be very large, and\nneeds not be completely instantiated (i.e., it is pruned: only\nthe low penalty paths are created).\nIX.\nAN ON-LINE HANDWRITING RECOGNITION SYSTEM\nNatural handwriting is often a mixture of different\n“styles,” i.e., lower case printed, upper case, and cursive.\nA reliable recognizer for such handwriting would greatly\nimprove interaction with pen-based devices, but its imple-\nmentation presents new technical challenges. Characters\ntaken in isolation can be very ambiguous, but considerable\ninformation is available from the context of the whole word.\nWe have built a word recognition system for pen-based\ndevices based on four main modules: 1) a preprocessor that\nnormalizes a word, or word group, by ﬁtting a geometrical\nmodel to the word structure; 2) a module that produces an\n“annotated image” from the normalized pen trajectory; 3)\na replicated convolutional NN that spots and recognizes\ncharacters; and 4) a GTN that interprets the networks\noutput by taking word-level constraints into account. The\nnetwork and the GTN are jointly trained to minimize an\nerror measure deﬁned at the word level.\nIn this work, we have compared a system based on\nSDNN’s (such as described in Section VII), and a system\nbased on HOS (such as described in Section V). Because of\nthe sequential nature of the information in the pen trajectory\n(which reveals more information than the purely optical in-\nput from in image), HOS can be very efﬁcient in proposing\ncandidate character cuts, especially for noncursive script.\nA. Preprocessing\nInput normalization reduces intracharacter variability,\nthereby simplifying character recognition. We have used\na word normalization scheme [92] based on ﬁtting a geo-\nmetrical model of the word structure. Our model has four\n“ﬂexible” lines representing respectively the ascenders line,\nFig. 30.\nAn online handwriting recognition GTN based on HOS.\nthe core line, the base line, and the descenders line. The\nlines are ﬁtted to local minima or maxima of the pen\ntrajectory. The parameters of the lines are estimated with\na modiﬁed version of the EM algorithm to maximize the\njoint probability of observed points and parameter values,\nusing a prior on parameters that prevents the lines from\ncollapsing on each other.\nThe recognition of handwritten characters from a pen\ntrajectory on a digitizing surface is often done in the\ntime domain [44], [110], [111]. Typically, trajectories are\nnormalized and local geometrical or dynamical features are\nextracted. The recognition may then be performed using\ncurve matching [110], or other classiﬁcation techniques\nsuch as TDNN’s [44], [111]. While these representations\nhave several advantages, their dependence on stroke order-\ning and individual writing styles makes them difﬁcult to use\nin high accuracy, writer independent systems that integrate\nthe segmentation with the recognition.\nSince the intent of the writer is to produce a legible\nimage, it seems natural to preserve as much of the pictorial\nnature of the signal as possible, while at the same time\nexploit the sequential information in the trajectory. For this\npurpose we have designed a representation scheme called\nAMAP [38], where pen trajectories are represented by low-\nresolution images in which each picture element contains\ninformation about the local properties of the trajectory. An\nAMAP can be viewed as an “annotated image” in which\neach pixel is a ﬁve-element feature vector: four features are\nassociated to four orientations of the pen trajectory in the\n2312\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 31.\nAn online handwriting recognition GTN based on\nSDNN.\narea around the pixel and the ﬁfth one is associated to local\ncurvature in the area around the pixel. A particularly useful\nfeature of the AMAP representation is that it makes very\nfew assumptions about the nature of the input trajectory.\nIt does not depend on stroke ordering or writing speed,\nand it can be used with all types of handwriting (capital,\nlower case, cursive, punctuation, symbols). Unlike many\nother representations (such as global features), AMAP’s\ncan be computed for complete words without requiring\nsegmentation.\nB. Network Architecture\nOne of the best networks we found for both online and\nofﬂine character recognition is a ﬁve-layer convolutional\nnetwork somewhat similar to LeNet-5 (Fig. 2), but with\nmultiple input planes and different numbers of units on\nthe last two layers—layer one: convolution with eight\nkernels of size 3 3; layer two: 2 2 subsampling; layer\nthree: convolution with 25 kernels of size 5 5; layer\nfour: convolution with 84 kernels of size 4 4; layer ﬁve:\n2 1 subsampling; classiﬁcation layer: 95 RBF units (one\nper class in the full printable ASCII set). The distributed\ncodes on the output are the same as for LeNet-5, except\nthey are adaptive unlike with LeNet-5. When used in the\nHOS system, the input to above network consisted of\nan AMAP with ﬁve planes, 20 rows, and 18 columns.\nIt was determined that this resolution was sufﬁcient for\nrepresenting handwritten characters. In the SDNN version,\nthe number of columns was varied according to the width\nof the input word. Once the number of subsampling layers\nand the sizes of the kernels are chosen, the sizes of all the\nlayers, including the input, are determined unambiguously.\nThe only architectural parameters that remain to be selected\nare the number of feature maps in each layer and the infor-\nmation as to what feature map is connected to what other\nfeature map. In our case, the subsampling rates were chosen\nas small as possible (2 2) and the kernels as small as\npossible in the ﬁrst layer (3 3) to limit the total number of\nconnections. Kernel sizes in the upper layers are chosen to\nbe as small as possible while satisfying the size constraints\nmentioned above. Larger architectures did not necessarily\nperform better and required considerably more time to\nbe trained. A very small architecture with half the input\nﬁeld also performed worse because of insufﬁcient input\nresolution. Note that the input resolution is nonetheless\nmuch less than for OCR because the angle and curvature\nprovide more information than would a single grey level\nat each pixel.\nC. Network Training\nTraining proceeded in two phases. First, we kept the\ncenters of the RBF’s ﬁxed and trained the network weights\nso as to minimize the output distance of the RBF unit\ncorresponding to the correct class. This is equivalent to\nminimizing the MSE between the previous layer and the\ncenter of the correct-class RBF. This bootstrap phase was\nperformed on isolated characters. In the second phase, all\nthe parameters, network weights, and RBF centers were\ntrained globally to minimize a discriminative criterion at\nthe word level.\nWith the HOS approach, the GTN was composed of four\nmain GT’s.\n1) The segmentation transformer performs the HOS and\noutputs the segmentation graph. An AMAP is then\ncomputed for each image attached to the arcs of this\ngraph.\n2) The character recognition transformer applies the\nconvolutional network character recognizer to each\ncandidate segment and outputs the recognition graph\nwith penalties and classes on each arc.\n3) The composition transformer composes the recog-\nnition graph with a grammar graph representing a\nlanguage model incorporating lexical constraints.\n4) The beam search transformer extracts a good in-\nterpretation from the interpretation graph. This task\ncould have been achieved with the usual Viterbi\nTransformer. The beam search algorithm, however,\nimplements pruning strategies which are appropriate\nfor large interpretation graphs.\nWith the SDNN approach, the main GT’s are the fol-\nlowing.\n1) The SDNN transformer replicates the convolutional\nnetwork over the a whole word image and outputs\na recognition graph that is a linear graph with class\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2313\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 32.\nComparative results (character error rates) showing the improvement brought by global\ntraining on the SDNN/HMM hybrid, and on the HOS, without and with a 25 461-word dictionary.\npenalties for every window centered at regular inter-\nvals on the input image.\n2) The character-level composition transformer com-\nposes the recognition graph with a left-to-right HMM\nfor each character class (as in Fig. 27).\n3) The word-level composition transformer composes\nthe output of the previous transformer with a language\nmodel incorporating lexical constraints and outputs\nthe interpretation graph.\n4) The beam search transformer extracts a good inter-\npretation from the interpretation graph.\nIn this application, the language model simply constrains\nthe ﬁnal output graph to represent sequences of character\nlabels from a given dictionary. Furthermore, the interpreta-\ntion graph is not actually completely instantiated: the only\nnodes created are those that are needed by the beam search\nmodule. The interpretation graph is therefore represented\nprocedurally rather than explicitly.\nA crucial contribution of this research was the joint\ntraining of all GT modules within the network with respect\nto a single criterion, as explained in Sections VI and\nVII. We used the discriminative forward loss function on\nthe ﬁnal output graph: minimize the forward penalty of\nthe constrained interpretation (i.e., along all the “correct”\npaths) while maximizing the forward penalty of the whole\ninterpretation graph (i.e., along all the paths).\nDuring global training, the loss function was optimized\nwith the stochastic diagonal Levenberg–Marquardt proce-\ndure described in Appendix C, which uses second deriva-\ntives to compute optimal learning rates. This optimization\noperates on all the parameters in the system, most notably\nthe network weights and the RBF centers.\nD. Experimental Results\nIn the ﬁrst set of experiments, we evaluated the gen-\neralization ability of the NN classiﬁer coupled with the\nword normalization preprocessing and AMAP input rep-\nresentation. All results are in writer independent mode\n(different writers in training and testing). Initial training\non isolated characters was performed on a database of\napproximately 100 000 hand printed characters (95 classes\nof upper case, lower case, digits, and punctuation). Tests on\na database of isolated characters were performed separately\non the four types of characters: upper case (2.99% error on\n9122 patterns), lower case (4.15% error on 8201 patterns),\ndigits (1.4% error on 2938 patterns), and punctuation (4.3%\nerror on 881 patterns). Experiments were performed with\nthe network architecture described above. To enhance the\nrobustness of the recognizer to variations in position, size,\norientation, and other distortions, additional training data\nwas generated by applying local afﬁne transformations to\nthe original characters.\nThe second and third set of experiments concerned the\nrecognition of lower case words (writer independent). The\ntests were performed on a database of 881 words. First we\nevaluated the improvements brought by the word normal-\nization to the system. For the SDNN/HMM system we have\nto use word-level normalization since the network sees one\nwhole word at a time. With the HOS system, and before\ndoing any word-level training, we obtained with character-\nlevel normalization 7.3% and 3.5% word and character\nerrors (adding insertions, deletions and substitutions) when\nthe search was constrained within a 25 461-word dictionary.\nWhen using the word normalization preprocessing instead\nof a character level normalization, error rates dropped to\n4.6% and 2.0% for word and character errors respectively,\ni.e., a relative drop of 37% and 43% in word and character\nerror respectively. This suggests that normalizing the word\nin its entirety is better than ﬁrst segmenting it and then\nnormalizing and processing each of the segments.\nIn the third set of experiments, we measured the im-\nprovements obtained with the joint training of the NN\nand the postprocessor with the word-level criterion, in\ncomparison to training based only on the errors performed\nat the character level. After initial training on individual\ncharacters as above, global word-level discriminative train-\ning was performed with a database of 3500 lower case\nwords. For the SDNN/HMM system, without any dictionary\nconstraints, the error rates dropped from 38% and 12.4%\nword and character error to 26% and 8.2% respectively after\nword-level training, i.e., a relative drop of 32% and 34%.\n2314\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFor the HOS system and a slightly improved architecture,\nwithout any dictionary constraints, the error rates dropped\nfrom 22.5% and 8.5% word and character error to 17% and\n6.3% respectively, i.e., a relative drop of 24.4% and 25.6%.\nWith a 25 461-word dictionary, errors dropped from 4.6%\nand 2.0% word and character errors to 3.2% and 1.4%,\nrespectively, after word-level training, i.e., a relative drop\nof 30.4% and 30.0%. Even lower error rates can be obtained\nby drastically reducing the size of the dictionary to 350\nwords, yielding 1.6% and 0.94% word and character errors.\nThese results clearly demonstrate the usefulness of glob-\nally trained NN/HMM hybrids for handwriting recognition.\nThis conﬁrms similar results obtained earlier in speech\nrecognition [77].\nX.\nA CHECK READING SYSTEM\nThis section describes a GTN based check reading sys-\ntem, intended for immediate industrial deployment. It also\nshows how the use of gradient based-learning and GTN’s\nmake this deployment fast and cost-effective while yielding\nan accurate and reliable solution.\nThe veriﬁcation of the amount on a check is a task that\nis extremely time and money consuming for banks. As\na consequence, there is a very high interest in automat-\ning the process as much as possible (see, for example,\n[112]–[114]). Even a partial automation would result in\nconsiderable cost reductions. The threshold of economic\nviability for automatic check readers, as set by the bank,\nis when 50% of the checks are read with less than 1%\nerror. The other 50% of the check being rejected and\nsent to human operators. In such a case, we describe the\nperformance of the system as 50% correct/49% reject/1%\nerror. The system presented here was one of the ﬁrst to\ncross that threshold on representative mixtures of business\nand personal checks.\nChecks contain at least two versions of the amount. The\ncourtesy amount is written with numerals, while the legal\namount is written with letters. On business checks, which\nare generally machine-printed, these amounts are relatively\neasy to read but quite difﬁcult to ﬁnd due to the lack of\nstandard for business check layout. On the other hand, these\namounts on personal checks are easy to ﬁnd but much\nharder to read.\nFor simplicity (and speed requirements), our initial task\nis to read the courtesy amount only. This task consists of\ntwo main steps.\n1) The system has to ﬁnd, among all the ﬁelds (lines\nof text), the candidates that are the most likely to\ncontain the courtesy amount. This is obvious for many\npersonal checks, where the position of the amount\nis standardized. However, as already noted, ﬁnding\nthe amount can be rather difﬁcult in business checks,\neven for the human eye. There are many strings of\ndigits, such as the check number, the date, or even\n“not to exceed” amounts, that can be confused with\nthe actual amount. In many cases, it is very difﬁcult to\ndecide which candidate is the courtesy amount before\nperforming a full recognition.\nFig. 33.\nA complete check amount reader implemented as a\nsingle cascade of GT modules. Successive graph transformations\nprogressively extract higher level information.\n2) In order to read (and choose) some courtesy amount\ncandidates, the system has to segment the ﬁelds into\ncharacters, read and score the candidate characters,\nand ﬁnally ﬁnd the best interpretation of the amount\nusing contextual knowledge represented by a stochas-\ntic grammar for check amounts.\nThe GTN methodology was used to build a check amount\nreading system that handles both personal checks and\nbusiness checks.\nA. A GTN for Check Amount Recognition\nWe now describe the successive graph transformations\nthat allow this network to read the check amount (cf.\nFig. 33). Each GT produces a graph whose paths encode\nand score the current hypotheses considered at this stage\nof the system.\nThe input to the system is a trivial graph with a single\narc that carries the image of the whole check (cf. Fig. 33).\n1) The Field Location Transformer:\nﬁrst performs\nclassical image analysis (including connected component\nanalysis, ink density histograms, layout analysis, etc.) and\nheuristically extracts rectangular zones that may contain the\ncheck amount.\nproduces an output graph, called the\nﬁeld graph (cf. Fig. 33) such that each candidate zone is\nassociated with one arc that links the start node to the\nend node. Each arc contains the image of the zone and\na penalty term computed from simple features extracted\nfrom the zone (absolute position, size, aspect ratio, etc.).\nThe penalty term is close to zero if the features suggest\nthat the ﬁeld is a likely candidate and is large if the ﬁeld is\ndeemed less likely to be an amount. The penalty function is\ndifferentiable, therefore its parameters are globally tunable.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2315\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nAn arc may represent separate dollar and cent amounts\nas a sequence of ﬁelds. In fact, in handwritten checks, the\ncent amount may be written over a fractional bar and not\naligned at all with the dollar amount. In the worst case, one\nmay ﬁnd several cent amount candidates (above and below\nthe fraction bar) for the same dollar amount.\n2) The Segmentation Transformer:\nsimilar to the\none\ndescribed\nin\nSection VIII,\nexamines\neach\nzone\ncontained in the ﬁeld graph and cuts each image into\npieces of ink using heuristic image processing techniques.\nEach piece of ink may be a whole character or a piece\nof character. Each arc in the ﬁeld graph is replaced by\nits corresponding segmentation graph that represents all\npossible groupings of pieces of ink. Each ﬁeld segmentation\ngraph is appended to an arc that contains the penalty of the\nﬁeld in the ﬁeld graph. Each arc carries the segment image,\ntogether with a penalty that provides a ﬁrst evaluation\nof the likelihood that the segment actually contains a\ncharacter. This penalty is obtained with a differentiable\nfunction that combines a few simple features such as\nthe space between the pieces of ink or the compliance\nof the segment image with a global baseline, and a few\ntunable parameters. The segmentation graph represents all\nthe possible segmentations of all the ﬁeld images. We can\ncompute the penalty for one segmented ﬁeld by adding\nthe arc penalties along the corresponding path. As before,\nusing a differentiable function for computing the penalties\nwill ensure that the parameters can be optimized globally.\nThe segmenter uses a variety of heuristics to ﬁnd candi-\ndate cut. One of the most important ones is called “hit and\ndeﬂect” [115]. The idea is to cast lines downward from the\ntop of the ﬁeld image. When a line hits a black pixel, it is\ndeﬂected so as to follow the contour of the object. When a\nline hits a local minimum of the upper proﬁle, i.e., when it\ncannot continue downward without crossing a black pixel,\nit is just propagated vertically downward through the ink.\nWhen two such lines meet each other, they are merged\ninto a single cut. The procedure can be repeated from the\nbottom up. This strategy allows the separation of touching\ncharacters such as double zeros.\n3) The Recognition Transformer:\niterates over all\nsegment arcs in the segmentation graph and runs a character\nrecognizer on the corresponding segment image. In our\ncase, the recognizer is LeNet-5, the convolutional NN\ndescribed in Section II, whose weights constitute the largest\nand most important subset of tunable parameters. The\nrecognizer classiﬁes segment images into one of 95 classes\n(fully printable ASCII set) plus a rubbish class for unknown\nsymbols or badly formed characters. Each arc in the input\ngraph\nis replaced by 96 arcs in the output graph.\nEach of those 96 arcs contains the label of one of the\nclasses, and a penalty that is the sum of the penalty of\nthe corresponding arc in the input (segmentation) graph,\nand the penalty associated with classifying the image in\nthe corresponding class, as computed by the recognizer. In\nother words, the recognition graph represents a weighted\ntrellis of scored character classes. Each path in this graph\nrepresents a possible character string for the corresponding\nﬁeld. We can compute a penalty for this interpretation\nby adding the penalties along the path. This sequence of\ncharacters may or may not be a valid check amount.\n4) The Composition Transformer:\nselects the paths\nof the recognition graph that represent valid character\nsequences for check amounts. This transformer takes two\ngraphs as input: the recognition graph and the grammar\ngraph. The grammar graph contains all possible sequences\nof symbols that constitute a well-formed amount. The out-\nput of the composition transformer, called the interpretation\ngraph, contains all the paths in the recognition graph that are\ncompatible with the grammar. The operation that combines\nthe two input graphs to produce the output is a generalized\ntransduction (see Section IX). A differentiable function is\nused to compute the data attached to the output arc from\nthe data attached to the input arcs. In our case, the output\narc receives the class label of the two arcs and a penalty\ncomputed by simply summing the penalties of the two\ninput arcs (the recognizer penalty and the arc penalty in\nthe grammar graph). Each path in the interpretation graph\nrepresents one interpretation of one segmentation of one\nﬁeld on the check. The sum of the penalties along the path\nrepresents the “badness” of the corresponding interpretation\nand combines evidence from each of the modules along the\nprocess, as well as from the grammar.\n5) The Viterbi Transformer: The Viterbi transformer ﬁ-\nnally selects the path with the lowest accumulated penalty\ncorresponding to the best grammatically correct interpreta-\ntions.\nB. Gradient-Based Learning\nEach stage of this check reading system contains tunable\nparameters. While some of these parameters could be\nmanually adjusted (e.g., the parameters of the ﬁeld locator\nand segmenter), the vast majority of them must be learned,\nparticularly the weights of the NN recognizer.\nPrior to globally optimizing the system, each module pa-\nrameters are initialized with reasonable values. The param-\neters of the ﬁeld locator and the segmenter are initialized by\nhand, while the parameters of the NN character recognizer\nare initialized by training on a database of presegmented\nand labeled characters. Then, the entire system is trained\nglobally from whole check images labeled with the correct\namount. No explicit segmentation of the amounts is needed\nto train the system: it is trained at the check level.\nThe loss function\nminimized by our global training\nprocedure is the discriminative forward criterion described\nin Section VI: the difference between 1) the forward penalty\nof the constrained interpretation graph (constrained by the\ncorrect label sequence) and 2) the forward penalty of the\nunconstrained interpretation graph. Derivatives can be back\npropagated through the entire structure, although it is only\npractical to do it down to the segmenter.\nC. Rejecting Low Conﬁdence Checks\nIn order to be able to reject checks which are the\nmost likely to carry erroneous Viterbi answers, we must\nrate them with a conﬁdence and reject the check if this\n2316\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nFig. 34.\nAdditional processing required to compute the conﬁ-\ndence.\nconﬁdence is below a given threshold. To compare the\nunnormalized Viterbi penalties of two different checks\nwould be meaningless when it comes to decide which\nanswer we trust the most.\nThe optimal measure of conﬁdence is the probability\nof the Viterbi answer given the input image. As seen\nin Section VI-E, given a target sequence (which, in this\ncase, would be the Viterbi answer), the discriminative\nforward loss function is an estimate of the logarithm of\nthis probability. Therefore, a simple solution to obtain a\ngood estimate of the conﬁdence is to reuse the interpretation\ngraph (see Fig. 33) to compute the discriminative forward\nloss as described in Fig. 21, using as our desired sequence\nthe Viterbi answer. This is summarized in Fig. 34, with\nD. Results\nA version of the above system was fully implemented\nand tested on machine-print business checks. This system is\nbasically a generic GTN engine with task speciﬁc heuristics\nencapsulated in the check and fprop method. As a con-\nsequence, the amount of code to write was minimal: mostly\nthe adaptation of an earlier segmenter into the segmentation\ntransformer. The system that deals with handwritten or\npersonal checks was based on earlier implementations that\nused the GTN concept in a restricted way.\nThe NN classiﬁer was initially trained on 500 000 images\nof character images from various origins spanning the entire\nprintable ASCII set. This contained both handwritten and\nmachine-printed characters that had been previously size\nnormalized at the string level. Additional images were\ngenerated by randomly distorting the original images using\nsimple afﬁne transformations of the images. The network\nwas then further trained on character images that had been\nautomatically segmented from check images and manually\ntruthed. The network was also initially trained to reject\nnoncharacters that resulted from segmentation errors. The\nrecognizer was then inserted in the check-reading system\nand a small subset of the parameters were trained globally\n(at the ﬁeld level) on whole check images.\nOn 646 business checks that were automatically cat-\negorized as machine printed, the performance was 82%\ncorrectly recognized checks, 1% errors, and 17% rejects.\nThis can be compared to the performance of the previous\nsystem on the same test set: 68% correct, 1% errors, and\n31% rejects. A check is categorized as machine-printed\nwhen characters that are near a standard position dollar\nsign are detected as machine printed, or when, if nothing is\nfound in the standard position, at least one courtesy amount\ncandidate is found somewhere else. The improvement is\nattributed to three main causes. First the NN recognizer\nwas bigger and trained on more data. Second, because of\nthe GTN architecture, the new system could take advantage\nof grammatical constraints in a much more efﬁcient way\nthan the previous system. Third, the GTN architecture\nprovided extreme ﬂexibility for testing heuristics, adjusting\nparameters, and tuning the system. This last point is more\nimportant than it seems. The GTN framework separates\nthe “algorithmic” part of the system from the “knowledge-\nbased” part of the system, allowing easy adjustments of the\nlatter. The importance of global training was only minor\nin this task because the global training only concerned a\nsmall subset of the parameters.\nAn independent test performed by systems integrators\nin 1995 showed the superiority of this system over other\ncommercial courtesy amount reading systems. The system\nwas integrated in NCR’s line of check reading systems. It\nhas been ﬁelded in several banks across the United States\nsince June 1996, and it has been reading millions of checks\nper day since then.\nXI.\nCONCLUSIONS\nDuring the short history of automatic pattern recognition,\nincreasing the role of learning seems to have invariably\nimproved the overall performance of recognition systems.\nThe systems described in this paper are more evidence to\nthis fact. Convolutional NN’s have been shown to eliminate\nthe need for hand-crafted feature extractors. GTN’s have\nbeen shown to reduce the need for hand-crafted heuristics,\nmanual labeling, and manual parameter tuning in document\nrecognition systems. As training data becomes plentiful, as\ncomputers get faster, and as our understanding of learning\nalgorithms improves, recognition systems will rely more\nand more of learning and their performance will improve.\nJust as the back-propagation algorithm elegantly solved\nthe credit assignment problem in multilayer NN’s, the\ngradient-based learning procedure for GTN’s introduced in\nthis paper solves the credit assignment problem in systems\nwhose functional architecture dynamically changes with\neach new input. The learning algorithms presented here are\nin a sense nothing more than unusual forms of gradient\ndescent in complex, dynamic architectures, with efﬁcient\nback-propagation algorithms to compute the gradient. The\nresults in this paper help establish the usefulness and\nrelevance of gradient-based minimization methods as a\ngeneral organizing principle for learning in large systems.\nIt was shown that all the steps of a document analysis\nsystem can be formulated as GT’s through which gradi-\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2317\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nents can be back propagated. Even in the nontrainable\nparts of the system, the design philosophy in terms of\ngraph transformation provides a clear separation between\ndomain-speciﬁc heuristics (e.g., segmentation heuristics)\nand generic, procedural knowledge (the generalized trans-\nduction algorithm)\nIt is worth pointing out that data generating models (such\nas HMM’s) and the maximum likelihood principle were not\ncalled upon to justify most of the architectures and the train-\ning criteria described in this paper. Gradient-based learning\napplied to global discriminative loss functions guarantees\noptimal classiﬁcation and rejection without the use of “hard\nto justify” principles that put strong constraints on the\nsystem architecture, often at the expense of performances.\nMore speciﬁcally, the methods and architectures pre-\nsented in this paper offer generic solutions to a large number\nof problems encountered in pattern recognition systems.\n1) Feature extraction is traditionally a ﬁxed transform,\nand it is generally derived from some expert prior\nknowledge about the task. This relies on the probably\nincorrect assumption that the human designer is able\nto capture all the relevant information in the input.\nWe have shown that the application of gradient-based\nlearning to convolutional NN’s allows us to learn ap-\npropriate features from examples. The success of this\napproach was demonstrated in extensive comparative\ndigit recognition experiments on the NIST database.\n2) Segmentation and recognition of objects in images\ncannot be completely decoupled. Instead of taking\nhard segmentation decisions too early, we have used\nHOS to generate and evaluate a large number of\nhypotheses in parallel, postponing any decision until\nthe overall criterion is minimized.\n3) Hand-truthing images to obtain segmented characters\nfor training a character recognizer is expensive and\ndoes not take into account the way in which a whole\ndocument or sequence of characters will be recog-\nnized (in particular, the fact that some segmentation\ncandidates may be wrong, even though they may look\nlike true characters). Instead we train multimodule\nsystems to optimize a global measure of performance,\nwhich does not require time consuming detailed hand-\ntruthing and yields signiﬁcantly better recognition\nperformance because it allows to train these modules\nto cooperate toward a common goal.\n4) Ambiguities inherent in the segmentation, character\nrecognition, and linguistic model should be inte-\ngrated optimally. Instead of using a sequence of task-\ndependent heuristics to combine these sources of in-\nformation, we have proposed a uniﬁed framework in\nwhich generalized transduction methods are applied\nto graphs representing a weighted set of hypotheses\nabout the input. The success of this approach was\ndemonstrated with a commercially deployed check-\nreading system that reads millions of business and\npersonal checks per day: the generalized transduction\nengine resides in only a few hundred lines of code.\n5) Traditional recognition systems rely on many hand-\ncrafted heuristics to isolate individually recognizable\nobjects. The promising SDNN approach draws on the\nrobustness and efﬁciency of convolutional NN’s to\navoid explicit segmentation altogether. Simultaneous\nautomatic learning of segmentation and recognition\ncan be achieved with gradient-based learning meth-\nods.\nThis paper presents a small number of examples of GT\nmodules, but it is clear that the concept can be applied to\nmany situations where the domain knowledge or the state\ninformation can be represented by graphs. This is the case\nin many audio signal recognition tasks, and visual scene\nanalysis applications. Future work will attempt to apply\nGT networks to such problems, with the hope of allowing\nmore reliance on automatic learning and less on detailed\nengineering.\nAPPENDIX A\nPRECONDITIONS FOR FASTER CONVERGENCE\nAs seen before, the squashing function used in our\nconvolutional networks is\nSymmetric\nfunctions are believed to yield faster convergence, although\nthe learning can become extremely slow if the weights\nare too small. The cause of this problem is that in weight\nspace the origin is a ﬁxed point of the learning dynamics\nand, although it is a saddle point, it is attractive in almost\nall directions [116]. For our simulations, we use\nand\n(see [20], [34]). With this choice of\nparameters, the equalities\nand\nare\nsatisﬁed. The rationale behind this is that the overall gain\nof the squashing transformation is around one in normal\noperating conditions, and the interpretation of the state of\nthe network is simpliﬁed. Moreover, the absolute value of\nthe second derivative of\nis a maximum at\n1 and\n1,\nwhich improves the convergence toward the end of the\nlearning session. This particular choice of parameters is\nmerely a convenience, and does not affect the result.\nBefore training, the weights are initialized with random\nvalues using a uniform distribution between\nand\n, where\nis the number of inputs (fan-in) of the unit\nwhich the connection belongs to. Since several connections\nshare a weight, this rule could be difﬁcult to apply, but in\nour case all connections sharing a same weight belong to\nunits with identical fan-ins. The reason for dividing by the\nfan-in is that we would like the initial standard deviation\nof the weighted sums to be in the same range for each\nunit and to fall within the normal operating region of the\nsigmoid. If the initial weights are too small, the gradients\nare very small and the learning is slow. If they are too\nlarge, the sigmoids are saturated and the gradient is also\nvery small. The standard deviation of the weighted sum\nscales like the square root of the number of inputs when\nthe inputs are independent, and it scales linearly with the\nnumber of inputs if the inputs are highly correlated. We\nchose to assume the second hypothesis since some units\nreceive highly correlated signals.\n2318\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nAPPENDIX B\nSTOCHASTIC GRADIENT VERSUS BATCH GRADIENT\nGradient-based learning algorithms can use one of two\nclasses of methods to update the parameters. The ﬁrst\nmethod, dubbed “batch gradient,” is the classical one: the\ngradients are accumulated over the entire training set, and\nthe parameters are updated after the exact gradient has\nbeen so computed. In the second method, called “stochastic\ngradient,” a partial, or noisy, gradient is evaluated on the\nbasis of one single training sample (or a small number\nof samples), and the parameters are updated using this\napproximate gradient. The training samples can be selected\nrandomly or according to a properly randomized sequence.\nIn the stochastic version the gradient estimates are noisy,\nbut the parameters are updated much more often than\nwith the batch version. An empirical result of considerable\npractical importance is that on tasks with large, redundant\ndata sets, the stochastic version is considerably faster than\nthe batch version, sometimes by orders of magnitude [117].\nAlthough the reasons for this are not totally understood\ntheoretically, an intuitive explanation can be found in the\nfollowing extreme example. Let us take an example where\nthe training database is composed of two copies of the\nsame subset. Then accumulating the gradient over the whole\nset would cause redundant computations to be performed.\nOn the other hand, running Stochastic Gradient once on\nthis training set would amount to performing two complete\nlearning iterations over the small subset. This idea can be\ngeneralized to training sets where there exist no precise\nrepetition of the same pattern but where some redundancy is\npresent. In fact stochastic update must be better when there\nis redundancy, i.e., when a certain level of generalization\nis expected.\nMany authors have claimed that second-order methods\nshould be used in lieu of gradient descent for NN training.\nThe literature abounds with recommendations [118] for\nclassical second-order methods such as the Gauss–Newton\nor Levenberg–Marquardt algorithms for quasi-Newton\nmethods\nsuch\nas\nBroyden–Fletcher–Goldfarb–Shanno,\nlimited-storage\nBroyden–Fletcher–Goldfarb–Shanno,\nor\nfor various versions of the conjugate gradients method.\nUnfortunately, all of the above methods are unsuit-\nable for training large NN’s on large data sets. The\nGauss–Newton and Levenberg–Marquardt methods require\noperations per update, where\nis the number\nof parameters, which makes them impractical for even\nmoderate size networks. Quasi-Newton methods require\n“only”\noperations per update, but that still makes\nthem impractical for large networks. Limited-storage Broy-\nden–Fletcher–Goldfarb–Shanno’s and conjugate gradients\nrequire only\noperations per update so they would\nappear appropriate. Unfortunately, their convergence speed\nrelies on an accurate evaluation of successive “conjugate\ndescent directions” which only makes sense in “batch”\nmode. For large data sets, the speed-up brought by\nthese methods over regular batch gradient descent cannot\nmatch the enormous speed up brought by the use of\nstochastic gradient. Several authors have attempted to\nuse conjugate gradient with small batches or batches of\nincreasing sizes [119], [120], but those attempts have\nnot yet been demonstrated to surpass a carefully tuned\nstochastic gradient. Our experiments were performed with\na stochastic method that scales the parameter axes so as to\nminimize the eccentricity of the error surface.\nAPPENDIX C\nSTOCHASTIC DIAGONAL LEVENBERG–MARQUARDT\nOwing to the reasons given in Appendix B, we prefer\nto update the weights after each presentation of a single\npattern in accordance with stochastic update methods. The\npatterns are presented in a constant random order, and the\ntraining set is typically repeated 20 times.\nOur update algorithm is dubbed the stochastic diagonal\nLevenberg–Marquardt method where an individual learning\nrate (step size) is computed for each parameter (weight)\nbefore each pass through the training set [20], [34], [121].\nThese learning rates are computed using the diagonal terms\nof an estimate of the Gauss–Newton approximation to\nthe Hessian (second derivative) matrix. This algorithm is\nnot believed to bring a tremendous increase in learning\nspeed but it converges reliably without requiring extensive\nadjustments of the learning parameters. It corrects major\nill-conditioning of the loss function that are due to the\npeculiarities of the network architecture and the training\ndata. The additional cost of using this procedure over\nstandard stochastic gradient descent is negligible.\nAt each learning iteration a particular parameter\nis\nupdated according to the following stochastic update rule:\n(18)\nwhere\nis the instantaneous loss function for pattern\nIn convolutional NN’s, because of the weight sharing,\nthe partial derivative\nis the sum of the partial\nderivatives with respect to the connections that share the\nparameter\n(19)\nwhere\nis the connection weight from unit\nto unit\nis the set of unit index pairs\nsuch that the connection\nbetween\nand\nshare the parameter\ni.e.,\n(20)\nAs stated previously, the step sizes\nare not constant but\nare function of the second derivative of the loss function\nalong the axis\n(21)\nwhere\nis a hand-picked constant and\nis an estimate\nof the second derivative of the loss function\nwith respect\nto\nThe larger\nis, the smaller the weight update.\nThe parameter\nprevents the step size from becoming too\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2319\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nlarge when the second derivative is small, very much like\nthe “model-trust” methods, and the Levenberg–Marquardt\nmethods in nonlinear optimization [8]. The exact formula\nto compute\nfrom the second derivatives with respect\nto the connection weights is\n(22)\nHowever, we make three approximations. The ﬁrst approx-\nimation is to drop the off-diagonal terms of the Hessian\nwith respect to the connection weights in (22)\n(23)\nNaturally, the terms\nare the average over the\ntraining set of the local second derivatives\n(24)\nThose local second derivatives with respect to connection\nweights can be computed from local second derivatives with\nrespect to the total input of the downstream unit\n(25)\nwhere\nis the state of unit\nand\nis the second\nderivative of the instantaneous loss function with respect to\nthe total input to unit\n(denoted\nInterestingly, there is\nan efﬁcient algorithm to compute those second derivatives\nwhich is very similar to the back-propagation procedure\nused to compute the ﬁrst derivatives [20], [21]\n(26)\nUnfortunately, using those derivatives leads to well-known\nproblems associated with every Newton-like algorithm:\nthese terms can be negative and can cause the gradient\nalgorithm to move uphill instead of downhill. Therefore,\nour second approximation is a well-known trick called\nthe Gauss–Newton approximation, which guarantees that\nthe second derivative estimates are nonnegative. The\nGauss–Newton\napproximation\nessentially\nignores\nthe\nnonlinearity of the estimated function (the NN, in our case),\nbut not that of the loss function. The back propagation\nequation for Gauss-Newton approximations of the second\nderivatives is\n(27)\nThis is very similar to the formula for back propagating the\nﬁrst derivatives, except that the sigmoid’s derivative and\nthe weight values are squared. The right-hand side is a sum\nof products of nonnegative terms, therefore the left-hand\nside term is nonnegative.\nThe third approximation we make is that we do not run\nthe average in (24) over the entire training set, but run it\non a small subset of the training set instead. In addition\nthe re-estimation does not need to be done often since the\nsecond-order properties of the error surface change rather\nslowly. In the experiments described in this paper, we re-\nestimate the\non 500 patterns before each training pass\nthrough the training set. Since the size of the training set\nis 60 000, the additional cost of re-estimating the\nis\nnegligible. The estimates are not particularly sensitive to the\nparticular subset of the training set used in the averaging.\nThis seems to suggest that the second-order properties of\nthe error surface are mainly determined by the structure\nof the network, rather than by the detailed statistics of the\nsamples. This algorithm is particularly useful for shared-\nweight networks because the weight sharing creates ill\nconditioning of the error surface. Because of the sharing,\none single parameter in the ﬁrst few layers can have\nan enormous inﬂuence on the output. Consequently, the\nsecond derivative of the error with respect to this parameter\nmay be very large, while it can be quite small for other\nparameters elsewhere in the network. The above algorithm\ncompensates for that phenomenon.\nUnlike most other second-order acceleration methods for\nback-propagation, the above method works in stochastic\nmode. It uses a diagonal approximation of the Hessian.\nLike the classical Levenberg–Marquardt algorithm, it uses\na “safety” factor\nto prevent the step sizes from getting\ntoo large if the second derivative estimates are small.\nHence the method is called the stochastic diagonal Lev-\nenberg–Marquardt method.\nACKNOWLEDGMENT\nSome of the systems described in this paper are the work\nof many researchers now at AT&T and Lucent Technolo-\ngies. In particular, C. Burges, C. Nohl, T. Cauble, and J.\nBromley contributed much to the check reading system.\nExperimental results described in Section III include con-\ntributions by C. Burges, A. Brunot, C. Cortes, H. Drucker,\nL. Jackel, U. M¨uller, B. Sch¨olkopf, and P. Simard. The\nauthors wish to thank F. Pereira, V. Vapnik, J. Denker, and\nI. Guyon for helpful discussions, C. Stenard and R. Higgins\nfor providing the applications that motivated some of this\nwork, and L. R. Rabiner and L. D. Jackel for relentless\nsupport and encouragement.\nREFERENCES\n[1] R. O. Duda and P. E. Hart, Pattern Classiﬁcation and Scene\nAnalysis.\nNew York: Wiley, 1973.\n[2] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard,\nW. Hubbard, and L. D. Jackel, “Backpropagation applied to\nhandwritten zip code recognition,” Neural Computation, vol. 1,\nno. 4, pp. 541–551, Winter 1989.\n[3] S. Seung, H. Sompolinsky, and N. Tishby, “Statistical mechan-\nics of learning from examples,” Phys. Rev. A, vol. 45, pp.\n6056–6091, 1992.\n[4] V. N. Vapnik, E. Levin, and Y. LeCun, “Measuring the vc-\ndimension of a learning machine,” Neural Computation, vol. 6,\nno. 5, pp. 851–876, 1994.\n[5] C. Cortes, L. Jackel, S. Solla, V. N. Vapnik, and J. Denker,\n“Learning curves: Asymptotic values and rate of convergence,”\n2320\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nin Advances in Neural Information Processing Systems 6, J. D.\nCowan, G. Tesauro, and J. Alspector, Eds.\nSan Mateo, CA:\nMorgan Kaufmann, 1994, pp. 327–334.\n[6] V. N. Vapnik, The Nature of Statistical Learning Theory.\nNew\nYork: Springer, 1995.\n[7]\n, Statistical Learning Theory.\nNew York: Wiley, 1998.\n[8] W. H. Press, B. P. Flannery, S. A. Teukolsky, and W. T.\nVetterling, Numerical Recipes: The Art of Scientiﬁc Computing.\nCambridge, UK: Cambridge Univ., 1986.\n[9] S. I. Amari, “A theory of adaptive pattern classiﬁers,” IEEE\nTrans. Electron. Comput., vol. EC-16, pp. 299–307, 1967.\n[10] Y. Tsypkin, Adaptation and Learning in Automatic Systems\nNew York: Academic, 1971.\n[11]\n, Foundations of the Theory of Learning Systems.\nNew\nYork: Academic, 1973.\n[12] M. Minsky and O. Selfridge, “Learning in random nets,” in\nProc. 4th London Symp. Information Theory, pp. 335–347, 1961.\n[13] D. H. Ackley, G. E. Hinton, and T. J. Sejnowski, “A learning\nalgorithm for Boltzmann machines,” Cognitive Sci., vol. 9, pp.\n147–169, 1985.\n[14] G. E. Hinton and T. J. Sejnowski, “Learning and relearning\nin Boltzmann machines,” in Parallel Distributed Processing:\nExplorations in the Microstructure of Cognition. Volume 1:\nFoundations, D. E. Rumelhart and J. L. McClelland, Eds.\nCambridge, MA: MIT, 1986.\n[15] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, “Learn-\ning internal representations by error propagation,” in Parallel\nDistributed Processing: Explorations in the Microstructure of\nCognition, vol. I.\nCambridge, MA: Bradford Books, 1986,\npp. 318–362,\n[16] A. E. Bryson, Jr. and Y.-C. Ho, Applied Optimal Control.\nLondon, UK: Blaisdell, 1969.\n[17] Y. LeCun, “A learning scheme for asymmetric threshold\nnetworks,” in Proc. Cognitiva ’85, Paris, France, 1985, pp.\n599–604.\n[18]\n, “Learning processes in an asymmetric threshold net-\nwork,” in Disordered Systems and Biological Organization, E.\nBienenstock, F. Fogelman-Souli¨e, and G. Weisbuch, Eds.\nLes\nHouches, France: Springer-Verlag, 1986, pp. 233–240.\n[19] D. B. Parker, “Learning-logic,” Sloan School Manage., MIT,\nCambridge, MA, Tech. Rep., TR-47, Apr. 1985.\n[20] Y. LeCun, Mod´eles Connexionnistes de l’Apprentissage (Con-\nnectionist Learning Models), Ph.D. dissertation, Universit´e P.\net M. Curie (Paris 6), June 1987.\n[21]\n, “A theoretical framework for back-propagation,” in Proc.\n1988 Connectionist Models Summer School, D. Touretzky, G.\nHinton, and T. Sejnowski, Eds.\nPittsburgh, PA: CMU, Morgan\nKaufmann, 1988, pp. 21–28.\n[22] L. Bottou and P. Gallinari, “A framework for the cooperation\nof learning algorithms,” in Advances in Neural Information\nProcessing Systems, vol. 3, D. Touretzky and R. Lippmann,\nEds.\nDenver, CO: Morgan Kaufmann, 1991.\n[23] C. Y. Suen, C. Nadal, R. Legault, T. A. Mai, and L. Lam,\n“Computer recognition of unconstrained handwritten numerals,”\nProc. IEEE, vol. 80, pp. 1162–1180, July 1992.\n[24] S. N. Srihari, “High-performance reading machines,” Proc.\nIEEE., vol. 80, pp. 1120–1132, July 1992.\n[25] Y. LeCun, L. D. Jackel, B. Boser, J. S. Denker, H. P. Graf,\nI. Guyon, D. Henderson, R. E. Howard, and W. Hubbard,\n“Handwritten digit recognition: Applications of neural net chips\nand automatic learning,” IEEE Trans. Commun., vol. 37, pp.\n41–46, Nov. 1989.\n[26] J. Keeler, D. Rumelhart, and W. K. Leow, “Integrated seg-\nmentation and recognition of hand-printed numerals,” in Neural\nInformation Processing Systems, R. P. Lippmann, J. M. Moody,\nand D. S. Touretzky, Eds.\nSan Mateo, CA: Morgan Kaufmann,\nvol. 3, pp. 557–563, 1991.\n[27] O. Matan, C. J. C. Burges, Y. LeCun, and J. S. Denker, “Multi-\ndigit recognition using a space displacement neural network,”\nvol. 4, in Neural Information Processing Systems, J. M. Moody,\nS. J. Hanson, and R. P. Lippman, Eds.\nSan Mateo, CA:\nMorgan Kaufmann, 1992.\n[28] L. R. Rabiner, “A tutorial on hidden Markov models and\nselected applications in speech recognition,” Proc. IEEE, vol.\n77, pp. 257–286, Feb. 1989.\n[29] H. A. Bourland and N. Morgan, Connectionist Speech Recog-\nnition: A Hybrid Approach.\nBoston: Kluwer, 1994.\n[30] D. H. Hubel and T. N. Wiesel, “Receptive ﬁelds, binocular in-\nteraction, and functional architecture in the cat’s visual cortex,”\nJ. Physiology (London), vol. 160, pp. 106–154, 1962.\n[31] K. Fukushima, “Cognition: A self-organizing multilayered neu-\nral network,” Biological Cybern., vol. 20, pp. 121–136, 1975.\n[32] K. Fukushima and S. Miyake, “Neocognitron: A new algorithm\nfor pattern recognition tolerant of deformations and shifts in\nposition,” Pattern Recognit., vol. 15, no. 6, pp. 455–469, Nov.\n1982.\n[33] M. C. Mozer, The Perception of Multiple Objects: A Con-\nnectionist Approach.\nCambridge, MA: MIT-Bradford Books,\n1991.\n[34] Y. LeCun, “Generalization and network design strategies,”\nin Connectionism in Perspective, R. Pfeifer, Z. Schreter, F.\nFogelman, and L. Steels, Eds.\nZurich, Switzerland: Elsevier,\n1989.\n[35] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E.\nHoward, W. Hubbard, and L. D. Jackel, “Handwritten digit\nrecognition with a back-propagation network,” in Advances\nin Neural Information Processing Systems 2 (NIPS’89), David\nTouretzky, Ed.\nDenver, CO: Morgan Kaufmann, 1990.\n[36] G. L. Martin, “Centered-object integrated segmentation and\nrecognition of overlapping hand-printed characters,” Neural\nComputation, vol. 5, no. 3, pp. 419–429, 1993.\n[37] J. Wang and J. Jean, “Multi-resolution neural networks for\nomnifont character recognition,” in Proc. Int. Conf. Neural\nNetworks, vol. III, 1993, pp. 1588–1593.\n[38] Y. Bengio, Y. LeCun, C. Nohl, and C. Burges, “Lerec: A\nNN/HMM hybrid for on-line handwriting recognition,” Neural\nComputation, vol. 7, no. 5, 1995.\n[39] S. Lawrence, C. L. Giles, A. C. Tsoi, and A. D. Back, “Face\nrecognition: A convolutional neural network approach,” IEEE\nTrans. Neural Networks, vol. 8, pp. 98–113, Jan. 1997.\n[40] K. J. Lang and G. E. Hinton, “A time delay neural network\narchitecture for speech recognition,” Carnegie-Mellon Univ.,\nPittsburgh, PA, Tech. Rep. CMU-CS-88-152, 1988.\n[41] A. H. Waibel, T. Hanazawa, G. Hinton, K. Shikano, and K.\nLang, “Phoneme recognition using time-delay neural networks,”\nIEEE Trans. Acoustics, Speech, Signal Processing, vol. 37, pp.\n328–339, Mar. 1989.\n[42] L. Bottou, F. Fogelman, P. Blanchet, and J. S. Lienard, “Speaker\nindependent isolated digit recognition: Multilayer perceptron\nversus dynamic time warping,” Neural Networks, vol. 3, pp.\n453–465, 1990.\n[43] P. Haffner and A. H. Waibel, “Time-delay neural networks\nembedding time alignment: A performance analysis,” in Proc.\nEUROSPEECH’91, 2nd Europ. Conf. Speech Communication\nand Technology, Genova, Italy.\n[44] I. Guyon, P. Albrecht, Y. LeCun, J. S. Denker, and W. Hubbard,\n“Design of a neural network character recognizer for a touch\nterminal,” Pattern Recognit., vol. 24, no. 2, pp. 105–119, 1991.\n[45] J. Bromley, J. W. Bentz, L. bottou, I. Guyon, Y. LeCun, C.\nMoore, E. S¨ackinger, and R. Shah, “Signature veriﬁcation using\na siamese time delay neural network,” Int. J. Pattern Recognit.\nArtiﬁcial Intell., vol. 7, no. 4, pp. 669–687, Aug. 1993.\n[46] Y. LeCun, I. Kanter, and S. Solla, “Eigenvalues of covariance\nmatrices: Application to neural-network learning,” Phys. Rev.\nLett., vol. 66, no. 18, pp. 2396–2399, May 1991.\n[47] T. G. Dietterich and G. Bakiri, “Solving multiclass learning\nproblems via error-correcting output codes,” J. Artiﬁcial Intell.\nRes., vol. 2, pp. 263–286, 1995.\n[48] L. R. Bahl, P. F. Brown, P. V. de Souza, and R. L. Mercer,\n“Maximum mutual information of hidden Markov model pa-\nrameters for speech recognition,” in Proc. Int. Conf. Acoustics,\nSpeech, Signal Processing, 1986, pp. 49–52.\n[49]\n, “Speech recognition with continuous-parameter hidden\nMarkov models,” Comput., Speech Language, vol. 2, pp.\n219–234, 1987.\n[50] B. H. Juang and S. Katagiri, “Discriminative learning for\nminimum error classiﬁcation,” IEEE Trans. Acoustics, Speech,\nSignal Processing, vol. 40, pp. 3043–3054, Dec. 1992.\n[51] Y. LeCun, L. D. Jackel, L. Bottou, A. Brunot, C. Cortes, J. S.\nDenker, H. Drucker, I. Guyon, U. A. Muller, E. S¨ackinger, P.\nSimard, and V. N. Vapnik, “Comparison of learning algorithms\nfor handwritten digit recognition,” in Int. Conf. Artiﬁcial Neural\nNetworks, F. Fogelman and P. Gallinari, Eds.\nParis: EC2 &\nCie, 1995, pp. 53–60.\n[52] I. Guyon, I. Poujaud, L. Personnaz, G. Dreyfus, J. Denker, and\nY. LeCun, “Comparing different neural net architectures for\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2321\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nclassifying handwritten digits,” in Proc. IEEE IJCNN, Wash-\nington, DC, vol. II, 1989, pp. 127–132,.\n[53] R. Ott, “Construction of quadratic polynomial classiﬁers,” in\nProc. IEEE Int. Conf. Pattern Recognition, 1976, pp. 161–165.\n[54] J. Sch¨urmann, “A multifont word recognition system for postal\naddress reading,” IEEE Trans. Comput., vol. C-27, pp. 721–732,\nAug. 1978.\n[55] Y. Lee, “Handwritten digit recognition using k-nearest neigh-\nbor, radial-basis functions, and backpropagation neural net-\nworks,” Neural Computation, vol. 3, no. 3, pp. 440–449, 1991.\n[56] D. Saad and S. A. Solla, “Dynamics of on-line gradient descent\nlearning for multilayer neural networks,” in Advances in Neural\nInformation Processing Systems, vol. 8, D. S. Touretzky, M.\nC. Mozer, and M. E. Hasselmo, Eds.\nCambridge, MA: MIT,\n1996, pp. 302–308.\n[57] G. Cybenko, “Approximation by superpositions of sigmoidal\nfunctions,” Math. Control, Signals, Syst., vol. 2, no. 4, pp.\n303–314, 1989.\n[58] L. Bottou and V. N. Vapnik, “Local learning algorithms,”\nNeural Computation, vol. 4, no. 6, pp. 888–900, 1992.\n[59] R. E. Schapire, “The strength of weak learnability,” Machine\nLearning, vol. 5, no. 2, pp. 197–227, 1990.\n[60] H. Drucker, R. Schapire, and P. Simard, “Improving per-\nformance inneural networks using a boosting algorithm,” in\nAdvances in Neural Information Processing Systems 5, S. J.\nHanson, J. D. Cowan, and C. L. Giles, Eds.\nSan Mateo, CA:\nMorgan Kaufmann, 1993, pp. 42–49.\n[61] P. Simard, Y. LeCun, and J. Denker, “Efﬁcient pattern recog-\nnition using a new transformation distance,” in Advances in\nNeural Information Processing Systems, vol. 5, S. Hanson, J.\nCowan, and L. Giles, Eds.\nSan Mateo, CA: Morgan Kauf-\nmann, 1993.\n[62] B. Boser, I. Guyon, and V. Vapnik, “A training algorithm\nfor optimal margin classiﬁers,” in Proc. 5th Annu. Workshop\nComputational Learning Theory, vol. 5, 1992, pp. 144–152.\n[63] C. J. C. Burges and B. Schoelkopf, “Improving the accuracy\nand speed of support vector machines,” in Advances in Neural\nInformation Processing Systems 9, M. Jordan, M. Mozer, and\nT. Petsche, Eds.\nCambridge, MA: MIT, 1997.\n[64] E. S¨ackinger, B. Boser, J. Bromley, Y. LeCun, and L. D. Jackel,\n“Application of the ANNA neural network chip to high-speed\ncharacter recognition,” IEEE Trans. Neural Networks, vol. 3,\nno. 3, pp. 498–505, Mar. 1992.\n[65] J. S. Bridle, “Probabilistic interpretation of feedforward classi-\nﬁcation networks outputs, with relationship to statistical pattern\nrecognition,” in Neurocomputing, Algorithms, Architectures and\nApplications, F. Fogelman, J. Herault, and Y. Burnod, Eds.\nLes Arcs, France: Springer, 1989.\n[66] Y. LeCun, L. Bottou, and Y. Bengio, “Reading checks with\ngraph transformer networks,” in Proc. IEEE Int. Conf. Acous-\ntics, Speech, Signal Processing. Munich, Germany, vol. 1, 1997,\npp. 151–154,.\n[67] Y. Bengio, Neural Networks for Speech and Sequence Recogni-\ntion.\nLondon, UK: International Thompson, 1996.\n[68] C. Burges, O. Matan, Y. LeCun, J. Denker, L. Jackel, C.\nStenard, C. Nohl, and J. Ben, “Shortest path segmentation: A\nmethod for training a neural network to recognize character\nstrings,” in Proc. Int. Joint Conf. Neural Networks, Baltimore,\nMD, vol. 3, 1992, pp. 165–172.\n[69] T. M. Breuel, “A system for the off-line recognition of hand-\nwritten text,” in Proc. IEEE ICPR’94, Jerusalem, pp. 129–134.\n[70] A. Viterbi, “Error bounds for convolutional codes and an\nasymptotically optimum decoding algorithm,” IEEE Trans. In-\nform. Theory, vol. 15, pp. 260–269, Apr. 1967.\n[71] R. P. Lippmann and B. Gold, “Neural-net classiﬁers useful\nfor speech recognition,” in Proc. IEEE 1st Int. Conf. Neural\nNetworks, San Diego, CA, June 1987, pp. 417–422.\n[72] H. Sakoe, R. Isotani, K. Yoshida, K. Iso, and T. Watan-\nabe, “Speaker-independent word recognition using dynamic\nprogramming neural networks,” in Proc. Int. Conf. Acoustics,\nSpeech, Signal Processing, Glasgow, 1989, pp. 29–32.\n[73] J. S. Bridle, “Alphanets: A recurrent ‘neural’ network archi-\ntecture with a hidden Markov model interpretation,” Speech\nCommun., vol. 9, no. 1, pp. 83–92, 1990.\n[74] M. A. Franzini, K. F. Lee, and A. H. Waibel, “Connectionist\nviterbi training: A new hybrid method for continuous speech\nrecognition,” in Proc. Int. Conf. Acoustics, Speech, Signal Pro-\ncessing, Albuquerque, NM, 1990, pp. 425–428.\n[75] L. T. Niles and H. F. Silverman, “Combining hidden Markov\nmodels and neural network classiﬁers,” in Proc. Int. Conf.\nAcoustics, Speech, Signal Processing, Albuquerque, NM, 1990,\npp. 417–420.\n[76] X. Driancourt and L. Bottou, “MLP, LVQ and DP: Comparison\n& cooperation,” in Proc. Int. Joint Conf. Neural Networks,\nSeattle, WA, vol. 2, 1991, pp. 815–819.\n[77] Y. Bengio, R. De Mori, G. Flammia, and R. Kompe, “Global\noptimization of a neural network-hidden Markov model hybrid,”\nIEEE Trans. Neural Networks, vol. 3, pp. 252–259, March 1992.\n[78] P. Haffner and A. H. Waibel, “Multi-state time-delay neural net-\nworks for continuous speech recognition,” vol. 4, in Advances\nin Neural Information Processing Systems.\nSan Mateo, CA:\nMorgan Kaufmann, pp. 579–588, 1992.\n[79] Y. Bengio, P. Simard, and P. Frasconi, “Learning long-term\ndependencies with gradient descent is difﬁcult,” IEEE Trans.\nNeural Networks, vol. 5, no. 2, pp. 157–166, Mar. 1994.\n[80] T. Kohonen, G. Barna, and R. Chrisley, “Statistical pattern\nrecognition with neural network: Benchmarking studies,” in\nProc. IEEE 2nd Int. Conf. Neural Networks, San Diego, CA,\nvol. 1, 1988, pp. 61–68.\n[81] P. Haffner, “Connectionist speech recognition with a global\nMMI algorithm,” in Proc. EUROSPEECH’93, 3rd Europ. Conf.\nSpeech Communication and Technology, Berlin, pp. 1929–1932.\n[82] J. S. Denker and C. J. Burges, “Image segmentation and\nrecognition,” in The Mathematics of Induction.\nReading, MA:\nAddison Wesley, 1995.\n[83] L. Bottou, Une Approche th´eorique de l’Apprentissage Connex-\nionniste: Applications `a la Reconnaissance de la Parole, Ph.D.\ndissertation, Univ. Paris XI, France, 1991.\n[84] M. Rahim, Y. Bengio, and Y. LeCun, “Disriminative feature\nand model design for automatic speech recognition,” in Proc.\nEurospeech, Rhodes, Greece, 1997, pp. 75–78.\n[85] U. Bodenhausen, S. Manke, and A. Waibel, “Connectionist\narchitectural learning for high performance character and speech\nrecognition,” in Proc. Int. Conf. Acoustics, Speech, Signal Pro-\ncessing, Minneapolis, MN, vol. 1, 1993, pp. 625–628.\n[86] F. Pereira, M. Riley, and R. Sproat, “Weighted rational trans-\nductions and their application to human language processing,”\nin ARPA Natural Language Processing Workshop, 1994.\n[87] M. Lades, J. C. Vorbr¨uggen, J. Buhmann, and C. von der Mals-\nburg, “Distortion invariant object recognition in the dynamic\nlink architecture,” IEEE Trans. Comput., vol. 42, pp. 300–311,\nMarch 1993.\n[88] B. Boser, E. S¨ackinger, J. Bromley, Y. LeCun, and L. Jackel,\n“An analog neural network processor with programmable topol-\nogy,” IEEE J. Solid-State Circuits, vol. 26, pp. 2017–2025, Dec.\n1991.\n[89] M. Schenkel, H. Weissman, I. Guyon, C. Nohl, and D. Hender-\nson, “Recognition-based segmentation of on-line hand-printed\nwords,” in Advances in Neural Information Processing Systems\n5, S. J. Hanson, J. D. Cowan, and C. L. Giles, Eds.\nDenver,\nCO: Morgan Kaufmann, 1993, pp. 723–730.\n[90] C. Dugust, L. Devillers, and X. Aubert, “Combining TDNN\nand HMM in a hybrid system for improved continuous-speech\nrecognition,” IEEE Trans. Speech Audio Processing, vol. 2, pp.\n217–224, Jan. 1994.\n[91] O. Matan, H. S. Baird, J. Bromley, C. J. C. Burges, J. S. Denker,\nL. D. Jackel, Y. LeCun, E. P. D. Pednault, W. Satterﬁeld, C. E.\nStenard, and T. J. Thompson, “Reading handwritten digits: A\nZIP code recognition system,” IEEE Trans. Comput., vol. 25,\nno. 7, pp. 59–63, July 1992.\n[92] Y. Bengio and Y. LeCun, “Word normalization for on-line\nhandwritten word recognition,” in Proc. IEEE Int. Conf. Pattern\nRecognition, Jerusalem, 1994.\n[93] R. Vaillant, C. Monrocq, and Y. LeCun, “Original approach for\nthe localization of objects in images,” Proc. Inst. Elect. Eng.,\nvol. 141, no. 4, pp. 245–250, Aug. 1994.\n[94] R. Wolf and J. Platt, “Postal address block location using a\nconvolutional locator network,” in Advances in Neural Infor-\nmation Processing Systems 6, J. D. Cowan, G. Tesauro, and\nJ. Alspector, Eds.\nSan Mateo, CA: Morgan Kaufmann, 1994,\npp. 745–752.\n[95] S. Nowlan and J. Platt, “A convolutional neural network hand\ntracker,” in Advances in Neural Information Processing Systems\n7, G. Tesauro, D. Touretzky, and T. Leen, Eds.\nSan Mateo,\nCA: Morgan Kaufmann, 1995, pp. 901–908.\n[96] H. A. Rowley, S. Baluja, and T. Kanade, “Neural network-based\n2322\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nface detection,” in Proc. IEEE CVPR’96, pp. 203–208.\n[97] E. Osuna, R. Freund, and F. Girosi, “Training support vector\nmachines: An application to face detection,” in Proc. IEEE\nCVPR’96, pp. 130–136.\n[98] H. Bourlard and C. J. Wellekens, “Links between Markov\nmodels and multilayer perceptrons,” in Advances in Neural\nInformation Processing Systems, D. Touretzky, Ed.\nDenver:\nMorgan-Kaufmann, vol. 1, 1989, pp. 186–187.\n[99] Y. Bengio, R. De Mori, G. Flammia, and R. Kompe, “Neural\nnetwork—Gaussian mixture hybrid for speech recognition or\ndensity estimation,” in Advances in Neural Information Process-\ning Systems 4, J. E. Moody, S. J. Hanson, and R. P. Lippmann,\nEds.\nDenver, CO: Morgan Kaufmann, 1992, pp. 175–182.\n[100] F. C. N. Pereira and M. Riley, “Speech recognition by compo-\nsition of weighted ﬁnite automata,” in Finite-State Devices for\nNatural Lague Processing.\nCambridge, MA: MIT, 1997.\n[101] M. Mohri, “Finite-state transducers in language and speech\nprocessing,” Computational Linguistics, vol. 23, no. 2, pp.\n269–311, 1997.\n[102] I. Guyon, M. Schenkel, and J. Denker, “Overview and syn-\nthesis of on-line cursive handwriting recognition techniques,”\nin Handbook on Optical Character Recognition and Document\nImage Analysis, P. S. P. Wang and H. Bunke, Eds.\nNew York:\nWorld Scientiﬁc, 1996.\n[103] M. Mohri and M. Riley, “Weighted determinization and mini-\nmization for large vocabulary recognition,” in Proc. Eurospeech\n’97, Rhodes, Greece, pp. 131–134.\n[104] Y. Bengio and P. Frasconi, “An input/output HMM architec-\nture,” in Advances in Neural Information Processing Systems,\nvol. 7, G. Tesauro, D. Touretzky, and T. Leen, Eds.\nCam-\nbridge, MA: MIT, pp. 427–434, 1996.\n[105]\n, “Input/output HMM’s for sequence processing,” IEEE\nTrans. Neural Networks, vol. 7, no. 5, pp. 1231–1249, 1996.\n[106] M. Mohri, F. C. N. Pereira, and M. Riley, A Rational Design\nfor a Weighted Finite-State Transducer Library (Lecture Notes\nin Computer Science).\nNew York: Springer Verlag, 1997.\n[107] M. Rahim, C. H. Lee, and B. H. Juang, “Discriminative\nutterance veriﬁcation for connected digits recognition,” IEEE\nTrans. Speech Audio Processing, vol. 5, pp. 266–277, 1997.\n[108] M. Rahim, Y. Bengio, and Y. LeCun, “Discriminative feature\nand model design for automatic speech recognition,” in Proc.\nEurospeech ’97, Rhodes, Greece.\n[109] S. Bengio and Y. Bengio, “An EM algorithm for asynchronous\ninput/output hidden Markov models,” in Proc. International\nConference on Neural Information Processing, Hong-King,\n1996, pp. 328–334.\n[110] C. Tappert, C. Suen, and T. Wakahara, “The state of the art\nin on-line handwriting recognition,” IEEE Trans. Pattern Anal.\nMachine Intell., vol. 8, pp. 787–808, Dec. 1990.\n[111] S. Manke and U. Bodenhausen, “A connectionist recognizer\nfor on-line cursive handwriting recognition,” in Proc. Int. Conf.\nAcoustics, Speech, Signal Processing, Adelaide, vol. 2, 1994,\npp. 633–636.\n[112] M. Gilloux and M. Leroux, “Recognition of cursive script\namounts on postal checks,” in Proc. Europ. Conf. Postal Tech-\nnol., Nantes, France, June 1993, pp. 705–712.\n[113] D. Guillevic and C. Y. Suen, “Cursive script recognition applied\nto the processing of bank checks,” in Proc. Int. Conf. Document\nAnalysis Recognition, Montreal, Canada, Aug. 1995, pp. 11–14.\n[114] L. Lam, C. Y. Suen, D. Guillevic, N. W. Strathy, M. Cheriet,\nK. Liu, and J. N. Said, “Automatic processing of informa-\ntion on checks,” in Int. Conf. Systems, Man, and Cybernetics,\nVancouver, Canada, Oct. 1995, pp. 2353–2358.\n[115] C. J. C. Burges, J. I. Ben, J. S. Denker, Y. LeCun, and C. R.\nNohl, “Off line recognition of handwritten postal words using\nneural networks,” Int. J. Pattern Recognit. Artiﬁcial Intell., vol.\n7, no. 4, p. 689, 1993.\n[116] Y. LeCun, Y. Bengio, D. Henderson, A. Weisbuch, H. Weiss-\nman, and L. Jackel, “On-line handwriting recognition with\nneural networks: Spatial representation versus temporal repre-\nsentation,” in Proc. Int. Conf. Handwriting Drawing, 1993.\n[117] U. M¨uller, A. Gunzinger, and W. Guggenb¨uhl, “Fast neural net\nsimulation with a DSP processor array,” IEEE Trans. Neural\nNetworks, vol. 6, pp. 203–213, Jan. 1995.\n[118] R. Battiti, “First- and second-order methods for learning: Be-\ntween steepest descent and Newton’s method,” Neural Compu-\ntation, vol. 4, no. 2, pp. 141–166, 1992.\n[119] A. H. Kramer and A. Sangiovanni-Vincentelli, “Efﬁcient par-\nallel learning algorithms for neural networks,” in Advances in\nNeural Information Processing Systems, vol. 1, D. S. Touretzky,\nEd.\nSan Mateo, CA: Morgan Kaufmann, 1988, pp. 40–48.\n[120] M. Moller, Efﬁcient Training of Feed-Forward Neural Net-\nworks, Ph.D. dissertation, Aarhus Univ., Aarhus, Denmark,\n1993.\n[121] S. Becker and Y. LeCun, “Improving the convergence of\nback-propagation learning with second-order methods,” Univ.\nToronto Connectionist Res. Group, Toronto, Ontario, Canada,\nTech. Rep. CRG-TR-88-5, Sept. 1988.\nYann LeCun (Member, IEEE) received the\nDiplˆome d’Ing´enieur degree from the Ecole\nSup´erieure\nd’Ing´enieur\nen\nElectrotechnique\net Electronique, Paris, in 1983 and the Ph.D.\ndegree in computer science from the Universit´e\nPierre et Marie Curie, Paris, in 1987.\nDuring his time at the Universit´e Pierre et\nMarie Curie, he proposed an early version of\nthe back-propagation learning algorithm for\nneural networks. He joined the Department of\nComputer Science at the University of Toronto,\nToronto, Ont., Canada, as a Research Associate in 1987. In 1988, he joined\nthe Adaptive Systems Research Department at AT&T Bell Laboratories,\nHolmdel, NJ, where he worked on neural networks, machine learning, and\nhandwriting recognition. In 1996 he became Head of the Image Processing\nServices Research Department at AT&T Labs-Research, Red Bank, NJ.\nHe has published over 70 technical papers and book chapters on neural\nnetworks, machine learning, pattern recognition, handwriting recognition,\ndocument understanding, image processing, very large scale integration\n(VLSI) design, and information theory. In addition to the above topics, his\ncurrent interests include video-based user interfaces, image compression,\nand content-based indexing of multimedia material.\nDr. LeCun serves on the board of the Machine Learning Journal and\nhas served as Associate Editor of the IEEE TRANSACTIONS ON NEURAL\nNETWORKS. He is General Chair of the “Machines That Learn” workshop,\nwhich has been held every year since 1986 in Snowbird, UT. He has\nserved as Program Co-Chair of IJCNN’89, INNC’90, and NIPS’90,\n’94, and ’95. He is a member of the IEEE Neural Network for Signal\nProcessing Technical Committee.\nL´eon Bottou received the Dipˆome degree from\nEcole Polytechnique, Paris, in 1987, the Mag-\nist`ere en Math´ematiques Fondamentales et Ap-\npliqu´ees et Informatiques degree from Ecole\nNormale Sup´erieure, Paris in 1988, and the\nPh.D. degree in computer science from Univer-\nsit´e de Paris-Sud in 1991.\nDuring his time at Universit´e de Paris-Sud he\nworked on speech recognition and proposed a\nframework for stochastic gradient learning and\nglobal training. He then joined the Adaptive\nSystems Research Department at AT&T Bell Laboratories, Holmdel, NJ,\nwhere he worked on neural networks, statistical learning theory, and local\nlearning algorithms. He returned to France in 1992 as a Research Engineer\nat ONERA. He then became Chairman of Neuristique S.A., a company\nthat makes neural network simulators and trafﬁc forecasting software.\nHe returned to AT&T Bell Laboratories in 1995 where he worked on\ngraph transformer networks for optical character recognition. He is now a\nMember of the Image Processing Services Research Department at AT&T\nLabs-Research, Red Bank, NJ. Besides learning algorithms, his current\ninterests include arithmetic coding, image compression, and indexing.\nLECUN et al.: GRADIENT-BASED LEARNING APPLIED TO DOCUMENT RECOGNITION\n2323\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n\n\nYoshua Bengio received the B.Eng. degree in\nelectrical engineering and the M.Sc. and Ph.D.\ndegrees in computer science from McGill Uni-\nversity, Montreal, P.Q., Canada, in 1986, 1988,\nand 1991, respectively.\nIn 1991–1992 he was a Postdoctoral Fel-\nlow at the Massachusetts Institute of Technol-\nogy, Cambridge. In 1992 he joined AT&T Bell\nLaboratories, which later became AT&T Labs-\nResearch, Red Bank, NJ. In 1993 he joined the\nfaculty of the computer science department of\nthe Universit´e de Montr´eal, Montr´eal, P.Q., Canada, where he is now an\nAssociate Professor. Since his ﬁrst work on neural networks in 1986,\nhis research interests have been centered around learning algorithms,\nespecially for data with a sequential or spatial nature, such as speech,\nhandwriting, and time-series.\nPatrick Haffner graduated from Ecole Poly-\ntechnique, Paris, in 1987 and from Ecole\nNationale Sup´erieure des T´el´ecommunications\n(ENST), Paris, in 1989. He received the Ph.D\ndegree in speech and signal processing from\nENST in 1994.\nIn 1988 and 1990, he worked on the design of\nthe TDNN and the MS-TDNN architectures at\nATR (Japan) and Carnegie Mellon University.\nFrom 1989 to 1995, as a Research Scientist\nfor CNET/France-T´el´ecom in Lannion, France,\nhe developed connectionist learning algorithms for telephone speech\nrecognition. In 1995, he joined AT&T Bell Laboratories, Holmdel, NJ, and\nworked on the application of optical character recognition and transducers\nto the processing of ﬁnancial documents. In 1997, he joined the Image\nProcessing Services Research Department at AT&T Labs-Research, Red\nBank, NJ. His research interests include statistical and connectionist\nmodels for sequence recognition, machine learning, speech and image\nrecognition, and information theory.\n2324\nPROCEEDINGS OF THE IEEE, VOL. 86, NO. 11, NOVEMBER 1998\nAuthorized licensed use limited to: ULAKBIM UASL - Firat Universitesi. Downloaded on April 06,2025 at 14:19:04 UTC from IEEE Xplore.  Restrictions apply. \n"
}